INFO: [Torch-TensorRT] - ir was set to default, using TorchScript as ir
INFO: [Torch-TensorRT] - Module was provided as a torch.nn.Module, trying to script the module with torch.jit.script. In the event of a failure please preconvert your module to TorchScript
DEBUG: [Torch-TensorRT] - TensorRT Compile Spec: {
    "Inputs": [
Input(min_shape=(1,), opt_shape=(8,), max_shape=(16,), dtype=Int32, format=Contiguous/Linear/NCHW, tensor_domain=[0, 2))Input(min_shape=(1,), opt_shape=(8,), max_shape=(16,), dtype=Int32, format=Contiguous/Linear/NCHW, tensor_domain=[0, 2))    ]
    "Enabled Precision": [Float, ]
    "TF32 Disabled": 0
    "Sparsity": 0
    "Refit": 0
    "Debug": 0
    "Device":  {
        "device_type": GPU
        "allow_gpu_fallback": False
        "gpu_id": 0
        "dla_core": -1
    }

    "Engine Capability": Default
    "Num Avg Timing Iters": 1
    "Workspace Size": 8589934592
    "DLA SRAM Size": 1048576
    "DLA Local DRAM Size": 1073741824
    "DLA Global DRAM Size": 536870912
    "Truncate long and double": 0
    "Allow Shape tensors": 0
    "Torch Fallback":  {
        "enabled": False
        "min_block_size": 3
        "forced_fallback_operators": [
        ]
        "forced_fallback_modules": [
        ]
    }
}
DEBUG: [Torch-TensorRT] - init_compile_spec with input vector
DEBUG: [Torch-TensorRT] - Settings requested for Lowering:
    torch_executed_modules: [
    ]
DEBUG: [Torch-TensorRT] - RemoveNOPs - Note: Removing operators that have no meaning in TRT
INFO: [Torch-TensorRT] - Lowered Graph: graph(%idx.1 : Tensor,
      %pos.1 : Tensor):
  %self.token_emb.weight.1 : Float(50257, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.pos_emb.weight.1 : Float(1024, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.0.ln_1.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.0.ln_1.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.0.attention.c_attn.weight : Float(2304, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.0.attention.c_attn.bias : Float(2304, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.0.attention.n_embd : int = prim::Constant[value=768]()
  %self.blocks.0.attention.c_proj.weight.1 : Float(768, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.0.attention.c_proj.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.0.ln_2.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.0.ln_2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.0.mlp.0.weight.1 : Float(3072, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.0.mlp.0.bias.1 : Float(3072, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.0.mlp.2.weight.1 : Float(768, 3072, strides=[3072, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.0.mlp.2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.1.ln_1.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.1.ln_1.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.1.attention.c_attn.weight : Float(2304, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.1.attention.c_proj.weight.1 : Float(768, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.1.ln_2.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.1.ln_2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.1.mlp.0.weight.1 : Float(3072, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.1.mlp.0.bias.1 : Float(3072, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.1.mlp.2.weight.1 : Float(768, 3072, strides=[3072, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.1.mlp.2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.2.ln_1.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.2.ln_1.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.2.attention.c_attn.weight : Float(2304, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.2.attention.c_proj.weight.1 : Float(768, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.2.ln_2.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.2.ln_2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.2.mlp.0.weight.1 : Float(3072, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.2.mlp.0.bias.1 : Float(3072, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.2.mlp.2.weight.1 : Float(768, 3072, strides=[3072, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.2.mlp.2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.3.ln_1.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.3.ln_1.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.3.attention.c_attn.weight : Float(2304, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.3.attention.c_proj.weight.1 : Float(768, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.3.ln_2.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.3.ln_2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.3.mlp.0.weight.1 : Float(3072, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.3.mlp.0.bias.1 : Float(3072, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.3.mlp.2.weight.1 : Float(768, 3072, strides=[3072, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.3.mlp.2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.4.ln_1.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.4.ln_1.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.4.attention.c_attn.weight : Float(2304, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.4.attention.c_proj.weight.1 : Float(768, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.4.ln_2.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.4.ln_2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.4.mlp.0.weight.1 : Float(3072, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.4.mlp.0.bias.1 : Float(3072, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.4.mlp.2.weight.1 : Float(768, 3072, strides=[3072, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.4.mlp.2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.5.ln_1.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.5.ln_1.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.5.attention.c_attn.weight : Float(2304, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.5.attention.c_proj.weight.1 : Float(768, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.5.ln_2.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.5.ln_2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.5.mlp.0.weight.1 : Float(3072, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.5.mlp.0.bias.1 : Float(3072, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.5.mlp.2.weight.1 : Float(768, 3072, strides=[3072, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.5.mlp.2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.6.ln_1.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.6.ln_1.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.6.attention.c_attn.weight : Float(2304, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.6.attention.c_proj.weight.1 : Float(768, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.6.ln_2.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.6.ln_2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.6.mlp.0.weight.1 : Float(3072, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.6.mlp.0.bias.1 : Float(3072, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.6.mlp.2.weight.1 : Float(768, 3072, strides=[3072, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.6.mlp.2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.7.ln_1.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.7.ln_1.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.7.attention.c_attn.weight : Float(2304, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.7.attention.c_proj.weight.1 : Float(768, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.7.ln_2.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.7.ln_2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.7.mlp.0.weight.1 : Float(3072, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.7.mlp.0.bias.1 : Float(3072, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.7.mlp.2.weight.1 : Float(768, 3072, strides=[3072, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.7.mlp.2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.8.ln_1.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.8.ln_1.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.8.attention.c_attn.weight : Float(2304, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.8.attention.c_proj.weight.1 : Float(768, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.8.ln_2.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.8.ln_2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.8.mlp.0.weight.1 : Float(3072, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.8.mlp.0.bias.1 : Float(3072, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.8.mlp.2.weight.1 : Float(768, 3072, strides=[3072, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.8.mlp.2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.9.ln_1.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.9.ln_1.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.9.attention.c_attn.weight : Float(2304, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.9.attention.c_proj.weight.1 : Float(768, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.9.ln_2.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.9.ln_2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.9.mlp.0.weight.1 : Float(3072, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.9.mlp.0.bias.1 : Float(3072, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.9.mlp.2.weight.1 : Float(768, 3072, strides=[3072, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.9.mlp.2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.10.ln_1.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.10.ln_1.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.10.attention.c_attn.weight : Float(2304, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.10.attention.c_proj.weight.1 : Float(768, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.10.ln_2.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.10.ln_2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.10.mlp.0.weight.1 : Float(3072, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.10.mlp.0.bias.1 : Float(3072, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.10.mlp.2.weight.1 : Float(768, 3072, strides=[3072, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.10.mlp.2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.11.ln_1.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.11.ln_1.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.11.attention.c_attn.weight : Float(2304, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.11.attention.c_proj.weight.1 : Float(768, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.11.ln_2.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.11.ln_2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.11.mlp.0.weight.1 : Float(3072, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.11.mlp.0.bias.1 : Float(3072, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.11.mlp.2.weight.1 : Float(768, 3072, strides=[3072, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.11.mlp.2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.ln.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.ln.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %21 : bool = prim::Constant[value=0]()
  %20 : NoneType = prim::Constant()
  %19 : int = prim::Constant[value=0]() # gptadv_static.py:237:20
  %18 : int = prim::Constant[value=-1]() # gptadv_static.py:237:27
  %17 : int = prim::Constant[value=1]() # gptadv_static.py:231:8
  %16 : float = prim::Constant[value=1.41421]() # gptadv_static.py:26:46
  %15 : float = prim::Constant[value=0.5]() # gptadv_static.py:26:19
  %14 : float = prim::Constant[value=1.]() # gptadv_static.py:62:43
  %13 : int = prim::Constant[value=2]() # gptadv_static.py:62:32
  %12 : int = prim::Constant[value=-2]() # gptadv_static.py:62:31
  %11 : float = prim::Constant[value=1.0000000000000001e-05]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/normalization.py:191:66
  %10 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2515:72
  %9 : int[] = prim::Constant[value=[768]]()
  %8 : Float(32, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %7 : int[] = prim::Constant[value=[-1, 12, 64]]()
  %6 : float = prim::Constant[value=0.125]()
  %5 : int[] = prim::Constant[value=[-1, 768]]()
  %4 : int[] = prim::Constant[value=[-1, 50257]]()
  %3 : int[] = prim::Constant[value=[-1, 1]]()
  %token_emb.3 : Tensor = aten::embedding(%self.token_emb.weight.1, %idx.1, %18, %21, %21) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2210:11
  %pos_emb.3 : Tensor = aten::embedding(%self.pos_emb.weight.1, %pos.1, %18, %21, %21) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2210:11
  %x.1 : Tensor = aten::add(%token_emb.3, %pos_emb.3, %17) # gptadv_static.py:227:12
  %x_.2 : Tensor = aten::layer_norm(%x.1, %9, %self.blocks.0.ln_1.weight.1, %self.blocks.0.ln_1.bias.1, %11, %10) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2515:11
  %5305 : int = prim::Constant[value=1]()
  %5306 : Tensor = aten::t(%self.blocks.0.attention.c_attn.weight)
  %5307 : Tensor = aten::matmul(%x_.2, %5306)
  %5308 : Tensor = trt::const(%self.blocks.0.attention.c_attn.bias)
  %5309 : Tensor = aten::add(%5308, %5307, %5305)
  %154 : Tensor[] = aten::split(%5309, %self.blocks.0.attention.n_embd, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:119:19
  %q.2 : Tensor, %k.2 : Tensor, %v.2 : Tensor = prim::ListUnpack(%154)
  %158 : Tensor[] = prim::ListConstruct(%8, %k.2)
  %160 : Tensor[] = prim::ListConstruct(%8, %q.2)
  %162 : Tensor[] = prim::ListConstruct(%8, %v.2)
  %k.6 : Tensor = aten::cat(%158, %19) # gptadv_static.py:54:12
  %5255 : Tensor = aten::reshape(%k.6, %7)
  %q.6 : Tensor = aten::cat(%160, %19) # gptadv_static.py:55:12
  %5256 : Tensor = aten::reshape(%q.6, %7)
  %v.6 : Tensor = aten::cat(%162, %19) # gptadv_static.py:56:12
  %5257 : Tensor = aten::reshape(%v.6, %7)
  %k.10 : Tensor = aten::transpose(%5255, %19, %17) # gptadv_static.py:58:12
  %q.10 : Tensor = aten::transpose(%5256, %19, %17) # gptadv_static.py:59:12
  %v.10 : Tensor = aten::transpose(%5257, %19, %17) # gptadv_static.py:60:12
  %4633 : Tensor = aten::transpose(%k.10, %12, %18) # gptadv_static.py:62:19
  %4634 : Tensor = aten::matmul(%q.10, %4633) # gptadv_static.py:62:15
  %att.2 : Tensor = aten::mul(%4634, %6) # gptadv_static.py:62:15
  %ret.24 : Tensor = aten::softmax(%att.2, %18, %20) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1843:14
  %y.3 : Tensor = aten::matmul(%ret.24, %v.10) # gptadv_static.py:66:12
  %4638 : Tensor = aten::transpose(%y.3, %17, %13) # gptadv_static.py:67:12
  %5258 : Tensor = aten::reshape(%4638, %5)
  %5310 : int = prim::Constant[value=1]()
  %5311 : Tensor = aten::t(%self.blocks.0.attention.c_proj.weight.1)
  %5312 : Tensor = aten::matmul(%5258, %5311)
  %5313 : Tensor = trt::const(%self.blocks.0.attention.c_proj.bias.1)
  %5314 : Tensor = aten::add(%5313, %5312, %5310)
  %x.18 : Tensor = aten::add(%x.1, %5314, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:162:12
  %4643 : Tensor = aten::layer_norm(%x.18, %9, %self.blocks.0.ln_2.weight.1, %self.blocks.0.ln_2.bias.1, %11, %10) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2515:11
  %5315 : int = prim::Constant[value=1]()
  %5316 : Tensor = aten::t(%self.blocks.0.mlp.0.weight.1)
  %5317 : Tensor = aten::matmul(%4643, %5316)
  %5318 : Tensor = trt::const(%self.blocks.0.mlp.0.bias.1)
  %5319 : Tensor = aten::add(%5318, %5317, %5315)
  %4645 : Tensor = aten::mul(%5319, %15) # gptadv_static.py:26:15
  %4646 : Tensor = aten::div(%5319, %16) # gptadv_static.py:26:42
  %4647 : Tensor = aten::erf(%4646) # gptadv_static.py:26:32
  %4648 : Tensor = aten::add(%4647, %14, %17) # <string>:5:9
  %input.10 : Tensor = aten::mul(%4645, %4648) # gptadv_static.py:26:15
  %5320 : int = prim::Constant[value=1]()
  %5321 : Tensor = aten::t(%self.blocks.0.mlp.2.weight.1)
  %5322 : Tensor = aten::matmul(%input.10, %5321)
  %5323 : Tensor = trt::const(%self.blocks.0.mlp.2.bias.1)
  %5324 : Tensor = aten::add(%5323, %5322, %5320)
  %x.5 : Tensor = aten::add(%x.18, %5324, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:163:12
  %x_.4 : Tensor = aten::layer_norm(%x.5, %9, %self.blocks.1.ln_1.weight.1, %self.blocks.1.ln_1.bias.1, %11, %10) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2515:11
  %5325 : int = prim::Constant[value=1]()
  %5326 : Tensor = aten::t(%self.blocks.1.attention.c_attn.weight)
  %5327 : Tensor = aten::matmul(%x_.4, %5326)
  %5328 : Tensor = trt::const(%self.blocks.0.attention.c_attn.bias)
  %5329 : Tensor = aten::add(%5328, %5327, %5325)
  %191 : Tensor[] = aten::split(%5329, %self.blocks.0.attention.n_embd, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:119:19
  %q.12 : Tensor, %k.12 : Tensor, %v.12 : Tensor = prim::ListUnpack(%191)
  %195 : Tensor[] = prim::ListConstruct(%8, %k.12)
  %197 : Tensor[] = prim::ListConstruct(%8, %q.12)
  %199 : Tensor[] = prim::ListConstruct(%8, %v.12)
  %k.14 : Tensor = aten::cat(%195, %19) # gptadv_static.py:54:12
  %5259 : Tensor = aten::reshape(%k.14, %7)
  %q.14 : Tensor = aten::cat(%197, %19) # gptadv_static.py:55:12
  %5260 : Tensor = aten::reshape(%q.14, %7)
  %v.14 : Tensor = aten::cat(%199, %19) # gptadv_static.py:56:12
  %5261 : Tensor = aten::reshape(%v.14, %7)
  %k.16 : Tensor = aten::transpose(%5259, %19, %17) # gptadv_static.py:58:12
  %q.16 : Tensor = aten::transpose(%5260, %19, %17) # gptadv_static.py:59:12
  %v.16 : Tensor = aten::transpose(%5261, %19, %17) # gptadv_static.py:60:12
  %4687 : Tensor = aten::transpose(%k.16, %12, %18) # gptadv_static.py:62:19
  %4688 : Tensor = aten::matmul(%q.16, %4687) # gptadv_static.py:62:15
  %att.4 : Tensor = aten::mul(%4688, %6) # gptadv_static.py:62:15
  %ret.4 : Tensor = aten::softmax(%att.4, %18, %20) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1843:14
  %y.7 : Tensor = aten::matmul(%ret.4, %v.16) # gptadv_static.py:66:12
  %4692 : Tensor = aten::transpose(%y.7, %17, %13) # gptadv_static.py:67:12
  %5262 : Tensor = aten::reshape(%4692, %5)
  %5330 : int = prim::Constant[value=1]()
  %5331 : Tensor = aten::t(%self.blocks.1.attention.c_proj.weight.1)
  %5332 : Tensor = aten::matmul(%5262, %5331)
  %5333 : Tensor = trt::const(%self.blocks.0.attention.c_proj.bias.1)
  %5334 : Tensor = aten::add(%5333, %5332, %5330)
  %x.22 : Tensor = aten::add(%x.5, %5334, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:162:12
  %4697 : Tensor = aten::layer_norm(%x.22, %9, %self.blocks.1.ln_2.weight.1, %self.blocks.1.ln_2.bias.1, %11, %10) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2515:11
  %5335 : int = prim::Constant[value=1]()
  %5336 : Tensor = aten::t(%self.blocks.1.mlp.0.weight.1)
  %5337 : Tensor = aten::matmul(%4697, %5336)
  %5338 : Tensor = trt::const(%self.blocks.1.mlp.0.bias.1)
  %5339 : Tensor = aten::add(%5338, %5337, %5335)
  %4699 : Tensor = aten::mul(%5339, %15) # gptadv_static.py:26:15
  %4700 : Tensor = aten::div(%5339, %16) # gptadv_static.py:26:42
  %4701 : Tensor = aten::erf(%4700) # gptadv_static.py:26:32
  %4702 : Tensor = aten::add(%4701, %14, %17) # <string>:5:9
  %input.18 : Tensor = aten::mul(%4699, %4702) # gptadv_static.py:26:15
  %5340 : int = prim::Constant[value=1]()
  %5341 : Tensor = aten::t(%self.blocks.1.mlp.2.weight.1)
  %5342 : Tensor = aten::matmul(%input.18, %5341)
  %5343 : Tensor = trt::const(%self.blocks.1.mlp.2.bias.1)
  %5344 : Tensor = aten::add(%5343, %5342, %5340)
  %x.9 : Tensor = aten::add(%x.22, %5344, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:163:12
  %x_.6 : Tensor = aten::layer_norm(%x.9, %9, %self.blocks.2.ln_1.weight.1, %self.blocks.2.ln_1.bias.1, %11, %10) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2515:11
  %5345 : int = prim::Constant[value=1]()
  %5346 : Tensor = aten::t(%self.blocks.2.attention.c_attn.weight)
  %5347 : Tensor = aten::matmul(%x_.6, %5346)
  %5348 : Tensor = trt::const(%self.blocks.0.attention.c_attn.bias)
  %5349 : Tensor = aten::add(%5348, %5347, %5345)
  %228 : Tensor[] = aten::split(%5349, %self.blocks.0.attention.n_embd, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:119:19
  %q.18 : Tensor, %k.18 : Tensor, %v.18 : Tensor = prim::ListUnpack(%228)
  %232 : Tensor[] = prim::ListConstruct(%8, %k.18)
  %234 : Tensor[] = prim::ListConstruct(%8, %q.18)
  %236 : Tensor[] = prim::ListConstruct(%8, %v.18)
  %k.20 : Tensor = aten::cat(%232, %19) # gptadv_static.py:54:12
  %5263 : Tensor = aten::reshape(%k.20, %7)
  %q.20 : Tensor = aten::cat(%234, %19) # gptadv_static.py:55:12
  %5264 : Tensor = aten::reshape(%q.20, %7)
  %v.20 : Tensor = aten::cat(%236, %19) # gptadv_static.py:56:12
  %5265 : Tensor = aten::reshape(%v.20, %7)
  %k.22 : Tensor = aten::transpose(%5263, %19, %17) # gptadv_static.py:58:12
  %q.22 : Tensor = aten::transpose(%5264, %19, %17) # gptadv_static.py:59:12
  %v.22 : Tensor = aten::transpose(%5265, %19, %17) # gptadv_static.py:60:12
  %4741 : Tensor = aten::transpose(%k.22, %12, %18) # gptadv_static.py:62:19
  %4742 : Tensor = aten::matmul(%q.22, %4741) # gptadv_static.py:62:15
  %att.6 : Tensor = aten::mul(%4742, %6) # gptadv_static.py:62:15
  %ret.6 : Tensor = aten::softmax(%att.6, %18, %20) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1843:14
  %y.11 : Tensor = aten::matmul(%ret.6, %v.22) # gptadv_static.py:66:12
  %4746 : Tensor = aten::transpose(%y.11, %17, %13) # gptadv_static.py:67:12
  %5266 : Tensor = aten::reshape(%4746, %5)
  %5350 : int = prim::Constant[value=1]()
  %5351 : Tensor = aten::t(%self.blocks.2.attention.c_proj.weight.1)
  %5352 : Tensor = aten::matmul(%5266, %5351)
  %5353 : Tensor = trt::const(%self.blocks.0.attention.c_proj.bias.1)
  %5354 : Tensor = aten::add(%5353, %5352, %5350)
  %x.26 : Tensor = aten::add(%x.9, %5354, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:162:12
  %4751 : Tensor = aten::layer_norm(%x.26, %9, %self.blocks.2.ln_2.weight.1, %self.blocks.2.ln_2.bias.1, %11, %10) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2515:11
  %5355 : int = prim::Constant[value=1]()
  %5356 : Tensor = aten::t(%self.blocks.2.mlp.0.weight.1)
  %5357 : Tensor = aten::matmul(%4751, %5356)
  %5358 : Tensor = trt::const(%self.blocks.2.mlp.0.bias.1)
  %5359 : Tensor = aten::add(%5358, %5357, %5355)
  %4753 : Tensor = aten::mul(%5359, %15) # gptadv_static.py:26:15
  %4754 : Tensor = aten::div(%5359, %16) # gptadv_static.py:26:42
  %4755 : Tensor = aten::erf(%4754) # gptadv_static.py:26:32
  %4756 : Tensor = aten::add(%4755, %14, %17) # <string>:5:9
  %input.24 : Tensor = aten::mul(%4753, %4756) # gptadv_static.py:26:15
  %5360 : int = prim::Constant[value=1]()
  %5361 : Tensor = aten::t(%self.blocks.2.mlp.2.weight.1)
  %5362 : Tensor = aten::matmul(%input.24, %5361)
  %5363 : Tensor = trt::const(%self.blocks.2.mlp.2.bias.1)
  %5364 : Tensor = aten::add(%5363, %5362, %5360)
  %x.14 : Tensor = aten::add(%x.26, %5364, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:163:12
  %x_.8 : Tensor = aten::layer_norm(%x.14, %9, %self.blocks.3.ln_1.weight.1, %self.blocks.3.ln_1.bias.1, %11, %10) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2515:11
  %5365 : int = prim::Constant[value=1]()
  %5366 : Tensor = aten::t(%self.blocks.3.attention.c_attn.weight)
  %5367 : Tensor = aten::matmul(%x_.8, %5366)
  %5368 : Tensor = trt::const(%self.blocks.0.attention.c_attn.bias)
  %5369 : Tensor = aten::add(%5368, %5367, %5365)
  %265 : Tensor[] = aten::split(%5369, %self.blocks.0.attention.n_embd, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:119:19
  %q.24 : Tensor, %k.24 : Tensor, %v.24 : Tensor = prim::ListUnpack(%265)
  %269 : Tensor[] = prim::ListConstruct(%8, %k.24)
  %271 : Tensor[] = prim::ListConstruct(%8, %q.24)
  %273 : Tensor[] = prim::ListConstruct(%8, %v.24)
  %k.26 : Tensor = aten::cat(%269, %19) # gptadv_static.py:54:12
  %5267 : Tensor = aten::reshape(%k.26, %7)
  %q.26 : Tensor = aten::cat(%271, %19) # gptadv_static.py:55:12
  %5268 : Tensor = aten::reshape(%q.26, %7)
  %v.26 : Tensor = aten::cat(%273, %19) # gptadv_static.py:56:12
  %5269 : Tensor = aten::reshape(%v.26, %7)
  %k.28 : Tensor = aten::transpose(%5267, %19, %17) # gptadv_static.py:58:12
  %q.28 : Tensor = aten::transpose(%5268, %19, %17) # gptadv_static.py:59:12
  %v.28 : Tensor = aten::transpose(%5269, %19, %17) # gptadv_static.py:60:12
  %4795 : Tensor = aten::transpose(%k.28, %12, %18) # gptadv_static.py:62:19
  %4796 : Tensor = aten::matmul(%q.28, %4795) # gptadv_static.py:62:15
  %att.8 : Tensor = aten::mul(%4796, %6) # gptadv_static.py:62:15
  %ret.8 : Tensor = aten::softmax(%att.8, %18, %20) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1843:14
  %y.15 : Tensor = aten::matmul(%ret.8, %v.28) # gptadv_static.py:66:12
  %4800 : Tensor = aten::transpose(%y.15, %17, %13) # gptadv_static.py:67:12
  %5270 : Tensor = aten::reshape(%4800, %5)
  %5370 : int = prim::Constant[value=1]()
  %5371 : Tensor = aten::t(%self.blocks.3.attention.c_proj.weight.1)
  %5372 : Tensor = aten::matmul(%5270, %5371)
  %5373 : Tensor = trt::const(%self.blocks.0.attention.c_proj.bias.1)
  %5374 : Tensor = aten::add(%5373, %5372, %5370)
  %x.30 : Tensor = aten::add(%x.14, %5374, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:162:12
  %4805 : Tensor = aten::layer_norm(%x.30, %9, %self.blocks.3.ln_2.weight.1, %self.blocks.3.ln_2.bias.1, %11, %10) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2515:11
  %5375 : int = prim::Constant[value=1]()
  %5376 : Tensor = aten::t(%self.blocks.3.mlp.0.weight.1)
  %5377 : Tensor = aten::matmul(%4805, %5376)
  %5378 : Tensor = trt::const(%self.blocks.3.mlp.0.bias.1)
  %5379 : Tensor = aten::add(%5378, %5377, %5375)
  %4807 : Tensor = aten::mul(%5379, %15) # gptadv_static.py:26:15
  %4808 : Tensor = aten::div(%5379, %16) # gptadv_static.py:26:42
  %4809 : Tensor = aten::erf(%4808) # gptadv_static.py:26:32
  %4810 : Tensor = aten::add(%4809, %14, %17) # <string>:5:9
  %input.30 : Tensor = aten::mul(%4807, %4810) # gptadv_static.py:26:15
  %5380 : int = prim::Constant[value=1]()
  %5381 : Tensor = aten::t(%self.blocks.3.mlp.2.weight.1)
  %5382 : Tensor = aten::matmul(%input.30, %5381)
  %5383 : Tensor = trt::const(%self.blocks.3.mlp.2.bias.1)
  %5384 : Tensor = aten::add(%5383, %5382, %5380)
  %x.17 : Tensor = aten::add(%x.30, %5384, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:163:12
  %x_.10 : Tensor = aten::layer_norm(%x.17, %9, %self.blocks.4.ln_1.weight.1, %self.blocks.4.ln_1.bias.1, %11, %10) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2515:11
  %5385 : int = prim::Constant[value=1]()
  %5386 : Tensor = aten::t(%self.blocks.4.attention.c_attn.weight)
  %5387 : Tensor = aten::matmul(%x_.10, %5386)
  %5388 : Tensor = trt::const(%self.blocks.0.attention.c_attn.bias)
  %5389 : Tensor = aten::add(%5388, %5387, %5385)
  %302 : Tensor[] = aten::split(%5389, %self.blocks.0.attention.n_embd, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:119:19
  %q.30 : Tensor, %k.30 : Tensor, %v.30 : Tensor = prim::ListUnpack(%302)
  %306 : Tensor[] = prim::ListConstruct(%8, %k.30)
  %308 : Tensor[] = prim::ListConstruct(%8, %q.30)
  %310 : Tensor[] = prim::ListConstruct(%8, %v.30)
  %k.32 : Tensor = aten::cat(%306, %19) # gptadv_static.py:54:12
  %5271 : Tensor = aten::reshape(%k.32, %7)
  %q.32 : Tensor = aten::cat(%308, %19) # gptadv_static.py:55:12
  %5272 : Tensor = aten::reshape(%q.32, %7)
  %v.32 : Tensor = aten::cat(%310, %19) # gptadv_static.py:56:12
  %5273 : Tensor = aten::reshape(%v.32, %7)
  %k.34 : Tensor = aten::transpose(%5271, %19, %17) # gptadv_static.py:58:12
  %q.34 : Tensor = aten::transpose(%5272, %19, %17) # gptadv_static.py:59:12
  %v.34 : Tensor = aten::transpose(%5273, %19, %17) # gptadv_static.py:60:12
  %4849 : Tensor = aten::transpose(%k.34, %12, %18) # gptadv_static.py:62:19
  %4850 : Tensor = aten::matmul(%q.34, %4849) # gptadv_static.py:62:15
  %att.10 : Tensor = aten::mul(%4850, %6) # gptadv_static.py:62:15
  %ret.10 : Tensor = aten::softmax(%att.10, %18, %20) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1843:14
  %y.19 : Tensor = aten::matmul(%ret.10, %v.34) # gptadv_static.py:66:12
  %4854 : Tensor = aten::transpose(%y.19, %17, %13) # gptadv_static.py:67:12
  %5274 : Tensor = aten::reshape(%4854, %5)
  %5390 : int = prim::Constant[value=1]()
  %5391 : Tensor = aten::t(%self.blocks.4.attention.c_proj.weight.1)
  %5392 : Tensor = aten::matmul(%5274, %5391)
  %5393 : Tensor = trt::const(%self.blocks.0.attention.c_proj.bias.1)
  %5394 : Tensor = aten::add(%5393, %5392, %5390)
  %x.34 : Tensor = aten::add(%x.17, %5394, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:162:12
  %4859 : Tensor = aten::layer_norm(%x.34, %9, %self.blocks.4.ln_2.weight.1, %self.blocks.4.ln_2.bias.1, %11, %10) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2515:11
  %5395 : int = prim::Constant[value=1]()
  %5396 : Tensor = aten::t(%self.blocks.4.mlp.0.weight.1)
  %5397 : Tensor = aten::matmul(%4859, %5396)
  %5398 : Tensor = trt::const(%self.blocks.4.mlp.0.bias.1)
  %5399 : Tensor = aten::add(%5398, %5397, %5395)
  %4861 : Tensor = aten::mul(%5399, %15) # gptadv_static.py:26:15
  %4862 : Tensor = aten::div(%5399, %16) # gptadv_static.py:26:42
  %4863 : Tensor = aten::erf(%4862) # gptadv_static.py:26:32
  %4864 : Tensor = aten::add(%4863, %14, %17) # <string>:5:9
  %input.36 : Tensor = aten::mul(%4861, %4864) # gptadv_static.py:26:15
  %5400 : int = prim::Constant[value=1]()
  %5401 : Tensor = aten::t(%self.blocks.4.mlp.2.weight.1)
  %5402 : Tensor = aten::matmul(%input.36, %5401)
  %5403 : Tensor = trt::const(%self.blocks.4.mlp.2.bias.1)
  %5404 : Tensor = aten::add(%5403, %5402, %5400)
  %x.21 : Tensor = aten::add(%x.34, %5404, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:163:12
  %x_.12 : Tensor = aten::layer_norm(%x.21, %9, %self.blocks.5.ln_1.weight.1, %self.blocks.5.ln_1.bias.1, %11, %10) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2515:11
  %5405 : int = prim::Constant[value=1]()
  %5406 : Tensor = aten::t(%self.blocks.5.attention.c_attn.weight)
  %5407 : Tensor = aten::matmul(%x_.12, %5406)
  %5408 : Tensor = trt::const(%self.blocks.0.attention.c_attn.bias)
  %5409 : Tensor = aten::add(%5408, %5407, %5405)
  %339 : Tensor[] = aten::split(%5409, %self.blocks.0.attention.n_embd, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:119:19
  %q.36 : Tensor, %k.36 : Tensor, %v.36 : Tensor = prim::ListUnpack(%339)
  %343 : Tensor[] = prim::ListConstruct(%8, %k.36)
  %345 : Tensor[] = prim::ListConstruct(%8, %q.36)
  %347 : Tensor[] = prim::ListConstruct(%8, %v.36)
  %k.38 : Tensor = aten::cat(%343, %19) # gptadv_static.py:54:12
  %5275 : Tensor = aten::reshape(%k.38, %7)
  %q.38 : Tensor = aten::cat(%345, %19) # gptadv_static.py:55:12
  %5276 : Tensor = aten::reshape(%q.38, %7)
  %v.38 : Tensor = aten::cat(%347, %19) # gptadv_static.py:56:12
  %5277 : Tensor = aten::reshape(%v.38, %7)
  %k.40 : Tensor = aten::transpose(%5275, %19, %17) # gptadv_static.py:58:12
  %q.40 : Tensor = aten::transpose(%5276, %19, %17) # gptadv_static.py:59:12
  %v.40 : Tensor = aten::transpose(%5277, %19, %17) # gptadv_static.py:60:12
  %4903 : Tensor = aten::transpose(%k.40, %12, %18) # gptadv_static.py:62:19
  %4904 : Tensor = aten::matmul(%q.40, %4903) # gptadv_static.py:62:15
  %att.12 : Tensor = aten::mul(%4904, %6) # gptadv_static.py:62:15
  %ret.12 : Tensor = aten::softmax(%att.12, %18, %20) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1843:14
  %y.23 : Tensor = aten::matmul(%ret.12, %v.40) # gptadv_static.py:66:12
  %4908 : Tensor = aten::transpose(%y.23, %17, %13) # gptadv_static.py:67:12
  %5278 : Tensor = aten::reshape(%4908, %5)
  %5410 : int = prim::Constant[value=1]()
  %5411 : Tensor = aten::t(%self.blocks.5.attention.c_proj.weight.1)
  %5412 : Tensor = aten::matmul(%5278, %5411)
  %5413 : Tensor = trt::const(%self.blocks.0.attention.c_proj.bias.1)
  %5414 : Tensor = aten::add(%5413, %5412, %5410)
  %x.38 : Tensor = aten::add(%x.21, %5414, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:162:12
  %4913 : Tensor = aten::layer_norm(%x.38, %9, %self.blocks.5.ln_2.weight.1, %self.blocks.5.ln_2.bias.1, %11, %10) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2515:11
  %5415 : int = prim::Constant[value=1]()
  %5416 : Tensor = aten::t(%self.blocks.5.mlp.0.weight.1)
  %5417 : Tensor = aten::matmul(%4913, %5416)
  %5418 : Tensor = trt::const(%self.blocks.5.mlp.0.bias.1)
  %5419 : Tensor = aten::add(%5418, %5417, %5415)
  %4915 : Tensor = aten::mul(%5419, %15) # gptadv_static.py:26:15
  %4916 : Tensor = aten::div(%5419, %16) # gptadv_static.py:26:42
  %4917 : Tensor = aten::erf(%4916) # gptadv_static.py:26:32
  %4918 : Tensor = aten::add(%4917, %14, %17) # <string>:5:9
  %input.42 : Tensor = aten::mul(%4915, %4918) # gptadv_static.py:26:15
  %5420 : int = prim::Constant[value=1]()
  %5421 : Tensor = aten::t(%self.blocks.5.mlp.2.weight.1)
  %5422 : Tensor = aten::matmul(%input.42, %5421)
  %5423 : Tensor = trt::const(%self.blocks.5.mlp.2.bias.1)
  %5424 : Tensor = aten::add(%5423, %5422, %5420)
  %x.25 : Tensor = aten::add(%x.38, %5424, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:163:12
  %x_.14 : Tensor = aten::layer_norm(%x.25, %9, %self.blocks.6.ln_1.weight.1, %self.blocks.6.ln_1.bias.1, %11, %10) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2515:11
  %5425 : int = prim::Constant[value=1]()
  %5426 : Tensor = aten::t(%self.blocks.6.attention.c_attn.weight)
  %5427 : Tensor = aten::matmul(%x_.14, %5426)
  %5428 : Tensor = trt::const(%self.blocks.0.attention.c_attn.bias)
  %5429 : Tensor = aten::add(%5428, %5427, %5425)
  %376 : Tensor[] = aten::split(%5429, %self.blocks.0.attention.n_embd, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:119:19
  %q.42 : Tensor, %k.42 : Tensor, %v.42 : Tensor = prim::ListUnpack(%376)
  %380 : Tensor[] = prim::ListConstruct(%8, %k.42)
  %382 : Tensor[] = prim::ListConstruct(%8, %q.42)
  %384 : Tensor[] = prim::ListConstruct(%8, %v.42)
  %k.44 : Tensor = aten::cat(%380, %19) # gptadv_static.py:54:12
  %5279 : Tensor = aten::reshape(%k.44, %7)
  %q.44 : Tensor = aten::cat(%382, %19) # gptadv_static.py:55:12
  %5280 : Tensor = aten::reshape(%q.44, %7)
  %v.44 : Tensor = aten::cat(%384, %19) # gptadv_static.py:56:12
  %5281 : Tensor = aten::reshape(%v.44, %7)
  %k.46 : Tensor = aten::transpose(%5279, %19, %17) # gptadv_static.py:58:12
  %q.46 : Tensor = aten::transpose(%5280, %19, %17) # gptadv_static.py:59:12
  %v.46 : Tensor = aten::transpose(%5281, %19, %17) # gptadv_static.py:60:12
  %4957 : Tensor = aten::transpose(%k.46, %12, %18) # gptadv_static.py:62:19
  %4958 : Tensor = aten::matmul(%q.46, %4957) # gptadv_static.py:62:15
  %att.14 : Tensor = aten::mul(%4958, %6) # gptadv_static.py:62:15
  %ret.14 : Tensor = aten::softmax(%att.14, %18, %20) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1843:14
  %y.27 : Tensor = aten::matmul(%ret.14, %v.46) # gptadv_static.py:66:12
  %4962 : Tensor = aten::transpose(%y.27, %17, %13) # gptadv_static.py:67:12
  %5282 : Tensor = aten::reshape(%4962, %5)
  %5430 : int = prim::Constant[value=1]()
  %5431 : Tensor = aten::t(%self.blocks.6.attention.c_proj.weight.1)
  %5432 : Tensor = aten::matmul(%5282, %5431)
  %5433 : Tensor = trt::const(%self.blocks.0.attention.c_proj.bias.1)
  %5434 : Tensor = aten::add(%5433, %5432, %5430)
  %x.42 : Tensor = aten::add(%x.25, %5434, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:162:12
  %4967 : Tensor = aten::layer_norm(%x.42, %9, %self.blocks.6.ln_2.weight.1, %self.blocks.6.ln_2.bias.1, %11, %10) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2515:11
  %5435 : int = prim::Constant[value=1]()
  %5436 : Tensor = aten::t(%self.blocks.6.mlp.0.weight.1)
  %5437 : Tensor = aten::matmul(%4967, %5436)
  %5438 : Tensor = trt::const(%self.blocks.6.mlp.0.bias.1)
  %5439 : Tensor = aten::add(%5438, %5437, %5435)
  %4969 : Tensor = aten::mul(%5439, %15) # gptadv_static.py:26:15
  %4970 : Tensor = aten::div(%5439, %16) # gptadv_static.py:26:42
  %4971 : Tensor = aten::erf(%4970) # gptadv_static.py:26:32
  %4972 : Tensor = aten::add(%4971, %14, %17) # <string>:5:9
  %input.48 : Tensor = aten::mul(%4969, %4972) # gptadv_static.py:26:15
  %5440 : int = prim::Constant[value=1]()
  %5441 : Tensor = aten::t(%self.blocks.6.mlp.2.weight.1)
  %5442 : Tensor = aten::matmul(%input.48, %5441)
  %5443 : Tensor = trt::const(%self.blocks.6.mlp.2.bias.1)
  %5444 : Tensor = aten::add(%5443, %5442, %5440)
  %x.29 : Tensor = aten::add(%x.42, %5444, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:163:12
  %x_.16 : Tensor = aten::layer_norm(%x.29, %9, %self.blocks.7.ln_1.weight.1, %self.blocks.7.ln_1.bias.1, %11, %10) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2515:11
  %5445 : int = prim::Constant[value=1]()
  %5446 : Tensor = aten::t(%self.blocks.7.attention.c_attn.weight)
  %5447 : Tensor = aten::matmul(%x_.16, %5446)
  %5448 : Tensor = trt::const(%self.blocks.0.attention.c_attn.bias)
  %5449 : Tensor = aten::add(%5448, %5447, %5445)
  %413 : Tensor[] = aten::split(%5449, %self.blocks.0.attention.n_embd, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:119:19
  %q.48 : Tensor, %k.48 : Tensor, %v.48 : Tensor = prim::ListUnpack(%413)
  %417 : Tensor[] = prim::ListConstruct(%8, %k.48)
  %419 : Tensor[] = prim::ListConstruct(%8, %q.48)
  %421 : Tensor[] = prim::ListConstruct(%8, %v.48)
  %k.50 : Tensor = aten::cat(%417, %19) # gptadv_static.py:54:12
  %5283 : Tensor = aten::reshape(%k.50, %7)
  %q.50 : Tensor = aten::cat(%419, %19) # gptadv_static.py:55:12
  %5284 : Tensor = aten::reshape(%q.50, %7)
  %v.50 : Tensor = aten::cat(%421, %19) # gptadv_static.py:56:12
  %5285 : Tensor = aten::reshape(%v.50, %7)
  %k.52 : Tensor = aten::transpose(%5283, %19, %17) # gptadv_static.py:58:12
  %q.52 : Tensor = aten::transpose(%5284, %19, %17) # gptadv_static.py:59:12
  %v.52 : Tensor = aten::transpose(%5285, %19, %17) # gptadv_static.py:60:12
  %5011 : Tensor = aten::transpose(%k.52, %12, %18) # gptadv_static.py:62:19
  %5012 : Tensor = aten::matmul(%q.52, %5011) # gptadv_static.py:62:15
  %att.16 : Tensor = aten::mul(%5012, %6) # gptadv_static.py:62:15
  %ret.16 : Tensor = aten::softmax(%att.16, %18, %20) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1843:14
  %y.31 : Tensor = aten::matmul(%ret.16, %v.52) # gptadv_static.py:66:12
  %5016 : Tensor = aten::transpose(%y.31, %17, %13) # gptadv_static.py:67:12
  %5286 : Tensor = aten::reshape(%5016, %5)
  %5450 : int = prim::Constant[value=1]()
  %5451 : Tensor = aten::t(%self.blocks.7.attention.c_proj.weight.1)
  %5452 : Tensor = aten::matmul(%5286, %5451)
  %5453 : Tensor = trt::const(%self.blocks.0.attention.c_proj.bias.1)
  %5454 : Tensor = aten::add(%5453, %5452, %5450)
  %x.46 : Tensor = aten::add(%x.29, %5454, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:162:12
  %5021 : Tensor = aten::layer_norm(%x.46, %9, %self.blocks.7.ln_2.weight.1, %self.blocks.7.ln_2.bias.1, %11, %10) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2515:11
  %5455 : int = prim::Constant[value=1]()
  %5456 : Tensor = aten::t(%self.blocks.7.mlp.0.weight.1)
  %5457 : Tensor = aten::matmul(%5021, %5456)
  %5458 : Tensor = trt::const(%self.blocks.7.mlp.0.bias.1)
  %5459 : Tensor = aten::add(%5458, %5457, %5455)
  %5023 : Tensor = aten::mul(%5459, %15) # gptadv_static.py:26:15
  %5024 : Tensor = aten::div(%5459, %16) # gptadv_static.py:26:42
  %5025 : Tensor = aten::erf(%5024) # gptadv_static.py:26:32
  %5026 : Tensor = aten::add(%5025, %14, %17) # <string>:5:9
  %input.54 : Tensor = aten::mul(%5023, %5026) # gptadv_static.py:26:15
  %5460 : int = prim::Constant[value=1]()
  %5461 : Tensor = aten::t(%self.blocks.7.mlp.2.weight.1)
  %5462 : Tensor = aten::matmul(%input.54, %5461)
  %5463 : Tensor = trt::const(%self.blocks.7.mlp.2.bias.1)
  %5464 : Tensor = aten::add(%5463, %5462, %5460)
  %x.33 : Tensor = aten::add(%x.46, %5464, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:163:12
  %x_.18 : Tensor = aten::layer_norm(%x.33, %9, %self.blocks.8.ln_1.weight.1, %self.blocks.8.ln_1.bias.1, %11, %10) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2515:11
  %5465 : int = prim::Constant[value=1]()
  %5466 : Tensor = aten::t(%self.blocks.8.attention.c_attn.weight)
  %5467 : Tensor = aten::matmul(%x_.18, %5466)
  %5468 : Tensor = trt::const(%self.blocks.0.attention.c_attn.bias)
  %5469 : Tensor = aten::add(%5468, %5467, %5465)
  %450 : Tensor[] = aten::split(%5469, %self.blocks.0.attention.n_embd, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:119:19
  %q.54 : Tensor, %k.54 : Tensor, %v.54 : Tensor = prim::ListUnpack(%450)
  %454 : Tensor[] = prim::ListConstruct(%8, %k.54)
  %456 : Tensor[] = prim::ListConstruct(%8, %q.54)
  %458 : Tensor[] = prim::ListConstruct(%8, %v.54)
  %k.56 : Tensor = aten::cat(%454, %19) # gptadv_static.py:54:12
  %5287 : Tensor = aten::reshape(%k.56, %7)
  %q.56 : Tensor = aten::cat(%456, %19) # gptadv_static.py:55:12
  %5288 : Tensor = aten::reshape(%q.56, %7)
  %v.56 : Tensor = aten::cat(%458, %19) # gptadv_static.py:56:12
  %5289 : Tensor = aten::reshape(%v.56, %7)
  %k.58 : Tensor = aten::transpose(%5287, %19, %17) # gptadv_static.py:58:12
  %q.58 : Tensor = aten::transpose(%5288, %19, %17) # gptadv_static.py:59:12
  %v.58 : Tensor = aten::transpose(%5289, %19, %17) # gptadv_static.py:60:12
  %5065 : Tensor = aten::transpose(%k.58, %12, %18) # gptadv_static.py:62:19
  %5066 : Tensor = aten::matmul(%q.58, %5065) # gptadv_static.py:62:15
  %att.18 : Tensor = aten::mul(%5066, %6) # gptadv_static.py:62:15
  %ret.18 : Tensor = aten::softmax(%att.18, %18, %20) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1843:14
  %y.35 : Tensor = aten::matmul(%ret.18, %v.58) # gptadv_static.py:66:12
  %5070 : Tensor = aten::transpose(%y.35, %17, %13) # gptadv_static.py:67:12
  %5290 : Tensor = aten::reshape(%5070, %5)
  %5470 : int = prim::Constant[value=1]()
  %5471 : Tensor = aten::t(%self.blocks.8.attention.c_proj.weight.1)
  %5472 : Tensor = aten::matmul(%5290, %5471)
  %5473 : Tensor = trt::const(%self.blocks.0.attention.c_proj.bias.1)
  %5474 : Tensor = aten::add(%5473, %5472, %5470)
  %x.50 : Tensor = aten::add(%x.33, %5474, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:162:12
  %5075 : Tensor = aten::layer_norm(%x.50, %9, %self.blocks.8.ln_2.weight.1, %self.blocks.8.ln_2.bias.1, %11, %10) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2515:11
  %5475 : int = prim::Constant[value=1]()
  %5476 : Tensor = aten::t(%self.blocks.8.mlp.0.weight.1)
  %5477 : Tensor = aten::matmul(%5075, %5476)
  %5478 : Tensor = trt::const(%self.blocks.8.mlp.0.bias.1)
  %5479 : Tensor = aten::add(%5478, %5477, %5475)
  %5077 : Tensor = aten::mul(%5479, %15) # gptadv_static.py:26:15
  %5078 : Tensor = aten::div(%5479, %16) # gptadv_static.py:26:42
  %5079 : Tensor = aten::erf(%5078) # gptadv_static.py:26:32
  %5080 : Tensor = aten::add(%5079, %14, %17) # <string>:5:9
  %input.60 : Tensor = aten::mul(%5077, %5080) # gptadv_static.py:26:15
  %5480 : int = prim::Constant[value=1]()
  %5481 : Tensor = aten::t(%self.blocks.8.mlp.2.weight.1)
  %5482 : Tensor = aten::matmul(%input.60, %5481)
  %5483 : Tensor = trt::const(%self.blocks.8.mlp.2.bias.1)
  %5484 : Tensor = aten::add(%5483, %5482, %5480)
  %x.37 : Tensor = aten::add(%x.50, %5484, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:163:12
  %x_.20 : Tensor = aten::layer_norm(%x.37, %9, %self.blocks.9.ln_1.weight.1, %self.blocks.9.ln_1.bias.1, %11, %10) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2515:11
  %5485 : int = prim::Constant[value=1]()
  %5486 : Tensor = aten::t(%self.blocks.9.attention.c_attn.weight)
  %5487 : Tensor = aten::matmul(%x_.20, %5486)
  %5488 : Tensor = trt::const(%self.blocks.0.attention.c_attn.bias)
  %5489 : Tensor = aten::add(%5488, %5487, %5485)
  %487 : Tensor[] = aten::split(%5489, %self.blocks.0.attention.n_embd, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:119:19
  %q.60 : Tensor, %k.60 : Tensor, %v.60 : Tensor = prim::ListUnpack(%487)
  %491 : Tensor[] = prim::ListConstruct(%8, %k.60)
  %493 : Tensor[] = prim::ListConstruct(%8, %q.60)
  %495 : Tensor[] = prim::ListConstruct(%8, %v.60)
  %k.62 : Tensor = aten::cat(%491, %19) # gptadv_static.py:54:12
  %5291 : Tensor = aten::reshape(%k.62, %7)
  %q.62 : Tensor = aten::cat(%493, %19) # gptadv_static.py:55:12
  %5292 : Tensor = aten::reshape(%q.62, %7)
  %v.62 : Tensor = aten::cat(%495, %19) # gptadv_static.py:56:12
  %5293 : Tensor = aten::reshape(%v.62, %7)
  %k.64 : Tensor = aten::transpose(%5291, %19, %17) # gptadv_static.py:58:12
  %q.64 : Tensor = aten::transpose(%5292, %19, %17) # gptadv_static.py:59:12
  %v.64 : Tensor = aten::transpose(%5293, %19, %17) # gptadv_static.py:60:12
  %5119 : Tensor = aten::transpose(%k.64, %12, %18) # gptadv_static.py:62:19
  %5120 : Tensor = aten::matmul(%q.64, %5119) # gptadv_static.py:62:15
  %att.20 : Tensor = aten::mul(%5120, %6) # gptadv_static.py:62:15
  %ret.20 : Tensor = aten::softmax(%att.20, %18, %20) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1843:14
  %y.39 : Tensor = aten::matmul(%ret.20, %v.64) # gptadv_static.py:66:12
  %5124 : Tensor = aten::transpose(%y.39, %17, %13) # gptadv_static.py:67:12
  %5294 : Tensor = aten::reshape(%5124, %5)
  %5490 : int = prim::Constant[value=1]()
  %5491 : Tensor = aten::t(%self.blocks.9.attention.c_proj.weight.1)
  %5492 : Tensor = aten::matmul(%5294, %5491)
  %5493 : Tensor = trt::const(%self.blocks.0.attention.c_proj.bias.1)
  %5494 : Tensor = aten::add(%5493, %5492, %5490)
  %x.54 : Tensor = aten::add(%x.37, %5494, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:162:12
  %5129 : Tensor = aten::layer_norm(%x.54, %9, %self.blocks.9.ln_2.weight.1, %self.blocks.9.ln_2.bias.1, %11, %10) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2515:11
  %5495 : int = prim::Constant[value=1]()
  %5496 : Tensor = aten::t(%self.blocks.9.mlp.0.weight.1)
  %5497 : Tensor = aten::matmul(%5129, %5496)
  %5498 : Tensor = trt::const(%self.blocks.9.mlp.0.bias.1)
  %5499 : Tensor = aten::add(%5498, %5497, %5495)
  %5131 : Tensor = aten::mul(%5499, %15) # gptadv_static.py:26:15
  %5132 : Tensor = aten::div(%5499, %16) # gptadv_static.py:26:42
  %5133 : Tensor = aten::erf(%5132) # gptadv_static.py:26:32
  %5134 : Tensor = aten::add(%5133, %14, %17) # <string>:5:9
  %input.66 : Tensor = aten::mul(%5131, %5134) # gptadv_static.py:26:15
  %5500 : int = prim::Constant[value=1]()
  %5501 : Tensor = aten::t(%self.blocks.9.mlp.2.weight.1)
  %5502 : Tensor = aten::matmul(%input.66, %5501)
  %5503 : Tensor = trt::const(%self.blocks.9.mlp.2.bias.1)
  %5504 : Tensor = aten::add(%5503, %5502, %5500)
  %x.41 : Tensor = aten::add(%x.54, %5504, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:163:12
  %x_.22 : Tensor = aten::layer_norm(%x.41, %9, %self.blocks.10.ln_1.weight.1, %self.blocks.10.ln_1.bias.1, %11, %10) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2515:11
  %5505 : int = prim::Constant[value=1]()
  %5506 : Tensor = aten::t(%self.blocks.10.attention.c_attn.weight)
  %5507 : Tensor = aten::matmul(%x_.22, %5506)
  %5508 : Tensor = trt::const(%self.blocks.0.attention.c_attn.bias)
  %5509 : Tensor = aten::add(%5508, %5507, %5505)
  %524 : Tensor[] = aten::split(%5509, %self.blocks.0.attention.n_embd, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:119:19
  %q.66 : Tensor, %k.66 : Tensor, %v.66 : Tensor = prim::ListUnpack(%524)
  %528 : Tensor[] = prim::ListConstruct(%8, %k.66)
  %530 : Tensor[] = prim::ListConstruct(%8, %q.66)
  %532 : Tensor[] = prim::ListConstruct(%8, %v.66)
  %k.68 : Tensor = aten::cat(%528, %19) # gptadv_static.py:54:12
  %5295 : Tensor = aten::reshape(%k.68, %7)
  %q.68 : Tensor = aten::cat(%530, %19) # gptadv_static.py:55:12
  %5296 : Tensor = aten::reshape(%q.68, %7)
  %v.68 : Tensor = aten::cat(%532, %19) # gptadv_static.py:56:12
  %5297 : Tensor = aten::reshape(%v.68, %7)
  %k.70 : Tensor = aten::transpose(%5295, %19, %17) # gptadv_static.py:58:12
  %q.70 : Tensor = aten::transpose(%5296, %19, %17) # gptadv_static.py:59:12
  %v.70 : Tensor = aten::transpose(%5297, %19, %17) # gptadv_static.py:60:12
  %5173 : Tensor = aten::transpose(%k.70, %12, %18) # gptadv_static.py:62:19
  %5174 : Tensor = aten::matmul(%q.70, %5173) # gptadv_static.py:62:15
  %att.22 : Tensor = aten::mul(%5174, %6) # gptadv_static.py:62:15
  %ret.22 : Tensor = aten::softmax(%att.22, %18, %20) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1843:14
  %y.43 : Tensor = aten::matmul(%ret.22, %v.70) # gptadv_static.py:66:12
  %5178 : Tensor = aten::transpose(%y.43, %17, %13) # gptadv_static.py:67:12
  %5298 : Tensor = aten::reshape(%5178, %5)
  %5510 : int = prim::Constant[value=1]()
  %5511 : Tensor = aten::t(%self.blocks.10.attention.c_proj.weight.1)
  %5512 : Tensor = aten::matmul(%5298, %5511)
  %5513 : Tensor = trt::const(%self.blocks.0.attention.c_proj.bias.1)
  %5514 : Tensor = aten::add(%5513, %5512, %5510)
  %x.58 : Tensor = aten::add(%x.41, %5514, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:162:12
  %5183 : Tensor = aten::layer_norm(%x.58, %9, %self.blocks.10.ln_2.weight.1, %self.blocks.10.ln_2.bias.1, %11, %10) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2515:11
  %5515 : int = prim::Constant[value=1]()
  %5516 : Tensor = aten::t(%self.blocks.10.mlp.0.weight.1)
  %5517 : Tensor = aten::matmul(%5183, %5516)
  %5518 : Tensor = trt::const(%self.blocks.10.mlp.0.bias.1)
  %5519 : Tensor = aten::add(%5518, %5517, %5515)
  %5185 : Tensor = aten::mul(%5519, %15) # gptadv_static.py:26:15
  %5186 : Tensor = aten::div(%5519, %16) # gptadv_static.py:26:42
  %5187 : Tensor = aten::erf(%5186) # gptadv_static.py:26:32
  %5188 : Tensor = aten::add(%5187, %14, %17) # <string>:5:9
  %input.72 : Tensor = aten::mul(%5185, %5188) # gptadv_static.py:26:15
  %5520 : int = prim::Constant[value=1]()
  %5521 : Tensor = aten::t(%self.blocks.10.mlp.2.weight.1)
  %5522 : Tensor = aten::matmul(%input.72, %5521)
  %5523 : Tensor = trt::const(%self.blocks.10.mlp.2.bias.1)
  %5524 : Tensor = aten::add(%5523, %5522, %5520)
  %x.45 : Tensor = aten::add(%x.58, %5524, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:163:12
  %x_.1 : Tensor = aten::layer_norm(%x.45, %9, %self.blocks.11.ln_1.weight.1, %self.blocks.11.ln_1.bias.1, %11, %10) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2515:11
  %5525 : int = prim::Constant[value=1]()
  %5526 : Tensor = aten::t(%self.blocks.11.attention.c_attn.weight)
  %5527 : Tensor = aten::matmul(%x_.1, %5526)
  %5528 : Tensor = trt::const(%self.blocks.0.attention.c_attn.bias)
  %5529 : Tensor = aten::add(%5528, %5527, %5525)
  %561 : Tensor[] = aten::split(%5529, %self.blocks.0.attention.n_embd, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:119:19
  %q.1 : Tensor, %k.1 : Tensor, %v.1 : Tensor = prim::ListUnpack(%561)
  %565 : Tensor[] = prim::ListConstruct(%8, %k.1)
  %567 : Tensor[] = prim::ListConstruct(%8, %q.1)
  %569 : Tensor[] = prim::ListConstruct(%8, %v.1)
  %k.5 : Tensor = aten::cat(%565, %19) # gptadv_static.py:54:12
  %5299 : Tensor = aten::reshape(%k.5, %7)
  %q.5 : Tensor = aten::cat(%567, %19) # gptadv_static.py:55:12
  %5300 : Tensor = aten::reshape(%q.5, %7)
  %v.5 : Tensor = aten::cat(%569, %19) # gptadv_static.py:56:12
  %5301 : Tensor = aten::reshape(%v.5, %7)
  %k.9 : Tensor = aten::transpose(%5299, %19, %17) # gptadv_static.py:58:12
  %q.9 : Tensor = aten::transpose(%5300, %19, %17) # gptadv_static.py:59:12
  %v.9 : Tensor = aten::transpose(%5301, %19, %17) # gptadv_static.py:60:12
  %5229 : Tensor = aten::transpose(%k.9, %12, %18) # gptadv_static.py:62:19
  %5230 : Tensor = aten::matmul(%q.9, %5229) # gptadv_static.py:62:15
  %att.1 : Tensor = aten::mul(%5230, %6) # gptadv_static.py:62:15
  %ret.26 : Tensor = aten::softmax(%att.1, %18, %20) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1843:14
  %y.1 : Tensor = aten::matmul(%ret.26, %v.9) # gptadv_static.py:66:12
  %5234 : Tensor = aten::transpose(%y.1, %17, %13) # gptadv_static.py:67:12
  %5302 : Tensor = aten::reshape(%5234, %5)
  %5530 : int = prim::Constant[value=1]()
  %5531 : Tensor = aten::t(%self.blocks.11.attention.c_proj.weight.1)
  %5532 : Tensor = aten::matmul(%5302, %5531)
  %5533 : Tensor = trt::const(%self.blocks.0.attention.c_proj.bias.1)
  %5534 : Tensor = aten::add(%5533, %5532, %5530)
  %x.7 : Tensor = aten::add(%x.45, %5534, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:162:12
  %5239 : Tensor = aten::layer_norm(%x.7, %9, %self.blocks.11.ln_2.weight.1, %self.blocks.11.ln_2.bias.1, %11, %10) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2515:11
  %5535 : int = prim::Constant[value=1]()
  %5536 : Tensor = aten::t(%self.blocks.11.mlp.0.weight.1)
  %5537 : Tensor = aten::matmul(%5239, %5536)
  %5538 : Tensor = trt::const(%self.blocks.11.mlp.0.bias.1)
  %5539 : Tensor = aten::add(%5538, %5537, %5535)
  %5241 : Tensor = aten::mul(%5539, %15) # gptadv_static.py:26:15
  %5242 : Tensor = aten::div(%5539, %16) # gptadv_static.py:26:42
  %5243 : Tensor = aten::erf(%5242) # gptadv_static.py:26:32
  %5244 : Tensor = aten::add(%5243, %14, %17) # <string>:5:9
  %input.9 : Tensor = aten::mul(%5241, %5244) # gptadv_static.py:26:15
  %5540 : int = prim::Constant[value=1]()
  %5541 : Tensor = aten::t(%self.blocks.11.mlp.2.weight.1)
  %5542 : Tensor = aten::matmul(%input.9, %5541)
  %5543 : Tensor = trt::const(%self.blocks.11.mlp.2.bias.1)
  %5544 : Tensor = aten::add(%5543, %5542, %5540)
  %x.49 : Tensor = aten::add(%x.7, %5544, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:163:12
  %x.53 : Tensor = aten::layer_norm(%x.49, %9, %self.ln.weight.1, %self.ln.bias.1, %11, %10) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2515:11
  %5545 : Tensor = aten::t(%self.token_emb.weight.1) # <string>:3:35
  %5546 : Tensor = aten::matmul(%x.53, %5545) # <string>:3:16
  %5250 : Tensor = aten::select(%5546, %19, %18) # gptadv_static.py:237:20
  %5303 : Tensor = aten::reshape(%5250, %4)
  %ret.1 : Tensor = aten::softmax(%5303, %17, %20) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1843:14
  %new_token_idx.1 : Tensor = aten::argmax(%ret.1, %17, %21) # gptadv_static.py:241:24
  %5304 : Tensor = aten::reshape(%new_token_idx.1, %3)
  return (%5304)

DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.token_emb.weight.1 : Float(50257, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.pos_emb.weight.1 : Float(1024, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.0.ln_1.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.0.ln_1.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.0.attention.c_attn.weight : Float(2304, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.0.attention.c_attn.bias : Float(2304, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.0.attention.n_embd : int = prim::Constant[value=768]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.0.attention.c_proj.weight.1 : Float(768, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.0.attention.c_proj.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.0.ln_2.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.0.ln_2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.0.mlp.0.weight.1 : Float(3072, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.0.mlp.0.bias.1 : Float(3072, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.0.mlp.2.weight.1 : Float(768, 3072, strides=[3072, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.0.mlp.2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.1.ln_1.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.1.ln_1.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.1.attention.c_attn.weight : Float(2304, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.1.attention.c_proj.weight.1 : Float(768, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.1.ln_2.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.1.ln_2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.1.mlp.0.weight.1 : Float(3072, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.1.mlp.0.bias.1 : Float(3072, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.1.mlp.2.weight.1 : Float(768, 3072, strides=[3072, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.1.mlp.2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.2.ln_1.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.2.ln_1.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.2.attention.c_attn.weight : Float(2304, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.2.attention.c_proj.weight.1 : Float(768, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.2.ln_2.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.2.ln_2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.2.mlp.0.weight.1 : Float(3072, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.2.mlp.0.bias.1 : Float(3072, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.2.mlp.2.weight.1 : Float(768, 3072, strides=[3072, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.2.mlp.2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.3.ln_1.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.3.ln_1.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.3.attention.c_attn.weight : Float(2304, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.3.attention.c_proj.weight.1 : Float(768, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.3.ln_2.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.3.ln_2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.3.mlp.0.weight.1 : Float(3072, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.3.mlp.0.bias.1 : Float(3072, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.3.mlp.2.weight.1 : Float(768, 3072, strides=[3072, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.3.mlp.2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.4.ln_1.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.4.ln_1.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.4.attention.c_attn.weight : Float(2304, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.4.attention.c_proj.weight.1 : Float(768, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.4.ln_2.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.4.ln_2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.4.mlp.0.weight.1 : Float(3072, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.4.mlp.0.bias.1 : Float(3072, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.4.mlp.2.weight.1 : Float(768, 3072, strides=[3072, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.4.mlp.2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.5.ln_1.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.5.ln_1.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.5.attention.c_attn.weight : Float(2304, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.5.attention.c_proj.weight.1 : Float(768, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.5.ln_2.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.5.ln_2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.5.mlp.0.weight.1 : Float(3072, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.5.mlp.0.bias.1 : Float(3072, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.5.mlp.2.weight.1 : Float(768, 3072, strides=[3072, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.5.mlp.2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.6.ln_1.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.6.ln_1.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.6.attention.c_attn.weight : Float(2304, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.6.attention.c_proj.weight.1 : Float(768, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.6.ln_2.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.6.ln_2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.6.mlp.0.weight.1 : Float(3072, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.6.mlp.0.bias.1 : Float(3072, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.6.mlp.2.weight.1 : Float(768, 3072, strides=[3072, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.6.mlp.2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.7.ln_1.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.7.ln_1.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.7.attention.c_attn.weight : Float(2304, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.7.attention.c_proj.weight.1 : Float(768, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.7.ln_2.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.7.ln_2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.7.mlp.0.weight.1 : Float(3072, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.7.mlp.0.bias.1 : Float(3072, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.7.mlp.2.weight.1 : Float(768, 3072, strides=[3072, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.7.mlp.2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.8.ln_1.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.8.ln_1.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.8.attention.c_attn.weight : Float(2304, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.8.attention.c_proj.weight.1 : Float(768, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.8.ln_2.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.8.ln_2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.8.mlp.0.weight.1 : Float(3072, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.8.mlp.0.bias.1 : Float(3072, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.8.mlp.2.weight.1 : Float(768, 3072, strides=[3072, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.8.mlp.2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.9.ln_1.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.9.ln_1.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.9.attention.c_attn.weight : Float(2304, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.9.attention.c_proj.weight.1 : Float(768, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.9.ln_2.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.9.ln_2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.9.mlp.0.weight.1 : Float(3072, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.9.mlp.0.bias.1 : Float(3072, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.9.mlp.2.weight.1 : Float(768, 3072, strides=[3072, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.9.mlp.2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.10.ln_1.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.10.ln_1.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.10.attention.c_attn.weight : Float(2304, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.10.attention.c_proj.weight.1 : Float(768, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.10.ln_2.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.10.ln_2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.10.mlp.0.weight.1 : Float(3072, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.10.mlp.0.bias.1 : Float(3072, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.10.mlp.2.weight.1 : Float(768, 3072, strides=[3072, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.10.mlp.2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.11.ln_1.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.11.ln_1.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.11.attention.c_attn.weight : Float(2304, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.11.attention.c_proj.weight.1 : Float(768, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.11.ln_2.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.11.ln_2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.11.mlp.0.weight.1 : Float(3072, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.11.mlp.0.bias.1 : Float(3072, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.11.mlp.2.weight.1 : Float(768, 3072, strides=[3072, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.11.mlp.2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.ln.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.ln.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %21 : bool = prim::Constant[value=0]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %20 : NoneType = prim::Constant() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %19 : int = prim::Constant[value=0]() # gptadv_static.py:237:20 (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %18 : int = prim::Constant[value=-1]() # gptadv_static.py:237:27 (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %17 : int = prim::Constant[value=1]() # gptadv_static.py:231:8 (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %16 : float = prim::Constant[value=1.41421]() # gptadv_static.py:26:46 (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %15 : float = prim::Constant[value=0.5]() # gptadv_static.py:26:19 (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %14 : float = prim::Constant[value=1.]() # gptadv_static.py:62:43 (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %13 : int = prim::Constant[value=2]() # gptadv_static.py:62:32 (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %12 : int = prim::Constant[value=-2]() # gptadv_static.py:62:31 (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %11 : float = prim::Constant[value=1.0000000000000001e-05]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/normalization.py:191:66 (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %10 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2515:72 (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %9 : int[] = prim::Constant[value=[768]]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %8 : Float(32, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %7 : int[] = prim::Constant[value=[-1, 12, 64]]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %6 : float = prim::Constant[value=0.125]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %5 : int[] = prim::Constant[value=[-1, 768]]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %4 : int[] = prim::Constant[value=[-1, 50257]]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %3 : int[] = prim::Constant[value=[-1, 1]]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %5305 : int = prim::Constant[value=1]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %q.2 : Tensor, %k.2 : Tensor, %v.2 : Tensor = prim::ListUnpack(%154) (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %158 : Tensor[] = prim::ListConstruct(%8, %k.2) (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %160 : Tensor[] = prim::ListConstruct(%8, %q.2) (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %162 : Tensor[] = prim::ListConstruct(%8, %v.2) (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %5310 : int = prim::Constant[value=1]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %5315 : int = prim::Constant[value=1]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %5320 : int = prim::Constant[value=1]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %5325 : int = prim::Constant[value=1]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %q.12 : Tensor, %k.12 : Tensor, %v.12 : Tensor = prim::ListUnpack(%191) (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %195 : Tensor[] = prim::ListConstruct(%8, %k.12) (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %197 : Tensor[] = prim::ListConstruct(%8, %q.12) (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %199 : Tensor[] = prim::ListConstruct(%8, %v.12) (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %5330 : int = prim::Constant[value=1]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %5335 : int = prim::Constant[value=1]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %5340 : int = prim::Constant[value=1]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %5345 : int = prim::Constant[value=1]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %q.18 : Tensor, %k.18 : Tensor, %v.18 : Tensor = prim::ListUnpack(%228) (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %232 : Tensor[] = prim::ListConstruct(%8, %k.18) (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %234 : Tensor[] = prim::ListConstruct(%8, %q.18) (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %236 : Tensor[] = prim::ListConstruct(%8, %v.18) (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %5350 : int = prim::Constant[value=1]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %5355 : int = prim::Constant[value=1]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %5360 : int = prim::Constant[value=1]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %5365 : int = prim::Constant[value=1]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %q.24 : Tensor, %k.24 : Tensor, %v.24 : Tensor = prim::ListUnpack(%265) (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %269 : Tensor[] = prim::ListConstruct(%8, %k.24) (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %271 : Tensor[] = prim::ListConstruct(%8, %q.24) (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %273 : Tensor[] = prim::ListConstruct(%8, %v.24) (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %5370 : int = prim::Constant[value=1]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %5375 : int = prim::Constant[value=1]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %5380 : int = prim::Constant[value=1]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %5385 : int = prim::Constant[value=1]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %q.30 : Tensor, %k.30 : Tensor, %v.30 : Tensor = prim::ListUnpack(%302) (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %306 : Tensor[] = prim::ListConstruct(%8, %k.30) (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %308 : Tensor[] = prim::ListConstruct(%8, %q.30) (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %310 : Tensor[] = prim::ListConstruct(%8, %v.30) (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %5390 : int = prim::Constant[value=1]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %5395 : int = prim::Constant[value=1]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %5400 : int = prim::Constant[value=1]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %5405 : int = prim::Constant[value=1]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %q.36 : Tensor, %k.36 : Tensor, %v.36 : Tensor = prim::ListUnpack(%339) (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %343 : Tensor[] = prim::ListConstruct(%8, %k.36) (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %345 : Tensor[] = prim::ListConstruct(%8, %q.36) (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %347 : Tensor[] = prim::ListConstruct(%8, %v.36) (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %5410 : int = prim::Constant[value=1]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %5415 : int = prim::Constant[value=1]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %5420 : int = prim::Constant[value=1]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %5425 : int = prim::Constant[value=1]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %q.42 : Tensor, %k.42 : Tensor, %v.42 : Tensor = prim::ListUnpack(%376) (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %380 : Tensor[] = prim::ListConstruct(%8, %k.42) (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %382 : Tensor[] = prim::ListConstruct(%8, %q.42) (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %384 : Tensor[] = prim::ListConstruct(%8, %v.42) (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %5430 : int = prim::Constant[value=1]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %5435 : int = prim::Constant[value=1]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %5440 : int = prim::Constant[value=1]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %5445 : int = prim::Constant[value=1]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %q.48 : Tensor, %k.48 : Tensor, %v.48 : Tensor = prim::ListUnpack(%413) (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %417 : Tensor[] = prim::ListConstruct(%8, %k.48) (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %419 : Tensor[] = prim::ListConstruct(%8, %q.48) (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %421 : Tensor[] = prim::ListConstruct(%8, %v.48) (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %5450 : int = prim::Constant[value=1]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %5455 : int = prim::Constant[value=1]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %5460 : int = prim::Constant[value=1]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %5465 : int = prim::Constant[value=1]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %q.54 : Tensor, %k.54 : Tensor, %v.54 : Tensor = prim::ListUnpack(%450) (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %454 : Tensor[] = prim::ListConstruct(%8, %k.54) (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %456 : Tensor[] = prim::ListConstruct(%8, %q.54) (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %458 : Tensor[] = prim::ListConstruct(%8, %v.54) (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %5470 : int = prim::Constant[value=1]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %5475 : int = prim::Constant[value=1]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %5480 : int = prim::Constant[value=1]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %5485 : int = prim::Constant[value=1]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %q.60 : Tensor, %k.60 : Tensor, %v.60 : Tensor = prim::ListUnpack(%487) (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %491 : Tensor[] = prim::ListConstruct(%8, %k.60) (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %493 : Tensor[] = prim::ListConstruct(%8, %q.60) (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %495 : Tensor[] = prim::ListConstruct(%8, %v.60) (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %5490 : int = prim::Constant[value=1]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %5495 : int = prim::Constant[value=1]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %5500 : int = prim::Constant[value=1]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %5505 : int = prim::Constant[value=1]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %q.66 : Tensor, %k.66 : Tensor, %v.66 : Tensor = prim::ListUnpack(%524) (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %528 : Tensor[] = prim::ListConstruct(%8, %k.66) (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %530 : Tensor[] = prim::ListConstruct(%8, %q.66) (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %532 : Tensor[] = prim::ListConstruct(%8, %v.66) (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %5510 : int = prim::Constant[value=1]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %5515 : int = prim::Constant[value=1]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %5520 : int = prim::Constant[value=1]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %5525 : int = prim::Constant[value=1]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %q.1 : Tensor, %k.1 : Tensor, %v.1 : Tensor = prim::ListUnpack(%561) (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %565 : Tensor[] = prim::ListConstruct(%8, %k.1) (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %567 : Tensor[] = prim::ListConstruct(%8, %q.1) (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %569 : Tensor[] = prim::ListConstruct(%8, %v.1) (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %5530 : int = prim::Constant[value=1]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %5535 : int = prim::Constant[value=1]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %5540 : int = prim::Constant[value=1]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Found 2 inputs to graph
DEBUG: [Torch-TensorRT] - Handle input of debug name: idx.1
DEBUG: [Torch-TensorRT] - Handle input of debug name: pos.1
DEBUG: [Torch-TensorRT] - Paring 0: idx.1 : Input(shape: [-1], min: [1], opt: [8], max: [16], dtype: Int, format: NCHW\Contiguous\Linear)
DEBUG: [Torch-TensorRT] - Paring 1: pos.1 : Input(shape: [-1], min: [1], opt: [8], max: [16], dtype: Int, format: NCHW\Contiguous\Linear)
DEBUG: [Torch-TensorRT] - Found 2 inputs to graph
DEBUG: [Torch-TensorRT] - Handle input of debug name: idx.1
DEBUG: [Torch-TensorRT] - Handle input of debug name: pos.1
DEBUG: [Torch-TensorRT] - In MapInputsAndDetermineDTypes, the g->inputs() size is 2, CollectionInputSpecMap size is2
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.token_emb.weight.1 : Float(50257, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.pos_emb.weight.1 : Float(1024, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.0.ln_1.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.0.ln_1.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.0.attention.c_attn.weight : Float(2304, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.0.attention.c_attn.bias : Float(2304, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.0.attention.n_embd : int = prim::Constant[value=768]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.0.attention.c_proj.weight.1 : Float(768, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.0.attention.c_proj.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.0.ln_2.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.0.ln_2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.0.mlp.0.weight.1 : Float(3072, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.0.mlp.0.bias.1 : Float(3072, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.0.mlp.2.weight.1 : Float(768, 3072, strides=[3072, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.0.mlp.2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.1.ln_1.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.1.ln_1.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.1.attention.c_attn.weight : Float(2304, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.1.attention.c_proj.weight.1 : Float(768, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.1.ln_2.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.1.ln_2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.1.mlp.0.weight.1 : Float(3072, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.1.mlp.0.bias.1 : Float(3072, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.1.mlp.2.weight.1 : Float(768, 3072, strides=[3072, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.1.mlp.2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.2.ln_1.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.2.ln_1.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.2.attention.c_attn.weight : Float(2304, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.2.attention.c_proj.weight.1 : Float(768, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.2.ln_2.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.2.ln_2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.2.mlp.0.weight.1 : Float(3072, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.2.mlp.0.bias.1 : Float(3072, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.2.mlp.2.weight.1 : Float(768, 3072, strides=[3072, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.2.mlp.2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.3.ln_1.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.3.ln_1.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.3.attention.c_attn.weight : Float(2304, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.3.attention.c_proj.weight.1 : Float(768, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.3.ln_2.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.3.ln_2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.3.mlp.0.weight.1 : Float(3072, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.3.mlp.0.bias.1 : Float(3072, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.3.mlp.2.weight.1 : Float(768, 3072, strides=[3072, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.3.mlp.2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.4.ln_1.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.4.ln_1.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.4.attention.c_attn.weight : Float(2304, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.4.attention.c_proj.weight.1 : Float(768, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.4.ln_2.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.4.ln_2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.4.mlp.0.weight.1 : Float(3072, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.4.mlp.0.bias.1 : Float(3072, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.4.mlp.2.weight.1 : Float(768, 3072, strides=[3072, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.4.mlp.2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.5.ln_1.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.5.ln_1.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.5.attention.c_attn.weight : Float(2304, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.5.attention.c_proj.weight.1 : Float(768, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.5.ln_2.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.5.ln_2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.5.mlp.0.weight.1 : Float(3072, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.5.mlp.0.bias.1 : Float(3072, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.5.mlp.2.weight.1 : Float(768, 3072, strides=[3072, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.5.mlp.2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.6.ln_1.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.6.ln_1.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.6.attention.c_attn.weight : Float(2304, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.6.attention.c_proj.weight.1 : Float(768, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.6.ln_2.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.6.ln_2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.6.mlp.0.weight.1 : Float(3072, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.6.mlp.0.bias.1 : Float(3072, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.6.mlp.2.weight.1 : Float(768, 3072, strides=[3072, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.6.mlp.2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.7.ln_1.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.7.ln_1.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.7.attention.c_attn.weight : Float(2304, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.7.attention.c_proj.weight.1 : Float(768, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.7.ln_2.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.7.ln_2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.7.mlp.0.weight.1 : Float(3072, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.7.mlp.0.bias.1 : Float(3072, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.7.mlp.2.weight.1 : Float(768, 3072, strides=[3072, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.7.mlp.2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.8.ln_1.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.8.ln_1.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.8.attention.c_attn.weight : Float(2304, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.8.attention.c_proj.weight.1 : Float(768, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.8.ln_2.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.8.ln_2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.8.mlp.0.weight.1 : Float(3072, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.8.mlp.0.bias.1 : Float(3072, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.8.mlp.2.weight.1 : Float(768, 3072, strides=[3072, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.8.mlp.2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.9.ln_1.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.9.ln_1.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.9.attention.c_attn.weight : Float(2304, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.9.attention.c_proj.weight.1 : Float(768, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.9.ln_2.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.9.ln_2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.9.mlp.0.weight.1 : Float(3072, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.9.mlp.0.bias.1 : Float(3072, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.9.mlp.2.weight.1 : Float(768, 3072, strides=[3072, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.9.mlp.2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.10.ln_1.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.10.ln_1.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.10.attention.c_attn.weight : Float(2304, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.10.attention.c_proj.weight.1 : Float(768, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.10.ln_2.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.10.ln_2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.10.mlp.0.weight.1 : Float(3072, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.10.mlp.0.bias.1 : Float(3072, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.10.mlp.2.weight.1 : Float(768, 3072, strides=[3072, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.10.mlp.2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.11.ln_1.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.11.ln_1.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.11.attention.c_attn.weight : Float(2304, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.11.attention.c_proj.weight.1 : Float(768, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.11.ln_2.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.11.ln_2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.11.mlp.0.weight.1 : Float(3072, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.11.mlp.0.bias.1 : Float(3072, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.11.mlp.2.weight.1 : Float(768, 3072, strides=[3072, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.blocks.11.mlp.2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.ln.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %self.ln.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %21 : bool = prim::Constant[value=0]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %20 : NoneType = prim::Constant() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %19 : int = prim::Constant[value=0]() # gptadv_static.py:237:20 (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %18 : int = prim::Constant[value=-1]() # gptadv_static.py:237:27 (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %17 : int = prim::Constant[value=1]() # gptadv_static.py:231:8 (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %16 : float = prim::Constant[value=1.41421]() # gptadv_static.py:26:46 (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %15 : float = prim::Constant[value=0.5]() # gptadv_static.py:26:19 (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %14 : float = prim::Constant[value=1.]() # gptadv_static.py:62:43 (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %13 : int = prim::Constant[value=2]() # gptadv_static.py:62:32 (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %12 : int = prim::Constant[value=-2]() # gptadv_static.py:62:31 (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %11 : float = prim::Constant[value=1.0000000000000001e-05]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/normalization.py:191:66 (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %10 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2515:72 (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %9 : int[] = prim::Constant[value=[768]]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %8 : Float(32, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %7 : int[] = prim::Constant[value=[-1, 12, 64]]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %6 : float = prim::Constant[value=0.125]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %5 : int[] = prim::Constant[value=[-1, 768]]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %4 : int[] = prim::Constant[value=[-1, 50257]]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %3 : int[] = prim::Constant[value=[-1, 1]]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %5305 : int = prim::Constant[value=1]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %q.2 : Tensor, %k.2 : Tensor, %v.2 : Tensor = prim::ListUnpack(%154) (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %158 : Tensor[] = prim::ListConstruct(%8, %k.2) (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %160 : Tensor[] = prim::ListConstruct(%8, %q.2) (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %162 : Tensor[] = prim::ListConstruct(%8, %v.2) (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %5310 : int = prim::Constant[value=1]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %5315 : int = prim::Constant[value=1]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %5320 : int = prim::Constant[value=1]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %5325 : int = prim::Constant[value=1]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %q.12 : Tensor, %k.12 : Tensor, %v.12 : Tensor = prim::ListUnpack(%191) (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %195 : Tensor[] = prim::ListConstruct(%8, %k.12) (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %197 : Tensor[] = prim::ListConstruct(%8, %q.12) (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %199 : Tensor[] = prim::ListConstruct(%8, %v.12) (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %5330 : int = prim::Constant[value=1]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %5335 : int = prim::Constant[value=1]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %5340 : int = prim::Constant[value=1]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %5345 : int = prim::Constant[value=1]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %q.18 : Tensor, %k.18 : Tensor, %v.18 : Tensor = prim::ListUnpack(%228) (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %232 : Tensor[] = prim::ListConstruct(%8, %k.18) (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %234 : Tensor[] = prim::ListConstruct(%8, %q.18) (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %236 : Tensor[] = prim::ListConstruct(%8, %v.18) (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %5350 : int = prim::Constant[value=1]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %5355 : int = prim::Constant[value=1]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %5360 : int = prim::Constant[value=1]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %5365 : int = prim::Constant[value=1]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %q.24 : Tensor, %k.24 : Tensor, %v.24 : Tensor = prim::ListUnpack(%265) (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %269 : Tensor[] = prim::ListConstruct(%8, %k.24) (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %271 : Tensor[] = prim::ListConstruct(%8, %q.24) (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %273 : Tensor[] = prim::ListConstruct(%8, %v.24) (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %5370 : int = prim::Constant[value=1]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %5375 : int = prim::Constant[value=1]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %5380 : int = prim::Constant[value=1]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %5385 : int = prim::Constant[value=1]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %q.30 : Tensor, %k.30 : Tensor, %v.30 : Tensor = prim::ListUnpack(%302) (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %306 : Tensor[] = prim::ListConstruct(%8, %k.30) (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %308 : Tensor[] = prim::ListConstruct(%8, %q.30) (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %310 : Tensor[] = prim::ListConstruct(%8, %v.30) (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %5390 : int = prim::Constant[value=1]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %5395 : int = prim::Constant[value=1]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %5400 : int = prim::Constant[value=1]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %5405 : int = prim::Constant[value=1]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %q.36 : Tensor, %k.36 : Tensor, %v.36 : Tensor = prim::ListUnpack(%339) (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %343 : Tensor[] = prim::ListConstruct(%8, %k.36) (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %345 : Tensor[] = prim::ListConstruct(%8, %q.36) (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %347 : Tensor[] = prim::ListConstruct(%8, %v.36) (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %5410 : int = prim::Constant[value=1]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %5415 : int = prim::Constant[value=1]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %5420 : int = prim::Constant[value=1]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %5425 : int = prim::Constant[value=1]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %q.42 : Tensor, %k.42 : Tensor, %v.42 : Tensor = prim::ListUnpack(%376) (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %380 : Tensor[] = prim::ListConstruct(%8, %k.42) (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %382 : Tensor[] = prim::ListConstruct(%8, %q.42) (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %384 : Tensor[] = prim::ListConstruct(%8, %v.42) (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %5430 : int = prim::Constant[value=1]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %5435 : int = prim::Constant[value=1]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %5440 : int = prim::Constant[value=1]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %5445 : int = prim::Constant[value=1]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %q.48 : Tensor, %k.48 : Tensor, %v.48 : Tensor = prim::ListUnpack(%413) (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %417 : Tensor[] = prim::ListConstruct(%8, %k.48) (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %419 : Tensor[] = prim::ListConstruct(%8, %q.48) (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %421 : Tensor[] = prim::ListConstruct(%8, %v.48) (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %5450 : int = prim::Constant[value=1]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %5455 : int = prim::Constant[value=1]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %5460 : int = prim::Constant[value=1]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %5465 : int = prim::Constant[value=1]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %q.54 : Tensor, %k.54 : Tensor, %v.54 : Tensor = prim::ListUnpack(%450) (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %454 : Tensor[] = prim::ListConstruct(%8, %k.54) (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %456 : Tensor[] = prim::ListConstruct(%8, %q.54) (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %458 : Tensor[] = prim::ListConstruct(%8, %v.54) (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %5470 : int = prim::Constant[value=1]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %5475 : int = prim::Constant[value=1]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %5480 : int = prim::Constant[value=1]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %5485 : int = prim::Constant[value=1]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %q.60 : Tensor, %k.60 : Tensor, %v.60 : Tensor = prim::ListUnpack(%487) (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %491 : Tensor[] = prim::ListConstruct(%8, %k.60) (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %493 : Tensor[] = prim::ListConstruct(%8, %q.60) (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %495 : Tensor[] = prim::ListConstruct(%8, %v.60) (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %5490 : int = prim::Constant[value=1]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %5495 : int = prim::Constant[value=1]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %5500 : int = prim::Constant[value=1]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %5505 : int = prim::Constant[value=1]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %q.66 : Tensor, %k.66 : Tensor, %v.66 : Tensor = prim::ListUnpack(%524) (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %528 : Tensor[] = prim::ListConstruct(%8, %k.66) (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %530 : Tensor[] = prim::ListConstruct(%8, %q.66) (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %532 : Tensor[] = prim::ListConstruct(%8, %v.66) (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %5510 : int = prim::Constant[value=1]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %5515 : int = prim::Constant[value=1]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %5520 : int = prim::Constant[value=1]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %5525 : int = prim::Constant[value=1]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %q.1 : Tensor, %k.1 : Tensor, %v.1 : Tensor = prim::ListUnpack(%561) (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %565 : Tensor[] = prim::ListConstruct(%8, %k.1) (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %567 : Tensor[] = prim::ListConstruct(%8, %q.1) (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %569 : Tensor[] = prim::ListConstruct(%8, %v.1) (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %5530 : int = prim::Constant[value=1]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %5535 : int = prim::Constant[value=1]() (NodeConverterRegistry.Convertable)
DEBUG: [Torch-TensorRT] - Unable to get schema for Node %5540 : int = prim::Constant[value=1]() (NodeConverterRegistry.Convertable)
INFO: [Torch-TensorRT TorchScript Conversion Context] - [MemUsageChange] Init CUDA: CPU +2, GPU +0, now: CPU 1128, GPU 936 (MiB)
INFO: [Torch-TensorRT TorchScript Conversion Context] - [MemUsageChange] Init builder kernel library: CPU +262, GPU +76, now: CPU 1442, GPU 1012 (MiB)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - CUDA lazy loading is enabled.
INFO: [Torch-TensorRT] - Settings requested for TensorRT engine:
    Enabled Precisions: Float32 
    TF32 Floating Point Computation Enabled: 1
    Truncate Long and Double: 0
    Make Refittable Engine: 0
    Debuggable Engine: 0
    GPU ID: 0
    Allow GPU Fallback (if running on DLA): 0
    Avg Timing Iterations: 1
    Max Workspace Size: 8589934592
    DLA SRAM Size: 1048576
    DLA Local DRAM Size: 1073741824
    DLA Global DRAM Size: 536870912
    Device Type: GPU
    GPU ID: 0
    Engine Capability: standard
    Calibrator Created: 0
INFO: [Torch-TensorRT TorchScript Conversion Context] - Converting Block
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - graph(%idx.1 : Tensor,
      %pos.1 : Tensor):
  %self.token_emb.weight.1 : Float(50257, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.pos_emb.weight.1 : Float(1024, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.0.ln_1.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.0.ln_1.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.0.attention.c_attn.weight : Float(2304, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.0.attention.c_attn.bias : Float(2304, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.0.attention.n_embd : int = prim::Constant[value=768]()
  %self.blocks.0.attention.c_proj.weight.1 : Float(768, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.0.attention.c_proj.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.0.ln_2.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.0.ln_2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.0.mlp.0.weight.1 : Float(3072, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.0.mlp.0.bias.1 : Float(3072, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.0.mlp.2.weight.1 : Float(768, 3072, strides=[3072, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.0.mlp.2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.1.ln_1.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.1.ln_1.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.1.attention.c_attn.weight : Float(2304, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.1.attention.c_proj.weight.1 : Float(768, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.1.ln_2.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.1.ln_2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.1.mlp.0.weight.1 : Float(3072, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.1.mlp.0.bias.1 : Float(3072, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.1.mlp.2.weight.1 : Float(768, 3072, strides=[3072, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.1.mlp.2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.2.ln_1.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.2.ln_1.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.2.attention.c_attn.weight : Float(2304, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.2.attention.c_proj.weight.1 : Float(768, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.2.ln_2.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.2.ln_2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.2.mlp.0.weight.1 : Float(3072, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.2.mlp.0.bias.1 : Float(3072, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.2.mlp.2.weight.1 : Float(768, 3072, strides=[3072, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.2.mlp.2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.3.ln_1.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.3.ln_1.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.3.attention.c_attn.weight : Float(2304, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.3.attention.c_proj.weight.1 : Float(768, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.3.ln_2.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.3.ln_2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.3.mlp.0.weight.1 : Float(3072, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.3.mlp.0.bias.1 : Float(3072, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.3.mlp.2.weight.1 : Float(768, 3072, strides=[3072, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.3.mlp.2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.4.ln_1.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.4.ln_1.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.4.attention.c_attn.weight : Float(2304, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.4.attention.c_proj.weight.1 : Float(768, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.4.ln_2.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.4.ln_2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.4.mlp.0.weight.1 : Float(3072, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.4.mlp.0.bias.1 : Float(3072, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.4.mlp.2.weight.1 : Float(768, 3072, strides=[3072, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.4.mlp.2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.5.ln_1.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.5.ln_1.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.5.attention.c_attn.weight : Float(2304, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.5.attention.c_proj.weight.1 : Float(768, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.5.ln_2.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.5.ln_2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.5.mlp.0.weight.1 : Float(3072, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.5.mlp.0.bias.1 : Float(3072, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.5.mlp.2.weight.1 : Float(768, 3072, strides=[3072, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.5.mlp.2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.6.ln_1.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.6.ln_1.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.6.attention.c_attn.weight : Float(2304, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.6.attention.c_proj.weight.1 : Float(768, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.6.ln_2.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.6.ln_2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.6.mlp.0.weight.1 : Float(3072, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.6.mlp.0.bias.1 : Float(3072, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.6.mlp.2.weight.1 : Float(768, 3072, strides=[3072, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.6.mlp.2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.7.ln_1.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.7.ln_1.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.7.attention.c_attn.weight : Float(2304, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.7.attention.c_proj.weight.1 : Float(768, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.7.ln_2.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.7.ln_2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.7.mlp.0.weight.1 : Float(3072, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.7.mlp.0.bias.1 : Float(3072, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.7.mlp.2.weight.1 : Float(768, 3072, strides=[3072, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.7.mlp.2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.8.ln_1.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.8.ln_1.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.8.attention.c_attn.weight : Float(2304, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.8.attention.c_proj.weight.1 : Float(768, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.8.ln_2.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.8.ln_2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.8.mlp.0.weight.1 : Float(3072, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.8.mlp.0.bias.1 : Float(3072, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.8.mlp.2.weight.1 : Float(768, 3072, strides=[3072, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.8.mlp.2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.9.ln_1.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.9.ln_1.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.9.attention.c_attn.weight : Float(2304, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.9.attention.c_proj.weight.1 : Float(768, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.9.ln_2.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.9.ln_2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.9.mlp.0.weight.1 : Float(3072, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.9.mlp.0.bias.1 : Float(3072, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.9.mlp.2.weight.1 : Float(768, 3072, strides=[3072, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.9.mlp.2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.10.ln_1.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.10.ln_1.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.10.attention.c_attn.weight : Float(2304, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.10.attention.c_proj.weight.1 : Float(768, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.10.ln_2.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.10.ln_2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.10.mlp.0.weight.1 : Float(3072, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.10.mlp.0.bias.1 : Float(3072, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.10.mlp.2.weight.1 : Float(768, 3072, strides=[3072, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.10.mlp.2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.11.ln_1.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.11.ln_1.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.11.attention.c_attn.weight : Float(2304, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.11.attention.c_proj.weight.1 : Float(768, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.11.ln_2.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.11.ln_2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.11.mlp.0.weight.1 : Float(3072, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.11.mlp.0.bias.1 : Float(3072, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.11.mlp.2.weight.1 : Float(768, 3072, strides=[3072, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.blocks.11.mlp.2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.ln.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %self.ln.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %21 : bool = prim::Constant[value=0]()
  %20 : NoneType = prim::Constant()
  %19 : int = prim::Constant[value=0]() # gptadv_static.py:237:20
  %18 : int = prim::Constant[value=-1]() # gptadv_static.py:237:27
  %17 : int = prim::Constant[value=1]() # gptadv_static.py:231:8
  %16 : float = prim::Constant[value=1.41421]() # gptadv_static.py:26:46
  %15 : float = prim::Constant[value=0.5]() # gptadv_static.py:26:19
  %14 : float = prim::Constant[value=1.]() # gptadv_static.py:62:43
  %13 : int = prim::Constant[value=2]() # gptadv_static.py:62:32
  %12 : int = prim::Constant[value=-2]() # gptadv_static.py:62:31
  %11 : float = prim::Constant[value=1.0000000000000001e-05]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/normalization.py:191:66
  %10 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2515:72
  %9 : int[] = prim::Constant[value=[768]]()
  %8 : Float(32, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
  %7 : int[] = prim::Constant[value=[-1, 12, 64]]()
  %6 : float = prim::Constant[value=0.125]()
  %5 : int[] = prim::Constant[value=[-1, 768]]()
  %4 : int[] = prim::Constant[value=[-1, 50257]]()
  %3 : int[] = prim::Constant[value=[-1, 1]]()
  %token_emb.3 : Tensor = aten::embedding(%self.token_emb.weight.1, %idx.1, %18, %21, %21) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2210:11
  %pos_emb.3 : Tensor = aten::embedding(%self.pos_emb.weight.1, %pos.1, %18, %21, %21) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2210:11
  %x.1 : Tensor = aten::add(%token_emb.3, %pos_emb.3, %17) # gptadv_static.py:227:12
  %x_.2 : Tensor = aten::layer_norm(%x.1, %9, %self.blocks.0.ln_1.weight.1, %self.blocks.0.ln_1.bias.1, %11, %10) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2515:11
  %5305 : int = prim::Constant[value=1]()
  %5306 : Tensor = aten::t(%self.blocks.0.attention.c_attn.weight)
  %5307 : Tensor = aten::matmul(%x_.2, %5306)
  %5308 : Tensor = trt::const(%self.blocks.0.attention.c_attn.bias)
  %5309 : Tensor = aten::add(%5308, %5307, %5305)
  %154 : Tensor[] = aten::split(%5309, %self.blocks.0.attention.n_embd, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:119:19
  %q.2 : Tensor, %k.2 : Tensor, %v.2 : Tensor = prim::ListUnpack(%154)
  %158 : Tensor[] = prim::ListConstruct(%8, %k.2)
  %160 : Tensor[] = prim::ListConstruct(%8, %q.2)
  %162 : Tensor[] = prim::ListConstruct(%8, %v.2)
  %k.6 : Tensor = aten::cat(%158, %19) # gptadv_static.py:54:12
  %5255 : Tensor = aten::reshape(%k.6, %7)
  %q.6 : Tensor = aten::cat(%160, %19) # gptadv_static.py:55:12
  %5256 : Tensor = aten::reshape(%q.6, %7)
  %v.6 : Tensor = aten::cat(%162, %19) # gptadv_static.py:56:12
  %5257 : Tensor = aten::reshape(%v.6, %7)
  %k.10 : Tensor = aten::transpose(%5255, %19, %17) # gptadv_static.py:58:12
  %q.10 : Tensor = aten::transpose(%5256, %19, %17) # gptadv_static.py:59:12
  %v.10 : Tensor = aten::transpose(%5257, %19, %17) # gptadv_static.py:60:12
  %4633 : Tensor = aten::transpose(%k.10, %12, %18) # gptadv_static.py:62:19
  %4634 : Tensor = aten::matmul(%q.10, %4633) # gptadv_static.py:62:15
  %att.2 : Tensor = aten::mul(%4634, %6) # gptadv_static.py:62:15
  %ret.24 : Tensor = aten::softmax(%att.2, %18, %20) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1843:14
  %y.3 : Tensor = aten::matmul(%ret.24, %v.10) # gptadv_static.py:66:12
  %4638 : Tensor = aten::transpose(%y.3, %17, %13) # gptadv_static.py:67:12
  %5258 : Tensor = aten::reshape(%4638, %5)
  %5310 : int = prim::Constant[value=1]()
  %5311 : Tensor = aten::t(%self.blocks.0.attention.c_proj.weight.1)
  %5312 : Tensor = aten::matmul(%5258, %5311)
  %5313 : Tensor = trt::const(%self.blocks.0.attention.c_proj.bias.1)
  %5314 : Tensor = aten::add(%5313, %5312, %5310)
  %x.18 : Tensor = aten::add(%x.1, %5314, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:162:12
  %4643 : Tensor = aten::layer_norm(%x.18, %9, %self.blocks.0.ln_2.weight.1, %self.blocks.0.ln_2.bias.1, %11, %10) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2515:11
  %5315 : int = prim::Constant[value=1]()
  %5316 : Tensor = aten::t(%self.blocks.0.mlp.0.weight.1)
  %5317 : Tensor = aten::matmul(%4643, %5316)
  %5318 : Tensor = trt::const(%self.blocks.0.mlp.0.bias.1)
  %5319 : Tensor = aten::add(%5318, %5317, %5315)
  %4645 : Tensor = aten::mul(%5319, %15) # gptadv_static.py:26:15
  %4646 : Tensor = aten::div(%5319, %16) # gptadv_static.py:26:42
  %4647 : Tensor = aten::erf(%4646) # gptadv_static.py:26:32
  %4648 : Tensor = aten::add(%4647, %14, %17) # <string>:5:9
  %input.10 : Tensor = aten::mul(%4645, %4648) # gptadv_static.py:26:15
  %5320 : int = prim::Constant[value=1]()
  %5321 : Tensor = aten::t(%self.blocks.0.mlp.2.weight.1)
  %5322 : Tensor = aten::matmul(%input.10, %5321)
  %5323 : Tensor = trt::const(%self.blocks.0.mlp.2.bias.1)
  %5324 : Tensor = aten::add(%5323, %5322, %5320)
  %x.5 : Tensor = aten::add(%x.18, %5324, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:163:12
  %x_.4 : Tensor = aten::layer_norm(%x.5, %9, %self.blocks.1.ln_1.weight.1, %self.blocks.1.ln_1.bias.1, %11, %10) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2515:11
  %5325 : int = prim::Constant[value=1]()
  %5326 : Tensor = aten::t(%self.blocks.1.attention.c_attn.weight)
  %5327 : Tensor = aten::matmul(%x_.4, %5326)
  %5328 : Tensor = trt::const(%self.blocks.0.attention.c_attn.bias)
  %5329 : Tensor = aten::add(%5328, %5327, %5325)
  %191 : Tensor[] = aten::split(%5329, %self.blocks.0.attention.n_embd, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:119:19
  %q.12 : Tensor, %k.12 : Tensor, %v.12 : Tensor = prim::ListUnpack(%191)
  %195 : Tensor[] = prim::ListConstruct(%8, %k.12)
  %197 : Tensor[] = prim::ListConstruct(%8, %q.12)
  %199 : Tensor[] = prim::ListConstruct(%8, %v.12)
  %k.14 : Tensor = aten::cat(%195, %19) # gptadv_static.py:54:12
  %5259 : Tensor = aten::reshape(%k.14, %7)
  %q.14 : Tensor = aten::cat(%197, %19) # gptadv_static.py:55:12
  %5260 : Tensor = aten::reshape(%q.14, %7)
  %v.14 : Tensor = aten::cat(%199, %19) # gptadv_static.py:56:12
  %5261 : Tensor = aten::reshape(%v.14, %7)
  %k.16 : Tensor = aten::transpose(%5259, %19, %17) # gptadv_static.py:58:12
  %q.16 : Tensor = aten::transpose(%5260, %19, %17) # gptadv_static.py:59:12
  %v.16 : Tensor = aten::transpose(%5261, %19, %17) # gptadv_static.py:60:12
  %4687 : Tensor = aten::transpose(%k.16, %12, %18) # gptadv_static.py:62:19
  %4688 : Tensor = aten::matmul(%q.16, %4687) # gptadv_static.py:62:15
  %att.4 : Tensor = aten::mul(%4688, %6) # gptadv_static.py:62:15
  %ret.4 : Tensor = aten::softmax(%att.4, %18, %20) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1843:14
  %y.7 : Tensor = aten::matmul(%ret.4, %v.16) # gptadv_static.py:66:12
  %4692 : Tensor = aten::transpose(%y.7, %17, %13) # gptadv_static.py:67:12
  %5262 : Tensor = aten::reshape(%4692, %5)
  %5330 : int = prim::Constant[value=1]()
  %5331 : Tensor = aten::t(%self.blocks.1.attention.c_proj.weight.1)
  %5332 : Tensor = aten::matmul(%5262, %5331)
  %5333 : Tensor = trt::const(%self.blocks.0.attention.c_proj.bias.1)
  %5334 : Tensor = aten::add(%5333, %5332, %5330)
  %x.22 : Tensor = aten::add(%x.5, %5334, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:162:12
  %4697 : Tensor = aten::layer_norm(%x.22, %9, %self.blocks.1.ln_2.weight.1, %self.blocks.1.ln_2.bias.1, %11, %10) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2515:11
  %5335 : int = prim::Constant[value=1]()
  %5336 : Tensor = aten::t(%self.blocks.1.mlp.0.weight.1)
  %5337 : Tensor = aten::matmul(%4697, %5336)
  %5338 : Tensor = trt::const(%self.blocks.1.mlp.0.bias.1)
  %5339 : Tensor = aten::add(%5338, %5337, %5335)
  %4699 : Tensor = aten::mul(%5339, %15) # gptadv_static.py:26:15
  %4700 : Tensor = aten::div(%5339, %16) # gptadv_static.py:26:42
  %4701 : Tensor = aten::erf(%4700) # gptadv_static.py:26:32
  %4702 : Tensor = aten::add(%4701, %14, %17) # <string>:5:9
  %input.18 : Tensor = aten::mul(%4699, %4702) # gptadv_static.py:26:15
  %5340 : int = prim::Constant[value=1]()
  %5341 : Tensor = aten::t(%self.blocks.1.mlp.2.weight.1)
  %5342 : Tensor = aten::matmul(%input.18, %5341)
  %5343 : Tensor = trt::const(%self.blocks.1.mlp.2.bias.1)
  %5344 : Tensor = aten::add(%5343, %5342, %5340)
  %x.9 : Tensor = aten::add(%x.22, %5344, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:163:12
  %x_.6 : Tensor = aten::layer_norm(%x.9, %9, %self.blocks.2.ln_1.weight.1, %self.blocks.2.ln_1.bias.1, %11, %10) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2515:11
  %5345 : int = prim::Constant[value=1]()
  %5346 : Tensor = aten::t(%self.blocks.2.attention.c_attn.weight)
  %5347 : Tensor = aten::matmul(%x_.6, %5346)
  %5348 : Tensor = trt::const(%self.blocks.0.attention.c_attn.bias)
  %5349 : Tensor = aten::add(%5348, %5347, %5345)
  %228 : Tensor[] = aten::split(%5349, %self.blocks.0.attention.n_embd, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:119:19
  %q.18 : Tensor, %k.18 : Tensor, %v.18 : Tensor = prim::ListUnpack(%228)
  %232 : Tensor[] = prim::ListConstruct(%8, %k.18)
  %234 : Tensor[] = prim::ListConstruct(%8, %q.18)
  %236 : Tensor[] = prim::ListConstruct(%8, %v.18)
  %k.20 : Tensor = aten::cat(%232, %19) # gptadv_static.py:54:12
  %5263 : Tensor = aten::reshape(%k.20, %7)
  %q.20 : Tensor = aten::cat(%234, %19) # gptadv_static.py:55:12
  %5264 : Tensor = aten::reshape(%q.20, %7)
  %v.20 : Tensor = aten::cat(%236, %19) # gptadv_static.py:56:12
  %5265 : Tensor = aten::reshape(%v.20, %7)
  %k.22 : Tensor = aten::transpose(%5263, %19, %17) # gptadv_static.py:58:12
  %q.22 : Tensor = aten::transpose(%5264, %19, %17) # gptadv_static.py:59:12
  %v.22 : Tensor = aten::transpose(%5265, %19, %17) # gptadv_static.py:60:12
  %4741 : Tensor = aten::transpose(%k.22, %12, %18) # gptadv_static.py:62:19
  %4742 : Tensor = aten::matmul(%q.22, %4741) # gptadv_static.py:62:15
  %att.6 : Tensor = aten::mul(%4742, %6) # gptadv_static.py:62:15
  %ret.6 : Tensor = aten::softmax(%att.6, %18, %20) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1843:14
  %y.11 : Tensor = aten::matmul(%ret.6, %v.22) # gptadv_static.py:66:12
  %4746 : Tensor = aten::transpose(%y.11, %17, %13) # gptadv_static.py:67:12
  %5266 : Tensor = aten::reshape(%4746, %5)
  %5350 : int = prim::Constant[value=1]()
  %5351 : Tensor = aten::t(%self.blocks.2.attention.c_proj.weight.1)
  %5352 : Tensor = aten::matmul(%5266, %5351)
  %5353 : Tensor = trt::const(%self.blocks.0.attention.c_proj.bias.1)
  %5354 : Tensor = aten::add(%5353, %5352, %5350)
  %x.26 : Tensor = aten::add(%x.9, %5354, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:162:12
  %4751 : Tensor = aten::layer_norm(%x.26, %9, %self.blocks.2.ln_2.weight.1, %self.blocks.2.ln_2.bias.1, %11, %10) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2515:11
  %5355 : int = prim::Constant[value=1]()
  %5356 : Tensor = aten::t(%self.blocks.2.mlp.0.weight.1)
  %5357 : Tensor = aten::matmul(%4751, %5356)
  %5358 : Tensor = trt::const(%self.blocks.2.mlp.0.bias.1)
  %5359 : Tensor = aten::add(%5358, %5357, %5355)
  %4753 : Tensor = aten::mul(%5359, %15) # gptadv_static.py:26:15
  %4754 : Tensor = aten::div(%5359, %16) # gptadv_static.py:26:42
  %4755 : Tensor = aten::erf(%4754) # gptadv_static.py:26:32
  %4756 : Tensor = aten::add(%4755, %14, %17) # <string>:5:9
  %input.24 : Tensor = aten::mul(%4753, %4756) # gptadv_static.py:26:15
  %5360 : int = prim::Constant[value=1]()
  %5361 : Tensor = aten::t(%self.blocks.2.mlp.2.weight.1)
  %5362 : Tensor = aten::matmul(%input.24, %5361)
  %5363 : Tensor = trt::const(%self.blocks.2.mlp.2.bias.1)
  %5364 : Tensor = aten::add(%5363, %5362, %5360)
  %x.14 : Tensor = aten::add(%x.26, %5364, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:163:12
  %x_.8 : Tensor = aten::layer_norm(%x.14, %9, %self.blocks.3.ln_1.weight.1, %self.blocks.3.ln_1.bias.1, %11, %10) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2515:11
  %5365 : int = prim::Constant[value=1]()
  %5366 : Tensor = aten::t(%self.blocks.3.attention.c_attn.weight)
  %5367 : Tensor = aten::matmul(%x_.8, %5366)
  %5368 : Tensor = trt::const(%self.blocks.0.attention.c_attn.bias)
  %5369 : Tensor = aten::add(%5368, %5367, %5365)
  %265 : Tensor[] = aten::split(%5369, %self.blocks.0.attention.n_embd, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:119:19
  %q.24 : Tensor, %k.24 : Tensor, %v.24 : Tensor = prim::ListUnpack(%265)
  %269 : Tensor[] = prim::ListConstruct(%8, %k.24)
  %271 : Tensor[] = prim::ListConstruct(%8, %q.24)
  %273 : Tensor[] = prim::ListConstruct(%8, %v.24)
  %k.26 : Tensor = aten::cat(%269, %19) # gptadv_static.py:54:12
  %5267 : Tensor = aten::reshape(%k.26, %7)
  %q.26 : Tensor = aten::cat(%271, %19) # gptadv_static.py:55:12
  %5268 : Tensor = aten::reshape(%q.26, %7)
  %v.26 : Tensor = aten::cat(%273, %19) # gptadv_static.py:56:12
  %5269 : Tensor = aten::reshape(%v.26, %7)
  %k.28 : Tensor = aten::transpose(%5267, %19, %17) # gptadv_static.py:58:12
  %q.28 : Tensor = aten::transpose(%5268, %19, %17) # gptadv_static.py:59:12
  %v.28 : Tensor = aten::transpose(%5269, %19, %17) # gptadv_static.py:60:12
  %4795 : Tensor = aten::transpose(%k.28, %12, %18) # gptadv_static.py:62:19
  %4796 : Tensor = aten::matmul(%q.28, %4795) # gptadv_static.py:62:15
  %att.8 : Tensor = aten::mul(%4796, %6) # gptadv_static.py:62:15
  %ret.8 : Tensor = aten::softmax(%att.8, %18, %20) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1843:14
  %y.15 : Tensor = aten::matmul(%ret.8, %v.28) # gptadv_static.py:66:12
  %4800 : Tensor = aten::transpose(%y.15, %17, %13) # gptadv_static.py:67:12
  %5270 : Tensor = aten::reshape(%4800, %5)
  %5370 : int = prim::Constant[value=1]()
  %5371 : Tensor = aten::t(%self.blocks.3.attention.c_proj.weight.1)
  %5372 : Tensor = aten::matmul(%5270, %5371)
  %5373 : Tensor = trt::const(%self.blocks.0.attention.c_proj.bias.1)
  %5374 : Tensor = aten::add(%5373, %5372, %5370)
  %x.30 : Tensor = aten::add(%x.14, %5374, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:162:12
  %4805 : Tensor = aten::layer_norm(%x.30, %9, %self.blocks.3.ln_2.weight.1, %self.blocks.3.ln_2.bias.1, %11, %10) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2515:11
  %5375 : int = prim::Constant[value=1]()
  %5376 : Tensor = aten::t(%self.blocks.3.mlp.0.weight.1)
  %5377 : Tensor = aten::matmul(%4805, %5376)
  %5378 : Tensor = trt::const(%self.blocks.3.mlp.0.bias.1)
  %5379 : Tensor = aten::add(%5378, %5377, %5375)
  %4807 : Tensor = aten::mul(%5379, %15) # gptadv_static.py:26:15
  %4808 : Tensor = aten::div(%5379, %16) # gptadv_static.py:26:42
  %4809 : Tensor = aten::erf(%4808) # gptadv_static.py:26:32
  %4810 : Tensor = aten::add(%4809, %14, %17) # <string>:5:9
  %input.30 : Tensor = aten::mul(%4807, %4810) # gptadv_static.py:26:15
  %5380 : int = prim::Constant[value=1]()
  %5381 : Tensor = aten::t(%self.blocks.3.mlp.2.weight.1)
  %5382 : Tensor = aten::matmul(%input.30, %5381)
  %5383 : Tensor = trt::const(%self.blocks.3.mlp.2.bias.1)
  %5384 : Tensor = aten::add(%5383, %5382, %5380)
  %x.17 : Tensor = aten::add(%x.30, %5384, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:163:12
  %x_.10 : Tensor = aten::layer_norm(%x.17, %9, %self.blocks.4.ln_1.weight.1, %self.blocks.4.ln_1.bias.1, %11, %10) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2515:11
  %5385 : int = prim::Constant[value=1]()
  %5386 : Tensor = aten::t(%self.blocks.4.attention.c_attn.weight)
  %5387 : Tensor = aten::matmul(%x_.10, %5386)
  %5388 : Tensor = trt::const(%self.blocks.0.attention.c_attn.bias)
  %5389 : Tensor = aten::add(%5388, %5387, %5385)
  %302 : Tensor[] = aten::split(%5389, %self.blocks.0.attention.n_embd, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:119:19
  %q.30 : Tensor, %k.30 : Tensor, %v.30 : Tensor = prim::ListUnpack(%302)
  %306 : Tensor[] = prim::ListConstruct(%8, %k.30)
  %308 : Tensor[] = prim::ListConstruct(%8, %q.30)
  %310 : Tensor[] = prim::ListConstruct(%8, %v.30)
  %k.32 : Tensor = aten::cat(%306, %19) # gptadv_static.py:54:12
  %5271 : Tensor = aten::reshape(%k.32, %7)
  %q.32 : Tensor = aten::cat(%308, %19) # gptadv_static.py:55:12
  %5272 : Tensor = aten::reshape(%q.32, %7)
  %v.32 : Tensor = aten::cat(%310, %19) # gptadv_static.py:56:12
  %5273 : Tensor = aten::reshape(%v.32, %7)
  %k.34 : Tensor = aten::transpose(%5271, %19, %17) # gptadv_static.py:58:12
  %q.34 : Tensor = aten::transpose(%5272, %19, %17) # gptadv_static.py:59:12
  %v.34 : Tensor = aten::transpose(%5273, %19, %17) # gptadv_static.py:60:12
  %4849 : Tensor = aten::transpose(%k.34, %12, %18) # gptadv_static.py:62:19
  %4850 : Tensor = aten::matmul(%q.34, %4849) # gptadv_static.py:62:15
  %att.10 : Tensor = aten::mul(%4850, %6) # gptadv_static.py:62:15
  %ret.10 : Tensor = aten::softmax(%att.10, %18, %20) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1843:14
  %y.19 : Tensor = aten::matmul(%ret.10, %v.34) # gptadv_static.py:66:12
  %4854 : Tensor = aten::transpose(%y.19, %17, %13) # gptadv_static.py:67:12
  %5274 : Tensor = aten::reshape(%4854, %5)
  %5390 : int = prim::Constant[value=1]()
  %5391 : Tensor = aten::t(%self.blocks.4.attention.c_proj.weight.1)
  %5392 : Tensor = aten::matmul(%5274, %5391)
  %5393 : Tensor = trt::const(%self.blocks.0.attention.c_proj.bias.1)
  %5394 : Tensor = aten::add(%5393, %5392, %5390)
  %x.34 : Tensor = aten::add(%x.17, %5394, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:162:12
  %4859 : Tensor = aten::layer_norm(%x.34, %9, %self.blocks.4.ln_2.weight.1, %self.blocks.4.ln_2.bias.1, %11, %10) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2515:11
  %5395 : int = prim::Constant[value=1]()
  %5396 : Tensor = aten::t(%self.blocks.4.mlp.0.weight.1)
  %5397 : Tensor = aten::matmul(%4859, %5396)
  %5398 : Tensor = trt::const(%self.blocks.4.mlp.0.bias.1)
  %5399 : Tensor = aten::add(%5398, %5397, %5395)
  %4861 : Tensor = aten::mul(%5399, %15) # gptadv_static.py:26:15
  %4862 : Tensor = aten::div(%5399, %16) # gptadv_static.py:26:42
  %4863 : Tensor = aten::erf(%4862) # gptadv_static.py:26:32
  %4864 : Tensor = aten::add(%4863, %14, %17) # <string>:5:9
  %input.36 : Tensor = aten::mul(%4861, %4864) # gptadv_static.py:26:15
  %5400 : int = prim::Constant[value=1]()
  %5401 : Tensor = aten::t(%self.blocks.4.mlp.2.weight.1)
  %5402 : Tensor = aten::matmul(%input.36, %5401)
  %5403 : Tensor = trt::const(%self.blocks.4.mlp.2.bias.1)
  %5404 : Tensor = aten::add(%5403, %5402, %5400)
  %x.21 : Tensor = aten::add(%x.34, %5404, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:163:12
  %x_.12 : Tensor = aten::layer_norm(%x.21, %9, %self.blocks.5.ln_1.weight.1, %self.blocks.5.ln_1.bias.1, %11, %10) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2515:11
  %5405 : int = prim::Constant[value=1]()
  %5406 : Tensor = aten::t(%self.blocks.5.attention.c_attn.weight)
  %5407 : Tensor = aten::matmul(%x_.12, %5406)
  %5408 : Tensor = trt::const(%self.blocks.0.attention.c_attn.bias)
  %5409 : Tensor = aten::add(%5408, %5407, %5405)
  %339 : Tensor[] = aten::split(%5409, %self.blocks.0.attention.n_embd, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:119:19
  %q.36 : Tensor, %k.36 : Tensor, %v.36 : Tensor = prim::ListUnpack(%339)
  %343 : Tensor[] = prim::ListConstruct(%8, %k.36)
  %345 : Tensor[] = prim::ListConstruct(%8, %q.36)
  %347 : Tensor[] = prim::ListConstruct(%8, %v.36)
  %k.38 : Tensor = aten::cat(%343, %19) # gptadv_static.py:54:12
  %5275 : Tensor = aten::reshape(%k.38, %7)
  %q.38 : Tensor = aten::cat(%345, %19) # gptadv_static.py:55:12
  %5276 : Tensor = aten::reshape(%q.38, %7)
  %v.38 : Tensor = aten::cat(%347, %19) # gptadv_static.py:56:12
  %5277 : Tensor = aten::reshape(%v.38, %7)
  %k.40 : Tensor = aten::transpose(%5275, %19, %17) # gptadv_static.py:58:12
  %q.40 : Tensor = aten::transpose(%5276, %19, %17) # gptadv_static.py:59:12
  %v.40 : Tensor = aten::transpose(%5277, %19, %17) # gptadv_static.py:60:12
  %4903 : Tensor = aten::transpose(%k.40, %12, %18) # gptadv_static.py:62:19
  %4904 : Tensor = aten::matmul(%q.40, %4903) # gptadv_static.py:62:15
  %att.12 : Tensor = aten::mul(%4904, %6) # gptadv_static.py:62:15
  %ret.12 : Tensor = aten::softmax(%att.12, %18, %20) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1843:14
  %y.23 : Tensor = aten::matmul(%ret.12, %v.40) # gptadv_static.py:66:12
  %4908 : Tensor = aten::transpose(%y.23, %17, %13) # gptadv_static.py:67:12
  %5278 : Tensor = aten::reshape(%4908, %5)
  %5410 : int = prim::Constant[value=1]()
  %5411 : Tensor = aten::t(%self.blocks.5.attention.c_proj.weight.1)
  %5412 : Tensor = aten::matmul(%5278, %5411)
  %5413 : Tensor = trt::const(%self.blocks.0.attention.c_proj.bias.1)
  %5414 : Tensor = aten::add(%5413, %5412, %5410)
  %x.38 : Tensor = aten::add(%x.21, %5414, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:162:12
  %4913 : Tensor = aten::layer_norm(%x.38, %9, %self.blocks.5.ln_2.weight.1, %self.blocks.5.ln_2.bias.1, %11, %10) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2515:11
  %5415 : int = prim::Constant[value=1]()
  %5416 : Tensor = aten::t(%self.blocks.5.mlp.0.weight.1)
  %5417 : Tensor = aten::matmul(%4913, %5416)
  %5418 : Tensor = trt::const(%self.blocks.5.mlp.0.bias.1)
  %5419 : Tensor = aten::add(%5418, %5417, %5415)
  %4915 : Tensor = aten::mul(%5419, %15) # gptadv_static.py:26:15
  %4916 : Tensor = aten::div(%5419, %16) # gptadv_static.py:26:42
  %4917 : Tensor = aten::erf(%4916) # gptadv_static.py:26:32
  %4918 : Tensor = aten::add(%4917, %14, %17) # <string>:5:9
  %input.42 : Tensor = aten::mul(%4915, %4918) # gptadv_static.py:26:15
  %5420 : int = prim::Constant[value=1]()
  %5421 : Tensor = aten::t(%self.blocks.5.mlp.2.weight.1)
  %5422 : Tensor = aten::matmul(%input.42, %5421)
  %5423 : Tensor = trt::const(%self.blocks.5.mlp.2.bias.1)
  %5424 : Tensor = aten::add(%5423, %5422, %5420)
  %x.25 : Tensor = aten::add(%x.38, %5424, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:163:12
  %x_.14 : Tensor = aten::layer_norm(%x.25, %9, %self.blocks.6.ln_1.weight.1, %self.blocks.6.ln_1.bias.1, %11, %10) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2515:11
  %5425 : int = prim::Constant[value=1]()
  %5426 : Tensor = aten::t(%self.blocks.6.attention.c_attn.weight)
  %5427 : Tensor = aten::matmul(%x_.14, %5426)
  %5428 : Tensor = trt::const(%self.blocks.0.attention.c_attn.bias)
  %5429 : Tensor = aten::add(%5428, %5427, %5425)
  %376 : Tensor[] = aten::split(%5429, %self.blocks.0.attention.n_embd, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:119:19
  %q.42 : Tensor, %k.42 : Tensor, %v.42 : Tensor = prim::ListUnpack(%376)
  %380 : Tensor[] = prim::ListConstruct(%8, %k.42)
  %382 : Tensor[] = prim::ListConstruct(%8, %q.42)
  %384 : Tensor[] = prim::ListConstruct(%8, %v.42)
  %k.44 : Tensor = aten::cat(%380, %19) # gptadv_static.py:54:12
  %5279 : Tensor = aten::reshape(%k.44, %7)
  %q.44 : Tensor = aten::cat(%382, %19) # gptadv_static.py:55:12
  %5280 : Tensor = aten::reshape(%q.44, %7)
  %v.44 : Tensor = aten::cat(%384, %19) # gptadv_static.py:56:12
  %5281 : Tensor = aten::reshape(%v.44, %7)
  %k.46 : Tensor = aten::transpose(%5279, %19, %17) # gptadv_static.py:58:12
  %q.46 : Tensor = aten::transpose(%5280, %19, %17) # gptadv_static.py:59:12
  %v.46 : Tensor = aten::transpose(%5281, %19, %17) # gptadv_static.py:60:12
  %4957 : Tensor = aten::transpose(%k.46, %12, %18) # gptadv_static.py:62:19
  %4958 : Tensor = aten::matmul(%q.46, %4957) # gptadv_static.py:62:15
  %att.14 : Tensor = aten::mul(%4958, %6) # gptadv_static.py:62:15
  %ret.14 : Tensor = aten::softmax(%att.14, %18, %20) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1843:14
  %y.27 : Tensor = aten::matmul(%ret.14, %v.46) # gptadv_static.py:66:12
  %4962 : Tensor = aten::transpose(%y.27, %17, %13) # gptadv_static.py:67:12
  %5282 : Tensor = aten::reshape(%4962, %5)
  %5430 : int = prim::Constant[value=1]()
  %5431 : Tensor = aten::t(%self.blocks.6.attention.c_proj.weight.1)
  %5432 : Tensor = aten::matmul(%5282, %5431)
  %5433 : Tensor = trt::const(%self.blocks.0.attention.c_proj.bias.1)
  %5434 : Tensor = aten::add(%5433, %5432, %5430)
  %x.42 : Tensor = aten::add(%x.25, %5434, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:162:12
  %4967 : Tensor = aten::layer_norm(%x.42, %9, %self.blocks.6.ln_2.weight.1, %self.blocks.6.ln_2.bias.1, %11, %10) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2515:11
  %5435 : int = prim::Constant[value=1]()
  %5436 : Tensor = aten::t(%self.blocks.6.mlp.0.weight.1)
  %5437 : Tensor = aten::matmul(%4967, %5436)
  %5438 : Tensor = trt::const(%self.blocks.6.mlp.0.bias.1)
  %5439 : Tensor = aten::add(%5438, %5437, %5435)
  %4969 : Tensor = aten::mul(%5439, %15) # gptadv_static.py:26:15
  %4970 : Tensor = aten::div(%5439, %16) # gptadv_static.py:26:42
  %4971 : Tensor = aten::erf(%4970) # gptadv_static.py:26:32
  %4972 : Tensor = aten::add(%4971, %14, %17) # <string>:5:9
  %input.48 : Tensor = aten::mul(%4969, %4972) # gptadv_static.py:26:15
  %5440 : int = prim::Constant[value=1]()
  %5441 : Tensor = aten::t(%self.blocks.6.mlp.2.weight.1)
  %5442 : Tensor = aten::matmul(%input.48, %5441)
  %5443 : Tensor = trt::const(%self.blocks.6.mlp.2.bias.1)
  %5444 : Tensor = aten::add(%5443, %5442, %5440)
  %x.29 : Tensor = aten::add(%x.42, %5444, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:163:12
  %x_.16 : Tensor = aten::layer_norm(%x.29, %9, %self.blocks.7.ln_1.weight.1, %self.blocks.7.ln_1.bias.1, %11, %10) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2515:11
  %5445 : int = prim::Constant[value=1]()
  %5446 : Tensor = aten::t(%self.blocks.7.attention.c_attn.weight)
  %5447 : Tensor = aten::matmul(%x_.16, %5446)
  %5448 : Tensor = trt::const(%self.blocks.0.attention.c_attn.bias)
  %5449 : Tensor = aten::add(%5448, %5447, %5445)
  %413 : Tensor[] = aten::split(%5449, %self.blocks.0.attention.n_embd, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:119:19
  %q.48 : Tensor, %k.48 : Tensor, %v.48 : Tensor = prim::ListUnpack(%413)
  %417 : Tensor[] = prim::ListConstruct(%8, %k.48)
  %419 : Tensor[] = prim::ListConstruct(%8, %q.48)
  %421 : Tensor[] = prim::ListConstruct(%8, %v.48)
  %k.50 : Tensor = aten::cat(%417, %19) # gptadv_static.py:54:12
  %5283 : Tensor = aten::reshape(%k.50, %7)
  %q.50 : Tensor = aten::cat(%419, %19) # gptadv_static.py:55:12
  %5284 : Tensor = aten::reshape(%q.50, %7)
  %v.50 : Tensor = aten::cat(%421, %19) # gptadv_static.py:56:12
  %5285 : Tensor = aten::reshape(%v.50, %7)
  %k.52 : Tensor = aten::transpose(%5283, %19, %17) # gptadv_static.py:58:12
  %q.52 : Tensor = aten::transpose(%5284, %19, %17) # gptadv_static.py:59:12
  %v.52 : Tensor = aten::transpose(%5285, %19, %17) # gptadv_static.py:60:12
  %5011 : Tensor = aten::transpose(%k.52, %12, %18) # gptadv_static.py:62:19
  %5012 : Tensor = aten::matmul(%q.52, %5011) # gptadv_static.py:62:15
  %att.16 : Tensor = aten::mul(%5012, %6) # gptadv_static.py:62:15
  %ret.16 : Tensor = aten::softmax(%att.16, %18, %20) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1843:14
  %y.31 : Tensor = aten::matmul(%ret.16, %v.52) # gptadv_static.py:66:12
  %5016 : Tensor = aten::transpose(%y.31, %17, %13) # gptadv_static.py:67:12
  %5286 : Tensor = aten::reshape(%5016, %5)
  %5450 : int = prim::Constant[value=1]()
  %5451 : Tensor = aten::t(%self.blocks.7.attention.c_proj.weight.1)
  %5452 : Tensor = aten::matmul(%5286, %5451)
  %5453 : Tensor = trt::const(%self.blocks.0.attention.c_proj.bias.1)
  %5454 : Tensor = aten::add(%5453, %5452, %5450)
  %x.46 : Tensor = aten::add(%x.29, %5454, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:162:12
  %5021 : Tensor = aten::layer_norm(%x.46, %9, %self.blocks.7.ln_2.weight.1, %self.blocks.7.ln_2.bias.1, %11, %10) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2515:11
  %5455 : int = prim::Constant[value=1]()
  %5456 : Tensor = aten::t(%self.blocks.7.mlp.0.weight.1)
  %5457 : Tensor = aten::matmul(%5021, %5456)
  %5458 : Tensor = trt::const(%self.blocks.7.mlp.0.bias.1)
  %5459 : Tensor = aten::add(%5458, %5457, %5455)
  %5023 : Tensor = aten::mul(%5459, %15) # gptadv_static.py:26:15
  %5024 : Tensor = aten::div(%5459, %16) # gptadv_static.py:26:42
  %5025 : Tensor = aten::erf(%5024) # gptadv_static.py:26:32
  %5026 : Tensor = aten::add(%5025, %14, %17) # <string>:5:9
  %input.54 : Tensor = aten::mul(%5023, %5026) # gptadv_static.py:26:15
  %5460 : int = prim::Constant[value=1]()
  %5461 : Tensor = aten::t(%self.blocks.7.mlp.2.weight.1)
  %5462 : Tensor = aten::matmul(%input.54, %5461)
  %5463 : Tensor = trt::const(%self.blocks.7.mlp.2.bias.1)
  %5464 : Tensor = aten::add(%5463, %5462, %5460)
  %x.33 : Tensor = aten::add(%x.46, %5464, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:163:12
  %x_.18 : Tensor = aten::layer_norm(%x.33, %9, %self.blocks.8.ln_1.weight.1, %self.blocks.8.ln_1.bias.1, %11, %10) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2515:11
  %5465 : int = prim::Constant[value=1]()
  %5466 : Tensor = aten::t(%self.blocks.8.attention.c_attn.weight)
  %5467 : Tensor = aten::matmul(%x_.18, %5466)
  %5468 : Tensor = trt::const(%self.blocks.0.attention.c_attn.bias)
  %5469 : Tensor = aten::add(%5468, %5467, %5465)
  %450 : Tensor[] = aten::split(%5469, %self.blocks.0.attention.n_embd, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:119:19
  %q.54 : Tensor, %k.54 : Tensor, %v.54 : Tensor = prim::ListUnpack(%450)
  %454 : Tensor[] = prim::ListConstruct(%8, %k.54)
  %456 : Tensor[] = prim::ListConstruct(%8, %q.54)
  %458 : Tensor[] = prim::ListConstruct(%8, %v.54)
  %k.56 : Tensor = aten::cat(%454, %19) # gptadv_static.py:54:12
  %5287 : Tensor = aten::reshape(%k.56, %7)
  %q.56 : Tensor = aten::cat(%456, %19) # gptadv_static.py:55:12
  %5288 : Tensor = aten::reshape(%q.56, %7)
  %v.56 : Tensor = aten::cat(%458, %19) # gptadv_static.py:56:12
  %5289 : Tensor = aten::reshape(%v.56, %7)
  %k.58 : Tensor = aten::transpose(%5287, %19, %17) # gptadv_static.py:58:12
  %q.58 : Tensor = aten::transpose(%5288, %19, %17) # gptadv_static.py:59:12
  %v.58 : Tensor = aten::transpose(%5289, %19, %17) # gptadv_static.py:60:12
  %5065 : Tensor = aten::transpose(%k.58, %12, %18) # gptadv_static.py:62:19
  %5066 : Tensor = aten::matmul(%q.58, %5065) # gptadv_static.py:62:15
  %att.18 : Tensor = aten::mul(%5066, %6) # gptadv_static.py:62:15
  %ret.18 : Tensor = aten::softmax(%att.18, %18, %20) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1843:14
  %y.35 : Tensor = aten::matmul(%ret.18, %v.58) # gptadv_static.py:66:12
  %5070 : Tensor = aten::transpose(%y.35, %17, %13) # gptadv_static.py:67:12
  %5290 : Tensor = aten::reshape(%5070, %5)
  %5470 : int = prim::Constant[value=1]()
  %5471 : Tensor = aten::t(%self.blocks.8.attention.c_proj.weight.1)
  %5472 : Tensor = aten::matmul(%5290, %5471)
  %5473 : Tensor = trt::const(%self.blocks.0.attention.c_proj.bias.1)
  %5474 : Tensor = aten::add(%5473, %5472, %5470)
  %x.50 : Tensor = aten::add(%x.33, %5474, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:162:12
  %5075 : Tensor = aten::layer_norm(%x.50, %9, %self.blocks.8.ln_2.weight.1, %self.blocks.8.ln_2.bias.1, %11, %10) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2515:11
  %5475 : int = prim::Constant[value=1]()
  %5476 : Tensor = aten::t(%self.blocks.8.mlp.0.weight.1)
  %5477 : Tensor = aten::matmul(%5075, %5476)
  %5478 : Tensor = trt::const(%self.blocks.8.mlp.0.bias.1)
  %5479 : Tensor = aten::add(%5478, %5477, %5475)
  %5077 : Tensor = aten::mul(%5479, %15) # gptadv_static.py:26:15
  %5078 : Tensor = aten::div(%5479, %16) # gptadv_static.py:26:42
  %5079 : Tensor = aten::erf(%5078) # gptadv_static.py:26:32
  %5080 : Tensor = aten::add(%5079, %14, %17) # <string>:5:9
  %input.60 : Tensor = aten::mul(%5077, %5080) # gptadv_static.py:26:15
  %5480 : int = prim::Constant[value=1]()
  %5481 : Tensor = aten::t(%self.blocks.8.mlp.2.weight.1)
  %5482 : Tensor = aten::matmul(%input.60, %5481)
  %5483 : Tensor = trt::const(%self.blocks.8.mlp.2.bias.1)
  %5484 : Tensor = aten::add(%5483, %5482, %5480)
  %x.37 : Tensor = aten::add(%x.50, %5484, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:163:12
  %x_.20 : Tensor = aten::layer_norm(%x.37, %9, %self.blocks.9.ln_1.weight.1, %self.blocks.9.ln_1.bias.1, %11, %10) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2515:11
  %5485 : int = prim::Constant[value=1]()
  %5486 : Tensor = aten::t(%self.blocks.9.attention.c_attn.weight)
  %5487 : Tensor = aten::matmul(%x_.20, %5486)
  %5488 : Tensor = trt::const(%self.blocks.0.attention.c_attn.bias)
  %5489 : Tensor = aten::add(%5488, %5487, %5485)
  %487 : Tensor[] = aten::split(%5489, %self.blocks.0.attention.n_embd, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:119:19
  %q.60 : Tensor, %k.60 : Tensor, %v.60 : Tensor = prim::ListUnpack(%487)
  %491 : Tensor[] = prim::ListConstruct(%8, %k.60)
  %493 : Tensor[] = prim::ListConstruct(%8, %q.60)
  %495 : Tensor[] = prim::ListConstruct(%8, %v.60)
  %k.62 : Tensor = aten::cat(%491, %19) # gptadv_static.py:54:12
  %5291 : Tensor = aten::reshape(%k.62, %7)
  %q.62 : Tensor = aten::cat(%493, %19) # gptadv_static.py:55:12
  %5292 : Tensor = aten::reshape(%q.62, %7)
  %v.62 : Tensor = aten::cat(%495, %19) # gptadv_static.py:56:12
  %5293 : Tensor = aten::reshape(%v.62, %7)
  %k.64 : Tensor = aten::transpose(%5291, %19, %17) # gptadv_static.py:58:12
  %q.64 : Tensor = aten::transpose(%5292, %19, %17) # gptadv_static.py:59:12
  %v.64 : Tensor = aten::transpose(%5293, %19, %17) # gptadv_static.py:60:12
  %5119 : Tensor = aten::transpose(%k.64, %12, %18) # gptadv_static.py:62:19
  %5120 : Tensor = aten::matmul(%q.64, %5119) # gptadv_static.py:62:15
  %att.20 : Tensor = aten::mul(%5120, %6) # gptadv_static.py:62:15
  %ret.20 : Tensor = aten::softmax(%att.20, %18, %20) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1843:14
  %y.39 : Tensor = aten::matmul(%ret.20, %v.64) # gptadv_static.py:66:12
  %5124 : Tensor = aten::transpose(%y.39, %17, %13) # gptadv_static.py:67:12
  %5294 : Tensor = aten::reshape(%5124, %5)
  %5490 : int = prim::Constant[value=1]()
  %5491 : Tensor = aten::t(%self.blocks.9.attention.c_proj.weight.1)
  %5492 : Tensor = aten::matmul(%5294, %5491)
  %5493 : Tensor = trt::const(%self.blocks.0.attention.c_proj.bias.1)
  %5494 : Tensor = aten::add(%5493, %5492, %5490)
  %x.54 : Tensor = aten::add(%x.37, %5494, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:162:12
  %5129 : Tensor = aten::layer_norm(%x.54, %9, %self.blocks.9.ln_2.weight.1, %self.blocks.9.ln_2.bias.1, %11, %10) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2515:11
  %5495 : int = prim::Constant[value=1]()
  %5496 : Tensor = aten::t(%self.blocks.9.mlp.0.weight.1)
  %5497 : Tensor = aten::matmul(%5129, %5496)
  %5498 : Tensor = trt::const(%self.blocks.9.mlp.0.bias.1)
  %5499 : Tensor = aten::add(%5498, %5497, %5495)
  %5131 : Tensor = aten::mul(%5499, %15) # gptadv_static.py:26:15
  %5132 : Tensor = aten::div(%5499, %16) # gptadv_static.py:26:42
  %5133 : Tensor = aten::erf(%5132) # gptadv_static.py:26:32
  %5134 : Tensor = aten::add(%5133, %14, %17) # <string>:5:9
  %input.66 : Tensor = aten::mul(%5131, %5134) # gptadv_static.py:26:15
  %5500 : int = prim::Constant[value=1]()
  %5501 : Tensor = aten::t(%self.blocks.9.mlp.2.weight.1)
  %5502 : Tensor = aten::matmul(%input.66, %5501)
  %5503 : Tensor = trt::const(%self.blocks.9.mlp.2.bias.1)
  %5504 : Tensor = aten::add(%5503, %5502, %5500)
  %x.41 : Tensor = aten::add(%x.54, %5504, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:163:12
  %x_.22 : Tensor = aten::layer_norm(%x.41, %9, %self.blocks.10.ln_1.weight.1, %self.blocks.10.ln_1.bias.1, %11, %10) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2515:11
  %5505 : int = prim::Constant[value=1]()
  %5506 : Tensor = aten::t(%self.blocks.10.attention.c_attn.weight)
  %5507 : Tensor = aten::matmul(%x_.22, %5506)
  %5508 : Tensor = trt::const(%self.blocks.0.attention.c_attn.bias)
  %5509 : Tensor = aten::add(%5508, %5507, %5505)
  %524 : Tensor[] = aten::split(%5509, %self.blocks.0.attention.n_embd, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:119:19
  %q.66 : Tensor, %k.66 : Tensor, %v.66 : Tensor = prim::ListUnpack(%524)
  %528 : Tensor[] = prim::ListConstruct(%8, %k.66)
  %530 : Tensor[] = prim::ListConstruct(%8, %q.66)
  %532 : Tensor[] = prim::ListConstruct(%8, %v.66)
  %k.68 : Tensor = aten::cat(%528, %19) # gptadv_static.py:54:12
  %5295 : Tensor = aten::reshape(%k.68, %7)
  %q.68 : Tensor = aten::cat(%530, %19) # gptadv_static.py:55:12
  %5296 : Tensor = aten::reshape(%q.68, %7)
  %v.68 : Tensor = aten::cat(%532, %19) # gptadv_static.py:56:12
  %5297 : Tensor = aten::reshape(%v.68, %7)
  %k.70 : Tensor = aten::transpose(%5295, %19, %17) # gptadv_static.py:58:12
  %q.70 : Tensor = aten::transpose(%5296, %19, %17) # gptadv_static.py:59:12
  %v.70 : Tensor = aten::transpose(%5297, %19, %17) # gptadv_static.py:60:12
  %5173 : Tensor = aten::transpose(%k.70, %12, %18) # gptadv_static.py:62:19
  %5174 : Tensor = aten::matmul(%q.70, %5173) # gptadv_static.py:62:15
  %att.22 : Tensor = aten::mul(%5174, %6) # gptadv_static.py:62:15
  %ret.22 : Tensor = aten::softmax(%att.22, %18, %20) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1843:14
  %y.43 : Tensor = aten::matmul(%ret.22, %v.70) # gptadv_static.py:66:12
  %5178 : Tensor = aten::transpose(%y.43, %17, %13) # gptadv_static.py:67:12
  %5298 : Tensor = aten::reshape(%5178, %5)
  %5510 : int = prim::Constant[value=1]()
  %5511 : Tensor = aten::t(%self.blocks.10.attention.c_proj.weight.1)
  %5512 : Tensor = aten::matmul(%5298, %5511)
  %5513 : Tensor = trt::const(%self.blocks.0.attention.c_proj.bias.1)
  %5514 : Tensor = aten::add(%5513, %5512, %5510)
  %x.58 : Tensor = aten::add(%x.41, %5514, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:162:12
  %5183 : Tensor = aten::layer_norm(%x.58, %9, %self.blocks.10.ln_2.weight.1, %self.blocks.10.ln_2.bias.1, %11, %10) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2515:11
  %5515 : int = prim::Constant[value=1]()
  %5516 : Tensor = aten::t(%self.blocks.10.mlp.0.weight.1)
  %5517 : Tensor = aten::matmul(%5183, %5516)
  %5518 : Tensor = trt::const(%self.blocks.10.mlp.0.bias.1)
  %5519 : Tensor = aten::add(%5518, %5517, %5515)
  %5185 : Tensor = aten::mul(%5519, %15) # gptadv_static.py:26:15
  %5186 : Tensor = aten::div(%5519, %16) # gptadv_static.py:26:42
  %5187 : Tensor = aten::erf(%5186) # gptadv_static.py:26:32
  %5188 : Tensor = aten::add(%5187, %14, %17) # <string>:5:9
  %input.72 : Tensor = aten::mul(%5185, %5188) # gptadv_static.py:26:15
  %5520 : int = prim::Constant[value=1]()
  %5521 : Tensor = aten::t(%self.blocks.10.mlp.2.weight.1)
  %5522 : Tensor = aten::matmul(%input.72, %5521)
  %5523 : Tensor = trt::const(%self.blocks.10.mlp.2.bias.1)
  %5524 : Tensor = aten::add(%5523, %5522, %5520)
  %x.45 : Tensor = aten::add(%x.58, %5524, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:163:12
  %x_.1 : Tensor = aten::layer_norm(%x.45, %9, %self.blocks.11.ln_1.weight.1, %self.blocks.11.ln_1.bias.1, %11, %10) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2515:11
  %5525 : int = prim::Constant[value=1]()
  %5526 : Tensor = aten::t(%self.blocks.11.attention.c_attn.weight)
  %5527 : Tensor = aten::matmul(%x_.1, %5526)
  %5528 : Tensor = trt::const(%self.blocks.0.attention.c_attn.bias)
  %5529 : Tensor = aten::add(%5528, %5527, %5525)
  %561 : Tensor[] = aten::split(%5529, %self.blocks.0.attention.n_embd, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:119:19
  %q.1 : Tensor, %k.1 : Tensor, %v.1 : Tensor = prim::ListUnpack(%561)
  %565 : Tensor[] = prim::ListConstruct(%8, %k.1)
  %567 : Tensor[] = prim::ListConstruct(%8, %q.1)
  %569 : Tensor[] = prim::ListConstruct(%8, %v.1)
  %k.5 : Tensor = aten::cat(%565, %19) # gptadv_static.py:54:12
  %5299 : Tensor = aten::reshape(%k.5, %7)
  %q.5 : Tensor = aten::cat(%567, %19) # gptadv_static.py:55:12
  %5300 : Tensor = aten::reshape(%q.5, %7)
  %v.5 : Tensor = aten::cat(%569, %19) # gptadv_static.py:56:12
  %5301 : Tensor = aten::reshape(%v.5, %7)
  %k.9 : Tensor = aten::transpose(%5299, %19, %17) # gptadv_static.py:58:12
  %q.9 : Tensor = aten::transpose(%5300, %19, %17) # gptadv_static.py:59:12
  %v.9 : Tensor = aten::transpose(%5301, %19, %17) # gptadv_static.py:60:12
  %5229 : Tensor = aten::transpose(%k.9, %12, %18) # gptadv_static.py:62:19
  %5230 : Tensor = aten::matmul(%q.9, %5229) # gptadv_static.py:62:15
  %att.1 : Tensor = aten::mul(%5230, %6) # gptadv_static.py:62:15
  %ret.26 : Tensor = aten::softmax(%att.1, %18, %20) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1843:14
  %y.1 : Tensor = aten::matmul(%ret.26, %v.9) # gptadv_static.py:66:12
  %5234 : Tensor = aten::transpose(%y.1, %17, %13) # gptadv_static.py:67:12
  %5302 : Tensor = aten::reshape(%5234, %5)
  %5530 : int = prim::Constant[value=1]()
  %5531 : Tensor = aten::t(%self.blocks.11.attention.c_proj.weight.1)
  %5532 : Tensor = aten::matmul(%5302, %5531)
  %5533 : Tensor = trt::const(%self.blocks.0.attention.c_proj.bias.1)
  %5534 : Tensor = aten::add(%5533, %5532, %5530)
  %x.7 : Tensor = aten::add(%x.45, %5534, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:162:12
  %5239 : Tensor = aten::layer_norm(%x.7, %9, %self.blocks.11.ln_2.weight.1, %self.blocks.11.ln_2.bias.1, %11, %10) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2515:11
  %5535 : int = prim::Constant[value=1]()
  %5536 : Tensor = aten::t(%self.blocks.11.mlp.0.weight.1)
  %5537 : Tensor = aten::matmul(%5239, %5536)
  %5538 : Tensor = trt::const(%self.blocks.11.mlp.0.bias.1)
  %5539 : Tensor = aten::add(%5538, %5537, %5535)
  %5241 : Tensor = aten::mul(%5539, %15) # gptadv_static.py:26:15
  %5242 : Tensor = aten::div(%5539, %16) # gptadv_static.py:26:42
  %5243 : Tensor = aten::erf(%5242) # gptadv_static.py:26:32
  %5244 : Tensor = aten::add(%5243, %14, %17) # <string>:5:9
  %input.9 : Tensor = aten::mul(%5241, %5244) # gptadv_static.py:26:15
  %5540 : int = prim::Constant[value=1]()
  %5541 : Tensor = aten::t(%self.blocks.11.mlp.2.weight.1)
  %5542 : Tensor = aten::matmul(%input.9, %5541)
  %5543 : Tensor = trt::const(%self.blocks.11.mlp.2.bias.1)
  %5544 : Tensor = aten::add(%5543, %5542, %5540)
  %x.49 : Tensor = aten::add(%x.7, %5544, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:163:12
  %x.53 : Tensor = aten::layer_norm(%x.49, %9, %self.ln.weight.1, %self.ln.bias.1, %11, %10) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2515:11
  %5545 : Tensor = aten::t(%self.token_emb.weight.1) # <string>:3:35
  %5546 : Tensor = aten::matmul(%x.53, %5545) # <string>:3:16
  %5250 : Tensor = aten::select(%5546, %19, %18) # gptadv_static.py:237:20
  %5303 : Tensor = aten::reshape(%5250, %4)
  %ret.1 : Tensor = aten::softmax(%5303, %17, %20) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1843:14
  %new_token_idx.1 : Tensor = aten::argmax(%ret.1, %17, %21) # gptadv_static.py:241:24
  %5304 : Tensor = aten::reshape(%new_token_idx.1, %3)
  return (%5304)

DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Input Dimension Specs: {
}
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Input idx.1 (named: input_0): Input(shape: [-1], min: [1], opt: [8], max: [16], dtype: Int, format: NCHW\Contiguous\Linear) in engine (conversion.AddInputs)
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Input pos.1 (named: input_1): Input(shape: [-1], min: [1], opt: [8], max: [16], dtype: Int, format: NCHW\Contiguous\Linear) in engine (conversion.AddInputs)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.token_emb.weight.1 : Float(50257, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [50257, 768])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.pos_emb.weight.1 : Float(1024, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [1024, 768])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.0.ln_1.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [768])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.0.ln_1.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [768])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.0.attention.c_attn.weight : Float(2304, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [2304, 768])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.0.attention.c_attn.bias : Float(2304, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [2304])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.0.attention.n_embd : int = prim::Constant[value=768]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be: 768
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.0.attention.c_proj.weight.1 : Float(768, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [768, 768])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.0.attention.c_proj.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [768])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.0.ln_2.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [768])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.0.ln_2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [768])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.0.mlp.0.weight.1 : Float(3072, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [3072, 768])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.0.mlp.0.bias.1 : Float(3072, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [3072])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.0.mlp.2.weight.1 : Float(768, 3072, strides=[3072, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [768, 3072])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.0.mlp.2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [768])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.1.ln_1.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [768])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.1.ln_1.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [768])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.1.attention.c_attn.weight : Float(2304, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [2304, 768])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.1.attention.c_proj.weight.1 : Float(768, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [768, 768])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.1.ln_2.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [768])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.1.ln_2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [768])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.1.mlp.0.weight.1 : Float(3072, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [3072, 768])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.1.mlp.0.bias.1 : Float(3072, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [3072])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.1.mlp.2.weight.1 : Float(768, 3072, strides=[3072, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [768, 3072])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.1.mlp.2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [768])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.2.ln_1.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [768])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.2.ln_1.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [768])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.2.attention.c_attn.weight : Float(2304, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [2304, 768])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.2.attention.c_proj.weight.1 : Float(768, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [768, 768])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.2.ln_2.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [768])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.2.ln_2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [768])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.2.mlp.0.weight.1 : Float(3072, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [3072, 768])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.2.mlp.0.bias.1 : Float(3072, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [3072])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.2.mlp.2.weight.1 : Float(768, 3072, strides=[3072, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [768, 3072])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.2.mlp.2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [768])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.3.ln_1.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [768])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.3.ln_1.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [768])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.3.attention.c_attn.weight : Float(2304, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [2304, 768])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.3.attention.c_proj.weight.1 : Float(768, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [768, 768])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.3.ln_2.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [768])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.3.ln_2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [768])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.3.mlp.0.weight.1 : Float(3072, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [3072, 768])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.3.mlp.0.bias.1 : Float(3072, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [3072])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.3.mlp.2.weight.1 : Float(768, 3072, strides=[3072, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [768, 3072])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.3.mlp.2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [768])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.4.ln_1.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [768])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.4.ln_1.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [768])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.4.attention.c_attn.weight : Float(2304, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [2304, 768])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.4.attention.c_proj.weight.1 : Float(768, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [768, 768])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.4.ln_2.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [768])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.4.ln_2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [768])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.4.mlp.0.weight.1 : Float(3072, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [3072, 768])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.4.mlp.0.bias.1 : Float(3072, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [3072])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.4.mlp.2.weight.1 : Float(768, 3072, strides=[3072, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [768, 3072])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.4.mlp.2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [768])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.5.ln_1.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [768])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.5.ln_1.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [768])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.5.attention.c_attn.weight : Float(2304, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [2304, 768])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.5.attention.c_proj.weight.1 : Float(768, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [768, 768])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.5.ln_2.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [768])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.5.ln_2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [768])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.5.mlp.0.weight.1 : Float(3072, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [3072, 768])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.5.mlp.0.bias.1 : Float(3072, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [3072])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.5.mlp.2.weight.1 : Float(768, 3072, strides=[3072, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [768, 3072])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.5.mlp.2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [768])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.6.ln_1.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [768])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.6.ln_1.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [768])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.6.attention.c_attn.weight : Float(2304, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [2304, 768])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.6.attention.c_proj.weight.1 : Float(768, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [768, 768])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.6.ln_2.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [768])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.6.ln_2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [768])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.6.mlp.0.weight.1 : Float(3072, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [3072, 768])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.6.mlp.0.bias.1 : Float(3072, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [3072])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.6.mlp.2.weight.1 : Float(768, 3072, strides=[3072, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [768, 3072])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.6.mlp.2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [768])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.7.ln_1.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [768])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.7.ln_1.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [768])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.7.attention.c_attn.weight : Float(2304, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [2304, 768])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.7.attention.c_proj.weight.1 : Float(768, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [768, 768])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.7.ln_2.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [768])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.7.ln_2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [768])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.7.mlp.0.weight.1 : Float(3072, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [3072, 768])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.7.mlp.0.bias.1 : Float(3072, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [3072])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.7.mlp.2.weight.1 : Float(768, 3072, strides=[3072, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [768, 3072])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.7.mlp.2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [768])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.8.ln_1.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [768])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.8.ln_1.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [768])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.8.attention.c_attn.weight : Float(2304, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [2304, 768])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.8.attention.c_proj.weight.1 : Float(768, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [768, 768])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.8.ln_2.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [768])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.8.ln_2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [768])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.8.mlp.0.weight.1 : Float(3072, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [3072, 768])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.8.mlp.0.bias.1 : Float(3072, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [3072])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.8.mlp.2.weight.1 : Float(768, 3072, strides=[3072, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [768, 3072])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.8.mlp.2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [768])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.9.ln_1.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [768])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.9.ln_1.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [768])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.9.attention.c_attn.weight : Float(2304, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [2304, 768])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.9.attention.c_proj.weight.1 : Float(768, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [768, 768])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.9.ln_2.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [768])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.9.ln_2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [768])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.9.mlp.0.weight.1 : Float(3072, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [3072, 768])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.9.mlp.0.bias.1 : Float(3072, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [3072])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.9.mlp.2.weight.1 : Float(768, 3072, strides=[3072, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [768, 3072])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.9.mlp.2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [768])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.10.ln_1.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [768])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.10.ln_1.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [768])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.10.attention.c_attn.weight : Float(2304, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [2304, 768])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.10.attention.c_proj.weight.1 : Float(768, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [768, 768])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.10.ln_2.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [768])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.10.ln_2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [768])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.10.mlp.0.weight.1 : Float(3072, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [3072, 768])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.10.mlp.0.bias.1 : Float(3072, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [3072])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.10.mlp.2.weight.1 : Float(768, 3072, strides=[3072, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [768, 3072])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.10.mlp.2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [768])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.11.ln_1.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [768])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.11.ln_1.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [768])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.11.attention.c_attn.weight : Float(2304, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [2304, 768])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.11.attention.c_proj.weight.1 : Float(768, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [768, 768])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.11.ln_2.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [768])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.11.ln_2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [768])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.11.mlp.0.weight.1 : Float(3072, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [3072, 768])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.11.mlp.0.bias.1 : Float(3072, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [3072])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.11.mlp.2.weight.1 : Float(768, 3072, strides=[3072, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [768, 3072])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.blocks.11.mlp.2.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [768])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.ln.weight.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [768])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %self.ln.bias.1 : Float(768, strides=[1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [768])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %21 : bool = prim::Constant[value=0]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be: False
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %20 : NoneType = prim::Constant()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be: None
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %19 : int = prim::Constant[value=0]() # gptadv_static.py:237:20
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be: 0
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %18 : int = prim::Constant[value=-1]() # gptadv_static.py:237:27
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be: -1
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %17 : int = prim::Constant[value=1]() # gptadv_static.py:231:8
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be: 1
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %16 : float = prim::Constant[value=1.41421]() # gptadv_static.py:26:46
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be: 1.41421
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %15 : float = prim::Constant[value=0.5]() # gptadv_static.py:26:19
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be: 0.5
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %14 : float = prim::Constant[value=1.]() # gptadv_static.py:62:43
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be: 1.
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %13 : int = prim::Constant[value=2]() # gptadv_static.py:62:32
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be: 2
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %12 : int = prim::Constant[value=-2]() # gptadv_static.py:62:31
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be: -2
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %11 : float = prim::Constant[value=1.0000000000000001e-05]() # /opt/conda/lib/python3.8/site-packages/torch/nn/modules/normalization.py:191:66
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be: 1.0000000000000001e-05
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %10 : bool = prim::Constant[value=1]() # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2515:72
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be: True
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %9 : int[] = prim::Constant[value=[768]]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be: [768]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %8 : Float(32, 768, strides=[768, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be a tensor (shape [32, 768])
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %7 : int[] = prim::Constant[value=[-1, 12, 64]]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be: [-1, 12, 64]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %6 : float = prim::Constant[value=0.125]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be: 0.125
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %5 : int[] = prim::Constant[value=[-1, 768]]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be: [-1, 768]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %4 : int[] = prim::Constant[value=[-1, 50257]]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be: [-1, 50257]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %3 : int[] = prim::Constant[value=[-1, 1]]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be: [-1, 1]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %token_emb.3 : Tensor = aten::embedding(%self.token_emb.weight.1, %idx.1, %18, %21, %21) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2210:11 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found IValue containing object of type Float(50257, 768, strides=[768, 1], requires_grad=0, device=cuda:0)
DEBUG: [Torch-TensorRT] - Weights: [50257, 768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 50257
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a6d3660 as an IConstantLayer
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 0) [Constant]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [50257, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: input_0
DEBUG: [Torch-TensorRT] - ITensor shape: [-1]
DEBUG: [Torch-TensorRT] - ITensor type: Int32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %pos_emb.3 : Tensor = aten::embedding(%self.pos_emb.weight.1, %pos.1, %18, %21, %21) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2210:11 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found IValue containing object of type Float(1024, 768, strides=[768, 1], requires_grad=0, device=cuda:0)
DEBUG: [Torch-TensorRT] - Weights: [1024, 768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 1024
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a6d6d20 as an IConstantLayer
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 3) [Constant]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [1024, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: input_1
DEBUG: [Torch-TensorRT] - ITensor shape: [-1]
DEBUG: [Torch-TensorRT] - ITensor type: Int32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %x.1 : Tensor = aten::add(%token_emb.3, %pos_emb.3, %17) # gptadv_static.py:227:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 2) [Gather]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 5) [Gather]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %x_.2 : Tensor = aten::layer_norm(%x.1, %9, %self.blocks.0.ln_1.weight.1, %self.blocks.0.ln_1.bias.1, %11, %10) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2515:11 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - cudnn disregarded
DEBUG: [Torch-TensorRT] - Axis Mask for E[x]00000000000000000000000000000010
DEBUG: [Torch-TensorRT] - Weights: [1]
    Data Type: Float32
    Number of input maps: 1
    Number of output maps: 1
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a6d9830 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Weights: [1]
    Data Type: Float32
    Number of input maps: 1
    Number of output maps: 1
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a6daf20 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %5305 : int = prim::Constant[value=1]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be: 1
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5306 : Tensor = aten::t(%self.blocks.0.attention.c_attn.weight) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found IValue containing object of type Float(2304, 768, strides=[768, 1], requires_grad=0, device=cuda:0)
DEBUG: [Torch-TensorRT] - Weights: [2304, 768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 2304
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a6fc120 as an IConstantLayer
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 27) [Constant]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [2304, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [768, 2304]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5307 : Tensor = aten::matmul(%x_.2, %5306) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 26) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 28) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [768, 2304]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 2304]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5308 : Tensor = trt::const(%self.blocks.0.attention.c_attn.bias) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - Weights: [2304]
    Data Type: Float32
    Number of input maps: 2304
    Number of output maps: 2304
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor %5308 : Tensor = trt::const(%self.blocks.0.attention.c_attn.bias) as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [2304]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5309 : Tensor = aten::add(%5308, %5307, %5305) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 30) [Constant]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [2304]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 29) [Matrix Multiply]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 2304]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 2304]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %154 : Tensor[] = aten::split(%5309, %self.blocks.0.attention.n_embd, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:119:19 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 32) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 2304]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Number of split outputs: 3
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Int32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a6df3e0 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Int32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a705ca0 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Int32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a7081a0 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Converted split op into a list of IValues
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %q.2 : Tensor, %k.2 : Tensor, %v.2 : Tensor = prim::ListUnpack(%154)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the evaluated value(s) to be an ITensor of shape: [-1, 768]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the evaluated value(s) to be an ITensor of shape: [-1, 768]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the evaluated value(s) to be an ITensor of shape: [-1, 768]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %158 : Tensor[] = prim::ListConstruct(%8, %k.2)
DEBUG: [Torch-TensorRT] - Weights: [32, 768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 32
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a6fd250 as an IConstantLayer
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be: [<__torch__.torch.classes._torch_tensorrt_eval_ivalue_types.TensorContainer object at 0x56403a704e80>, <__torch__.torch.classes._torch_tensorrt_eval_ivalue_types.TensorContainer object at 0x56403a704f20>]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %160 : Tensor[] = prim::ListConstruct(%8, %q.2)
DEBUG: [Torch-TensorRT] - Weights: [32, 768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 32
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a7047f0 as an IConstantLayer
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be: [<__torch__.torch.classes._torch_tensorrt_eval_ivalue_types.TensorContainer object at 0x56403a704a10>, <__torch__.torch.classes._torch_tensorrt_eval_ivalue_types.TensorContainer object at 0x56403a704ab0>]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %162 : Tensor[] = prim::ListConstruct(%8, %v.2)
DEBUG: [Torch-TensorRT] - Weights: [32, 768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 32
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a706b70 as an IConstantLayer
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be: [<__torch__.torch.classes._torch_tensorrt_eval_ivalue_types.TensorContainer object at 0x56403a706d50>, <__torch__.torch.classes._torch_tensorrt_eval_ivalue_types.TensorContainer object at 0x56403a706dd0>]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %k.6 : Tensor = aten::cat(%158, %19) # gptadv_static.py:54:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5255 : Tensor = aten::reshape(%k.6, %7) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 42) [Concatenation]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Using dynamic version of reshape layer
DEBUG: [Torch-TensorRT] - Shape tensor is an IntList
DEBUG: [Torch-TensorRT] - Weights: [3]
    Data Type: Int32
    Number of input maps: 3
    Number of output maps: 3
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a751320 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 12, 64]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %q.6 : Tensor = aten::cat(%160, %19) # gptadv_static.py:55:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5256 : Tensor = aten::reshape(%q.6, %7) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 45) [Concatenation]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Using dynamic version of reshape layer
DEBUG: [Torch-TensorRT] - Shape tensor is an IntList
DEBUG: [Torch-TensorRT] - Weights: [3]
    Data Type: Int32
    Number of input maps: 3
    Number of output maps: 3
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a753830 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 12, 64]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %v.6 : Tensor = aten::cat(%162, %19) # gptadv_static.py:56:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5257 : Tensor = aten::reshape(%v.6, %7) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 48) [Concatenation]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Using dynamic version of reshape layer
DEBUG: [Torch-TensorRT] - Shape tensor is an IntList
DEBUG: [Torch-TensorRT] - Weights: [3]
    Data Type: Int32
    Number of input maps: 3
    Number of output maps: 3
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a7549a0 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 12, 64]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %k.10 : Tensor = aten::transpose(%5255, %19, %17) # gptadv_static.py:58:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 44) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 12, 64]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Shuffle to: [1, 0, 2]
DEBUG: [Torch-TensorRT] - Output tensor shape: [12, -1, 64]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %q.10 : Tensor = aten::transpose(%5256, %19, %17) # gptadv_static.py:59:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 47) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 12, 64]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Shuffle to: [1, 0, 2]
DEBUG: [Torch-TensorRT] - Output tensor shape: [12, -1, 64]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %v.10 : Tensor = aten::transpose(%5257, %19, %17) # gptadv_static.py:60:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 50) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 12, 64]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Shuffle to: [1, 0, 2]
DEBUG: [Torch-TensorRT] - Output tensor shape: [12, -1, 64]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %4633 : Tensor = aten::transpose(%k.10, %12, %18) # gptadv_static.py:62:19 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 51) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [12, -1, 64]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Shuffle to: [0, 2, 1]
DEBUG: [Torch-TensorRT] - Output tensor shape: [12, 64, -1]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %4634 : Tensor = aten::matmul(%q.10, %4633) # gptadv_static.py:62:15 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 52) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [12, -1, 64]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 54) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [12, 64, -1]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [12, -1, -1]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %att.2 : Tensor = aten::mul(%4634, %6) # gptadv_static.py:62:15 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 55) [Matrix Multiply]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [12, -1, -1]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Weights: [1]
    Data Type: Float32
    Number of input maps: 1
    Number of output maps: 1
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a7578f0 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [12, -1, -1]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %ret.24 : Tensor = aten::softmax(%att.2, %18, %20) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1843:14 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 58) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [12, -1, -1]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Softmax original dim -1
DEBUG: [Torch-TensorRT] - Softmax converted dim 2
DEBUG: [Torch-TensorRT] - Disregarding dtype argument
DEBUG: [Torch-TensorRT] - Output tensor shape: [12, -1, -1]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %y.3 : Tensor = aten::matmul(%ret.24, %v.10) # gptadv_static.py:66:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT] - ITensor name: ret.24
DEBUG: [Torch-TensorRT] - ITensor shape: [12, -1, -1]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 53) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [12, -1, 64]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [12, -1, 64]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %4638 : Tensor = aten::transpose(%y.3, %17, %13) # gptadv_static.py:67:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 60) [Matrix Multiply]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [12, -1, 64]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Shuffle to: [0, 2, 1]
DEBUG: [Torch-TensorRT] - Output tensor shape: [12, 64, -1]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5258 : Tensor = aten::reshape(%4638, %5) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 61) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [12, 64, -1]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Using dynamic version of reshape layer
DEBUG: [Torch-TensorRT] - Shape tensor is an IntList
DEBUG: [Torch-TensorRT] - Weights: [2]
    Data Type: Int32
    Number of input maps: 2
    Number of output maps: 2
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a755890 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %5310 : int = prim::Constant[value=1]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be: 1
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5311 : Tensor = aten::t(%self.blocks.0.attention.c_proj.weight.1) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found IValue containing object of type Float(768, 768, strides=[768, 1], requires_grad=0, device=cuda:0)
DEBUG: [Torch-TensorRT] - Weights: [768, 768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a75d320 as an IConstantLayer
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 64) [Constant]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [768, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [768, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5312 : Tensor = aten::matmul(%5258, %5311) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 63) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 65) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [768, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5313 : Tensor = trt::const(%self.blocks.0.attention.c_proj.bias.1) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor %5313 : Tensor = trt::const(%self.blocks.0.attention.c_proj.bias.1) as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5314 : Tensor = aten::add(%5313, %5312, %5310) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 67) [Constant]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 66) [Matrix Multiply]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %x.18 : Tensor = aten::add(%x.1, %5314, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:162:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 6) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 69) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %4643 : Tensor = aten::layer_norm(%x.18, %9, %self.blocks.0.ln_2.weight.1, %self.blocks.0.ln_2.bias.1, %11, %10) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2515:11 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - cudnn disregarded
DEBUG: [Torch-TensorRT] - Axis Mask for E[x]00000000000000000000000000000010
DEBUG: [Torch-TensorRT] - Weights: [1]
    Data Type: Float32
    Number of input maps: 1
    Number of output maps: 1
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a7606b0 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Weights: [1]
    Data Type: Float32
    Number of input maps: 1
    Number of output maps: 1
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a761e00 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %5315 : int = prim::Constant[value=1]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be: 1
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5316 : Tensor = aten::t(%self.blocks.0.mlp.0.weight.1) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found IValue containing object of type Float(3072, 768, strides=[768, 1], requires_grad=0, device=cuda:0)
DEBUG: [Torch-TensorRT] - Weights: [3072, 768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 3072
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a9ac170 as an IConstantLayer
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 91) [Constant]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [3072, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [768, 3072]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5317 : Tensor = aten::matmul(%4643, %5316) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 90) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 92) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [768, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 3072]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5318 : Tensor = trt::const(%self.blocks.0.mlp.0.bias.1) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - Weights: [3072]
    Data Type: Float32
    Number of input maps: 3072
    Number of output maps: 3072
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor %5318 : Tensor = trt::const(%self.blocks.0.mlp.0.bias.1) as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [3072]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5319 : Tensor = aten::add(%5318, %5317, %5315) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 94) [Constant]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 93) [Matrix Multiply]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 3072]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %4645 : Tensor = aten::mul(%5319, %15) # gptadv_static.py:26:15 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 96) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Weights: [1]
    Data Type: Float32
    Number of input maps: 1
    Number of output maps: 1
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a9af340 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 3072]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %4646 : Tensor = aten::div(%5319, %16) # gptadv_static.py:26:42 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 96) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Weights: [1]
    Data Type: Float32
    Number of input maps: 1
    Number of output maps: 1
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a9b3920 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 3072]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %4647 : Tensor = aten::erf(%4646) # gptadv_static.py:26:32 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 102) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 3072]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %4648 : Tensor = aten::add(%4647, %14, %17) # <string>:5:9 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 103) [Unary]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Weights: [1]
    Data Type: Float32
    Number of input maps: 1
    Number of output maps: 1
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a9b5fc0 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 3072]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %input.10 : Tensor = aten::mul(%4645, %4648) # gptadv_static.py:26:15 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 99) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 106) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 3072]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %5320 : int = prim::Constant[value=1]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be: 1
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5321 : Tensor = aten::t(%self.blocks.0.mlp.2.weight.1) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found IValue containing object of type Float(768, 3072, strides=[3072, 1], requires_grad=0, device=cuda:0)
DEBUG: [Torch-TensorRT] - Weights: [768, 3072]
    Data Type: Float32
    Number of input maps: 3072
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a9b6370 as an IConstantLayer
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 108) [Constant]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [768, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [3072, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5322 : Tensor = aten::matmul(%input.10, %5321) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 107) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 109) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [3072, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5323 : Tensor = trt::const(%self.blocks.0.mlp.2.bias.1) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor %5323 : Tensor = trt::const(%self.blocks.0.mlp.2.bias.1) as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5324 : Tensor = aten::add(%5323, %5322, %5320) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 111) [Constant]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 110) [Matrix Multiply]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %x.5 : Tensor = aten::add(%x.18, %5324, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:163:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 70) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 113) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %x_.4 : Tensor = aten::layer_norm(%x.5, %9, %self.blocks.1.ln_1.weight.1, %self.blocks.1.ln_1.bias.1, %11, %10) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2515:11 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - cudnn disregarded
DEBUG: [Torch-TensorRT] - Axis Mask for E[x]00000000000000000000000000000010
DEBUG: [Torch-TensorRT] - Weights: [1]
    Data Type: Float32
    Number of input maps: 1
    Number of output maps: 1
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a9b9340 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Weights: [1]
    Data Type: Float32
    Number of input maps: 1
    Number of output maps: 1
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a9bd890 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %5325 : int = prim::Constant[value=1]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be: 1
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5326 : Tensor = aten::t(%self.blocks.1.attention.c_attn.weight) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found IValue containing object of type Float(2304, 768, strides=[768, 1], requires_grad=0, device=cuda:0)
DEBUG: [Torch-TensorRT] - Weights: [2304, 768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 2304
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a9c86c0 as an IConstantLayer
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 135) [Constant]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [2304, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [768, 2304]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5327 : Tensor = aten::matmul(%x_.4, %5326) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 134) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 136) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [768, 2304]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 2304]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5328 : Tensor = trt::const(%self.blocks.0.attention.c_attn.bias) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - Weights: [2304]
    Data Type: Float32
    Number of input maps: 2304
    Number of output maps: 2304
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor %5328 : Tensor = trt::const(%self.blocks.0.attention.c_attn.bias) as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [2304]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5329 : Tensor = aten::add(%5328, %5327, %5325) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 138) [Constant]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [2304]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 137) [Matrix Multiply]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 2304]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 2304]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %191 : Tensor[] = aten::split(%5329, %self.blocks.0.attention.n_embd, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:119:19 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 140) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 2304]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Number of split outputs: 3
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Int32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a9bd210 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Int32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a9d2a60 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Int32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a9c9c00 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Converted split op into a list of IValues
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %q.12 : Tensor, %k.12 : Tensor, %v.12 : Tensor = prim::ListUnpack(%191)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the evaluated value(s) to be an ITensor of shape: [-1, 768]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the evaluated value(s) to be an ITensor of shape: [-1, 768]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the evaluated value(s) to be an ITensor of shape: [-1, 768]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %195 : Tensor[] = prim::ListConstruct(%8, %k.12)
DEBUG: [Torch-TensorRT] - Weights: [32, 768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 32
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a9c75a0 as an IConstantLayer
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be: [<__torch__.torch.classes._torch_tensorrt_eval_ivalue_types.TensorContainer object at 0x56403a9d2bc0>, <__torch__.torch.classes._torch_tensorrt_eval_ivalue_types.TensorContainer object at 0x56403a9d2c40>]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %197 : Tensor[] = prim::ListConstruct(%8, %q.12)
DEBUG: [Torch-TensorRT] - Weights: [32, 768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 32
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a9d2e60 as an IConstantLayer
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be: [<__torch__.torch.classes._torch_tensorrt_eval_ivalue_types.TensorContainer object at 0x56403a9d4440>, <__torch__.torch.classes._torch_tensorrt_eval_ivalue_types.TensorContainer object at 0x56403a9d44c0>]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %199 : Tensor[] = prim::ListConstruct(%8, %v.12)
DEBUG: [Torch-TensorRT] - Weights: [32, 768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 32
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a9d4850 as an IConstantLayer
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be: [<__torch__.torch.classes._torch_tensorrt_eval_ivalue_types.TensorContainer object at 0x56403a9cbc10>, <__torch__.torch.classes._torch_tensorrt_eval_ivalue_types.TensorContainer object at 0x56403a9cbcc0>]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %k.14 : Tensor = aten::cat(%195, %19) # gptadv_static.py:54:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5259 : Tensor = aten::reshape(%k.14, %7) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 150) [Concatenation]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Using dynamic version of reshape layer
DEBUG: [Torch-TensorRT] - Shape tensor is an IntList
DEBUG: [Torch-TensorRT] - Weights: [3]
    Data Type: Int32
    Number of input maps: 3
    Number of output maps: 3
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a9ed230 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 12, 64]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %q.14 : Tensor = aten::cat(%197, %19) # gptadv_static.py:55:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5260 : Tensor = aten::reshape(%q.14, %7) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 153) [Concatenation]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Using dynamic version of reshape layer
DEBUG: [Torch-TensorRT] - Shape tensor is an IntList
DEBUG: [Torch-TensorRT] - Weights: [3]
    Data Type: Int32
    Number of input maps: 3
    Number of output maps: 3
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a9d1420 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 12, 64]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %v.14 : Tensor = aten::cat(%199, %19) # gptadv_static.py:56:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5261 : Tensor = aten::reshape(%v.14, %7) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 156) [Concatenation]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Using dynamic version of reshape layer
DEBUG: [Torch-TensorRT] - Shape tensor is an IntList
DEBUG: [Torch-TensorRT] - Weights: [3]
    Data Type: Int32
    Number of input maps: 3
    Number of output maps: 3
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a9d36d0 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 12, 64]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %k.16 : Tensor = aten::transpose(%5259, %19, %17) # gptadv_static.py:58:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 152) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 12, 64]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Shuffle to: [1, 0, 2]
DEBUG: [Torch-TensorRT] - Output tensor shape: [12, -1, 64]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %q.16 : Tensor = aten::transpose(%5260, %19, %17) # gptadv_static.py:59:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 155) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 12, 64]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Shuffle to: [1, 0, 2]
DEBUG: [Torch-TensorRT] - Output tensor shape: [12, -1, 64]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %v.16 : Tensor = aten::transpose(%5261, %19, %17) # gptadv_static.py:60:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 158) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 12, 64]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Shuffle to: [1, 0, 2]
DEBUG: [Torch-TensorRT] - Output tensor shape: [12, -1, 64]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %4687 : Tensor = aten::transpose(%k.16, %12, %18) # gptadv_static.py:62:19 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 159) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [12, -1, 64]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Shuffle to: [0, 2, 1]
DEBUG: [Torch-TensorRT] - Output tensor shape: [12, 64, -1]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %4688 : Tensor = aten::matmul(%q.16, %4687) # gptadv_static.py:62:15 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 160) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [12, -1, 64]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 162) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [12, 64, -1]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [12, -1, -1]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %att.4 : Tensor = aten::mul(%4688, %6) # gptadv_static.py:62:15 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 163) [Matrix Multiply]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [12, -1, -1]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Weights: [1]
    Data Type: Float32
    Number of input maps: 1
    Number of output maps: 1
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a9f2990 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [12, -1, -1]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %ret.4 : Tensor = aten::softmax(%att.4, %18, %20) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1843:14 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 166) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [12, -1, -1]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Softmax original dim -1
DEBUG: [Torch-TensorRT] - Softmax converted dim 2
DEBUG: [Torch-TensorRT] - Disregarding dtype argument
DEBUG: [Torch-TensorRT] - Output tensor shape: [12, -1, -1]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %y.7 : Tensor = aten::matmul(%ret.4, %v.16) # gptadv_static.py:66:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT] - ITensor name: ret.4
DEBUG: [Torch-TensorRT] - ITensor shape: [12, -1, -1]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 161) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [12, -1, 64]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [12, -1, 64]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %4692 : Tensor = aten::transpose(%y.7, %17, %13) # gptadv_static.py:67:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 168) [Matrix Multiply]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [12, -1, 64]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Shuffle to: [0, 2, 1]
DEBUG: [Torch-TensorRT] - Output tensor shape: [12, 64, -1]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5262 : Tensor = aten::reshape(%4692, %5) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 169) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [12, 64, -1]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Using dynamic version of reshape layer
DEBUG: [Torch-TensorRT] - Shape tensor is an IntList
DEBUG: [Torch-TensorRT] - Weights: [2]
    Data Type: Int32
    Number of input maps: 2
    Number of output maps: 2
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a9f0690 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %5330 : int = prim::Constant[value=1]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be: 1
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5331 : Tensor = aten::t(%self.blocks.1.attention.c_proj.weight.1) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found IValue containing object of type Float(768, 768, strides=[768, 1], requires_grad=0, device=cuda:0)
DEBUG: [Torch-TensorRT] - Weights: [768, 768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a9f6110 as an IConstantLayer
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 172) [Constant]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [768, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [768, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5332 : Tensor = aten::matmul(%5262, %5331) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 171) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 173) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [768, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5333 : Tensor = trt::const(%self.blocks.0.attention.c_proj.bias.1) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor %5333 : Tensor = trt::const(%self.blocks.0.attention.c_proj.bias.1) as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5334 : Tensor = aten::add(%5333, %5332, %5330) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 175) [Constant]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 174) [Matrix Multiply]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %x.22 : Tensor = aten::add(%x.5, %5334, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:162:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 114) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 177) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %4697 : Tensor = aten::layer_norm(%x.22, %9, %self.blocks.1.ln_2.weight.1, %self.blocks.1.ln_2.bias.1, %11, %10) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2515:11 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - cudnn disregarded
DEBUG: [Torch-TensorRT] - Axis Mask for E[x]00000000000000000000000000000010
DEBUG: [Torch-TensorRT] - Weights: [1]
    Data Type: Float32
    Number of input maps: 1
    Number of output maps: 1
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a79bf90 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Weights: [1]
    Data Type: Float32
    Number of input maps: 1
    Number of output maps: 1
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a798e50 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %5335 : int = prim::Constant[value=1]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be: 1
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5336 : Tensor = aten::t(%self.blocks.1.mlp.0.weight.1) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found IValue containing object of type Float(3072, 768, strides=[768, 1], requires_grad=0, device=cuda:0)
DEBUG: [Torch-TensorRT] - Weights: [3072, 768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 3072
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a9f4ec0 as an IConstantLayer
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 199) [Constant]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [3072, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [768, 3072]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5337 : Tensor = aten::matmul(%4697, %5336) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 198) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 200) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [768, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 3072]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5338 : Tensor = trt::const(%self.blocks.1.mlp.0.bias.1) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - Weights: [3072]
    Data Type: Float32
    Number of input maps: 3072
    Number of output maps: 3072
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor %5338 : Tensor = trt::const(%self.blocks.1.mlp.0.bias.1) as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [3072]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5339 : Tensor = aten::add(%5338, %5337, %5335) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 202) [Constant]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 201) [Matrix Multiply]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 3072]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %4699 : Tensor = aten::mul(%5339, %15) # gptadv_static.py:26:15 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 204) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Weights: [1]
    Data Type: Float32
    Number of input maps: 1
    Number of output maps: 1
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a7a7ec0 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 3072]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %4700 : Tensor = aten::div(%5339, %16) # gptadv_static.py:26:42 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 204) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Weights: [1]
    Data Type: Float32
    Number of input maps: 1
    Number of output maps: 1
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a7af6a0 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 3072]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %4701 : Tensor = aten::erf(%4700) # gptadv_static.py:26:32 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 210) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 3072]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %4702 : Tensor = aten::add(%4701, %14, %17) # <string>:5:9 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 211) [Unary]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Weights: [1]
    Data Type: Float32
    Number of input maps: 1
    Number of output maps: 1
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a7a8d60 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 3072]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %input.18 : Tensor = aten::mul(%4699, %4702) # gptadv_static.py:26:15 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 207) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 214) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 3072]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %5340 : int = prim::Constant[value=1]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be: 1
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5341 : Tensor = aten::t(%self.blocks.1.mlp.2.weight.1) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found IValue containing object of type Float(768, 3072, strides=[3072, 1], requires_grad=0, device=cuda:0)
DEBUG: [Torch-TensorRT] - Weights: [768, 3072]
    Data Type: Float32
    Number of input maps: 3072
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a9f66f0 as an IConstantLayer
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 216) [Constant]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [768, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [3072, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5342 : Tensor = aten::matmul(%input.18, %5341) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 215) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 217) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [3072, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5343 : Tensor = trt::const(%self.blocks.1.mlp.2.bias.1) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor %5343 : Tensor = trt::const(%self.blocks.1.mlp.2.bias.1) as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5344 : Tensor = aten::add(%5343, %5342, %5340) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 219) [Constant]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 218) [Matrix Multiply]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %x.9 : Tensor = aten::add(%x.22, %5344, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:163:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 178) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 221) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %x_.6 : Tensor = aten::layer_norm(%x.9, %9, %self.blocks.2.ln_1.weight.1, %self.blocks.2.ln_1.bias.1, %11, %10) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2515:11 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - cudnn disregarded
DEBUG: [Torch-TensorRT] - Axis Mask for E[x]00000000000000000000000000000010
DEBUG: [Torch-TensorRT] - Weights: [1]
    Data Type: Float32
    Number of input maps: 1
    Number of output maps: 1
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a7b95d0 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Weights: [1]
    Data Type: Float32
    Number of input maps: 1
    Number of output maps: 1
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a7afc00 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %5345 : int = prim::Constant[value=1]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be: 1
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5346 : Tensor = aten::t(%self.blocks.2.attention.c_attn.weight) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found IValue containing object of type Float(2304, 768, strides=[768, 1], requires_grad=0, device=cuda:0)
DEBUG: [Torch-TensorRT] - Weights: [2304, 768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 2304
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a7bfa90 as an IConstantLayer
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 243) [Constant]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [2304, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [768, 2304]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5347 : Tensor = aten::matmul(%x_.6, %5346) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 242) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 244) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [768, 2304]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 2304]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5348 : Tensor = trt::const(%self.blocks.0.attention.c_attn.bias) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - Weights: [2304]
    Data Type: Float32
    Number of input maps: 2304
    Number of output maps: 2304
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor %5348 : Tensor = trt::const(%self.blocks.0.attention.c_attn.bias) as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [2304]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5349 : Tensor = aten::add(%5348, %5347, %5345) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 246) [Constant]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [2304]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 245) [Matrix Multiply]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 2304]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 2304]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %228 : Tensor[] = aten::split(%5349, %self.blocks.0.attention.n_embd, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:119:19 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 248) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 2304]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Number of split outputs: 3
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Int32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a7affb0 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Int32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a7cca20 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Int32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a7ce2a0 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Converted split op into a list of IValues
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %q.18 : Tensor, %k.18 : Tensor, %v.18 : Tensor = prim::ListUnpack(%228)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the evaluated value(s) to be an ITensor of shape: [-1, 768]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the evaluated value(s) to be an ITensor of shape: [-1, 768]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the evaluated value(s) to be an ITensor of shape: [-1, 768]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %232 : Tensor[] = prim::ListConstruct(%8, %k.18)
DEBUG: [Torch-TensorRT] - Weights: [32, 768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 32
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a7c3570 as an IConstantLayer
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be: [<__torch__.torch.classes._torch_tensorrt_eval_ivalue_types.TensorContainer object at 0x56403a7b8f60>, <__torch__.torch.classes._torch_tensorrt_eval_ivalue_types.TensorContainer object at 0x56403a7c7050>]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %234 : Tensor[] = prim::ListConstruct(%8, %q.18)
DEBUG: [Torch-TensorRT] - Weights: [32, 768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 32
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a7c3810 as an IConstantLayer
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be: [<__torch__.torch.classes._torch_tensorrt_eval_ivalue_types.TensorContainer object at 0x56403a7c38b0>, <__torch__.torch.classes._torch_tensorrt_eval_ivalue_types.TensorContainer object at 0x56403a7c1bf0>]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %236 : Tensor[] = prim::ListConstruct(%8, %v.18)
DEBUG: [Torch-TensorRT] - Weights: [32, 768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 32
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a7c6900 as an IConstantLayer
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be: [<__torch__.torch.classes._torch_tensorrt_eval_ivalue_types.TensorContainer object at 0x56403a7c6ae0>, <__torch__.torch.classes._torch_tensorrt_eval_ivalue_types.TensorContainer object at 0x56403a7c6e80>]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %k.20 : Tensor = aten::cat(%232, %19) # gptadv_static.py:54:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5263 : Tensor = aten::reshape(%k.20, %7) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 258) [Concatenation]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Using dynamic version of reshape layer
DEBUG: [Torch-TensorRT] - Shape tensor is an IntList
DEBUG: [Torch-TensorRT] - Weights: [3]
    Data Type: Int32
    Number of input maps: 3
    Number of output maps: 3
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a7cbe90 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 12, 64]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %q.20 : Tensor = aten::cat(%234, %19) # gptadv_static.py:55:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5264 : Tensor = aten::reshape(%q.20, %7) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 261) [Concatenation]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Using dynamic version of reshape layer
DEBUG: [Torch-TensorRT] - Shape tensor is an IntList
DEBUG: [Torch-TensorRT] - Weights: [3]
    Data Type: Int32
    Number of input maps: 3
    Number of output maps: 3
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a7cb210 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 12, 64]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %v.20 : Tensor = aten::cat(%236, %19) # gptadv_static.py:56:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5265 : Tensor = aten::reshape(%v.20, %7) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 264) [Concatenation]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Using dynamic version of reshape layer
DEBUG: [Torch-TensorRT] - Shape tensor is an IntList
DEBUG: [Torch-TensorRT] - Weights: [3]
    Data Type: Int32
    Number of input maps: 3
    Number of output maps: 3
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a81dde0 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 12, 64]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %k.22 : Tensor = aten::transpose(%5263, %19, %17) # gptadv_static.py:58:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 260) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 12, 64]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Shuffle to: [1, 0, 2]
DEBUG: [Torch-TensorRT] - Output tensor shape: [12, -1, 64]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %q.22 : Tensor = aten::transpose(%5264, %19, %17) # gptadv_static.py:59:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 263) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 12, 64]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Shuffle to: [1, 0, 2]
DEBUG: [Torch-TensorRT] - Output tensor shape: [12, -1, 64]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %v.22 : Tensor = aten::transpose(%5265, %19, %17) # gptadv_static.py:60:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 266) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 12, 64]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Shuffle to: [1, 0, 2]
DEBUG: [Torch-TensorRT] - Output tensor shape: [12, -1, 64]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %4741 : Tensor = aten::transpose(%k.22, %12, %18) # gptadv_static.py:62:19 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 267) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [12, -1, 64]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Shuffle to: [0, 2, 1]
DEBUG: [Torch-TensorRT] - Output tensor shape: [12, 64, -1]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %4742 : Tensor = aten::matmul(%q.22, %4741) # gptadv_static.py:62:15 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 268) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [12, -1, 64]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 270) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [12, 64, -1]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [12, -1, -1]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %att.6 : Tensor = aten::mul(%4742, %6) # gptadv_static.py:62:15 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 271) [Matrix Multiply]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [12, -1, -1]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Weights: [1]
    Data Type: Float32
    Number of input maps: 1
    Number of output maps: 1
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a8192a0 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [12, -1, -1]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %ret.6 : Tensor = aten::softmax(%att.6, %18, %20) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1843:14 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 274) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [12, -1, -1]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Softmax original dim -1
DEBUG: [Torch-TensorRT] - Softmax converted dim 2
DEBUG: [Torch-TensorRT] - Disregarding dtype argument
DEBUG: [Torch-TensorRT] - Output tensor shape: [12, -1, -1]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %y.11 : Tensor = aten::matmul(%ret.6, %v.22) # gptadv_static.py:66:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT] - ITensor name: ret.6
DEBUG: [Torch-TensorRT] - ITensor shape: [12, -1, -1]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 269) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [12, -1, 64]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [12, -1, 64]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %4746 : Tensor = aten::transpose(%y.11, %17, %13) # gptadv_static.py:67:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 276) [Matrix Multiply]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [12, -1, 64]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Shuffle to: [0, 2, 1]
DEBUG: [Torch-TensorRT] - Output tensor shape: [12, 64, -1]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5266 : Tensor = aten::reshape(%4746, %5) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 277) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [12, 64, -1]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Using dynamic version of reshape layer
DEBUG: [Torch-TensorRT] - Shape tensor is an IntList
DEBUG: [Torch-TensorRT] - Weights: [2]
    Data Type: Int32
    Number of input maps: 2
    Number of output maps: 2
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a81c170 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %5350 : int = prim::Constant[value=1]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be: 1
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5351 : Tensor = aten::t(%self.blocks.2.attention.c_proj.weight.1) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found IValue containing object of type Float(768, 768, strides=[768, 1], requires_grad=0, device=cuda:0)
DEBUG: [Torch-TensorRT] - Weights: [768, 768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a81b2f0 as an IConstantLayer
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 280) [Constant]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [768, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [768, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5352 : Tensor = aten::matmul(%5266, %5351) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 279) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 281) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [768, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5353 : Tensor = trt::const(%self.blocks.0.attention.c_proj.bias.1) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor %5353 : Tensor = trt::const(%self.blocks.0.attention.c_proj.bias.1) as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5354 : Tensor = aten::add(%5353, %5352, %5350) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 283) [Constant]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 282) [Matrix Multiply]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %x.26 : Tensor = aten::add(%x.9, %5354, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:162:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 222) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 285) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %4751 : Tensor = aten::layer_norm(%x.26, %9, %self.blocks.2.ln_2.weight.1, %self.blocks.2.ln_2.bias.1, %11, %10) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2515:11 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - cudnn disregarded
DEBUG: [Torch-TensorRT] - Axis Mask for E[x]00000000000000000000000000000010
DEBUG: [Torch-TensorRT] - Weights: [1]
    Data Type: Float32
    Number of input maps: 1
    Number of output maps: 1
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a821dd0 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Weights: [1]
    Data Type: Float32
    Number of input maps: 1
    Number of output maps: 1
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a82fec0 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %5355 : int = prim::Constant[value=1]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be: 1
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5356 : Tensor = aten::t(%self.blocks.2.mlp.0.weight.1) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found IValue containing object of type Float(3072, 768, strides=[768, 1], requires_grad=0, device=cuda:0)
DEBUG: [Torch-TensorRT] - Weights: [3072, 768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 3072
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a82a9c0 as an IConstantLayer
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 307) [Constant]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [3072, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [768, 3072]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5357 : Tensor = aten::matmul(%4751, %5356) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 306) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 308) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [768, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 3072]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5358 : Tensor = trt::const(%self.blocks.2.mlp.0.bias.1) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - Weights: [3072]
    Data Type: Float32
    Number of input maps: 3072
    Number of output maps: 3072
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor %5358 : Tensor = trt::const(%self.blocks.2.mlp.0.bias.1) as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [3072]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5359 : Tensor = aten::add(%5358, %5357, %5355) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 310) [Constant]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 309) [Matrix Multiply]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 3072]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %4753 : Tensor = aten::mul(%5359, %15) # gptadv_static.py:26:15 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 312) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Weights: [1]
    Data Type: Float32
    Number of input maps: 1
    Number of output maps: 1
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a83b3b0 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 3072]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %4754 : Tensor = aten::div(%5359, %16) # gptadv_static.py:26:42 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 312) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Weights: [1]
    Data Type: Float32
    Number of input maps: 1
    Number of output maps: 1
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a83c2a0 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 3072]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %4755 : Tensor = aten::erf(%4754) # gptadv_static.py:26:32 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 318) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 3072]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %4756 : Tensor = aten::add(%4755, %14, %17) # <string>:5:9 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 319) [Unary]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Weights: [1]
    Data Type: Float32
    Number of input maps: 1
    Number of output maps: 1
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a83c820 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 3072]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %input.24 : Tensor = aten::mul(%4753, %4756) # gptadv_static.py:26:15 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 315) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 322) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 3072]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %5360 : int = prim::Constant[value=1]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be: 1
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5361 : Tensor = aten::t(%self.blocks.2.mlp.2.weight.1) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found IValue containing object of type Float(768, 3072, strides=[3072, 1], requires_grad=0, device=cuda:0)
DEBUG: [Torch-TensorRT] - Weights: [768, 3072]
    Data Type: Float32
    Number of input maps: 3072
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a83dd70 as an IConstantLayer
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 324) [Constant]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [768, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [3072, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5362 : Tensor = aten::matmul(%input.24, %5361) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 323) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 325) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [3072, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5363 : Tensor = trt::const(%self.blocks.2.mlp.2.bias.1) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor %5363 : Tensor = trt::const(%self.blocks.2.mlp.2.bias.1) as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5364 : Tensor = aten::add(%5363, %5362, %5360) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 327) [Constant]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 326) [Matrix Multiply]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %x.14 : Tensor = aten::add(%x.26, %5364, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:163:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 286) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 329) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %x_.8 : Tensor = aten::layer_norm(%x.14, %9, %self.blocks.3.ln_1.weight.1, %self.blocks.3.ln_1.bias.1, %11, %10) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2515:11 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - cudnn disregarded
DEBUG: [Torch-TensorRT] - Axis Mask for E[x]00000000000000000000000000000010
DEBUG: [Torch-TensorRT] - Weights: [1]
    Data Type: Float32
    Number of input maps: 1
    Number of output maps: 1
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a844090 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Weights: [1]
    Data Type: Float32
    Number of input maps: 1
    Number of output maps: 1
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a842c40 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %5365 : int = prim::Constant[value=1]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be: 1
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5366 : Tensor = aten::t(%self.blocks.3.attention.c_attn.weight) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found IValue containing object of type Float(2304, 768, strides=[768, 1], requires_grad=0, device=cuda:0)
DEBUG: [Torch-TensorRT] - Weights: [2304, 768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 2304
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a84a350 as an IConstantLayer
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 351) [Constant]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [2304, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [768, 2304]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5367 : Tensor = aten::matmul(%x_.8, %5366) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 350) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 352) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [768, 2304]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 2304]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5368 : Tensor = trt::const(%self.blocks.0.attention.c_attn.bias) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - Weights: [2304]
    Data Type: Float32
    Number of input maps: 2304
    Number of output maps: 2304
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor %5368 : Tensor = trt::const(%self.blocks.0.attention.c_attn.bias) as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [2304]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5369 : Tensor = aten::add(%5368, %5367, %5365) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 354) [Constant]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [2304]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 353) [Matrix Multiply]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 2304]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 2304]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %265 : Tensor[] = aten::split(%5369, %self.blocks.0.attention.n_embd, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:119:19 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 356) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 2304]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Number of split outputs: 3
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Int32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a83e440 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Int32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a83e3a0 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Int32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a8563e0 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Converted split op into a list of IValues
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %q.24 : Tensor, %k.24 : Tensor, %v.24 : Tensor = prim::ListUnpack(%265)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the evaluated value(s) to be an ITensor of shape: [-1, 768]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the evaluated value(s) to be an ITensor of shape: [-1, 768]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the evaluated value(s) to be an ITensor of shape: [-1, 768]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %269 : Tensor[] = prim::ListConstruct(%8, %k.24)
DEBUG: [Torch-TensorRT] - Weights: [32, 768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 32
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a83e780 as an IConstantLayer
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be: [<__torch__.torch.classes._torch_tensorrt_eval_ivalue_types.TensorContainer object at 0x56403a83e550>, <__torch__.torch.classes._torch_tensorrt_eval_ivalue_types.TensorContainer object at 0x56403a84dd00>]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %271 : Tensor[] = prim::ListConstruct(%8, %q.24)
DEBUG: [Torch-TensorRT] - Weights: [32, 768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 32
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a8433d0 as an IConstantLayer
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be: [<__torch__.torch.classes._torch_tensorrt_eval_ivalue_types.TensorContainer object at 0x56403a84dae0>, <__torch__.torch.classes._torch_tensorrt_eval_ivalue_types.TensorContainer object at 0x56403a835370>]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %273 : Tensor[] = prim::ListConstruct(%8, %v.24)
DEBUG: [Torch-TensorRT] - Weights: [32, 768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 32
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a8430c0 as an IConstantLayer
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be: [<__torch__.torch.classes._torch_tensorrt_eval_ivalue_types.TensorContainer object at 0x56403a84d6b0>, <__torch__.torch.classes._torch_tensorrt_eval_ivalue_types.TensorContainer object at 0x56403a84d760>]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %k.26 : Tensor = aten::cat(%269, %19) # gptadv_static.py:54:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5267 : Tensor = aten::reshape(%k.26, %7) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 366) [Concatenation]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Using dynamic version of reshape layer
DEBUG: [Torch-TensorRT] - Shape tensor is an IntList
DEBUG: [Torch-TensorRT] - Weights: [3]
    Data Type: Int32
    Number of input maps: 3
    Number of output maps: 3
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a8a2c10 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 12, 64]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %q.26 : Tensor = aten::cat(%271, %19) # gptadv_static.py:55:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5268 : Tensor = aten::reshape(%q.26, %7) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 369) [Concatenation]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Using dynamic version of reshape layer
DEBUG: [Torch-TensorRT] - Shape tensor is an IntList
DEBUG: [Torch-TensorRT] - Weights: [3]
    Data Type: Int32
    Number of input maps: 3
    Number of output maps: 3
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a8a4e60 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 12, 64]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %v.26 : Tensor = aten::cat(%273, %19) # gptadv_static.py:56:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5269 : Tensor = aten::reshape(%v.26, %7) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 372) [Concatenation]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Using dynamic version of reshape layer
DEBUG: [Torch-TensorRT] - Shape tensor is an IntList
DEBUG: [Torch-TensorRT] - Weights: [3]
    Data Type: Int32
    Number of input maps: 3
    Number of output maps: 3
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a855e30 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 12, 64]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %k.28 : Tensor = aten::transpose(%5267, %19, %17) # gptadv_static.py:58:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 368) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 12, 64]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Shuffle to: [1, 0, 2]
DEBUG: [Torch-TensorRT] - Output tensor shape: [12, -1, 64]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %q.28 : Tensor = aten::transpose(%5268, %19, %17) # gptadv_static.py:59:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 371) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 12, 64]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Shuffle to: [1, 0, 2]
DEBUG: [Torch-TensorRT] - Output tensor shape: [12, -1, 64]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %v.28 : Tensor = aten::transpose(%5269, %19, %17) # gptadv_static.py:60:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 374) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 12, 64]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Shuffle to: [1, 0, 2]
DEBUG: [Torch-TensorRT] - Output tensor shape: [12, -1, 64]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %4795 : Tensor = aten::transpose(%k.28, %12, %18) # gptadv_static.py:62:19 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 375) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [12, -1, 64]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Shuffle to: [0, 2, 1]
DEBUG: [Torch-TensorRT] - Output tensor shape: [12, 64, -1]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %4796 : Tensor = aten::matmul(%q.28, %4795) # gptadv_static.py:62:15 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 376) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [12, -1, 64]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 378) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [12, 64, -1]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [12, -1, -1]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %att.8 : Tensor = aten::mul(%4796, %6) # gptadv_static.py:62:15 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 379) [Matrix Multiply]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [12, -1, -1]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Weights: [1]
    Data Type: Float32
    Number of input maps: 1
    Number of output maps: 1
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a8a5d60 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [12, -1, -1]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %ret.8 : Tensor = aten::softmax(%att.8, %18, %20) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1843:14 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 382) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [12, -1, -1]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Softmax original dim -1
DEBUG: [Torch-TensorRT] - Softmax converted dim 2
DEBUG: [Torch-TensorRT] - Disregarding dtype argument
DEBUG: [Torch-TensorRT] - Output tensor shape: [12, -1, -1]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %y.15 : Tensor = aten::matmul(%ret.8, %v.28) # gptadv_static.py:66:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT] - ITensor name: ret.8
DEBUG: [Torch-TensorRT] - ITensor shape: [12, -1, -1]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 377) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [12, -1, 64]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [12, -1, 64]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %4800 : Tensor = aten::transpose(%y.15, %17, %13) # gptadv_static.py:67:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 384) [Matrix Multiply]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [12, -1, 64]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Shuffle to: [0, 2, 1]
DEBUG: [Torch-TensorRT] - Output tensor shape: [12, 64, -1]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5270 : Tensor = aten::reshape(%4800, %5) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 385) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [12, 64, -1]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Using dynamic version of reshape layer
DEBUG: [Torch-TensorRT] - Shape tensor is an IntList
DEBUG: [Torch-TensorRT] - Weights: [2]
    Data Type: Int32
    Number of input maps: 2
    Number of output maps: 2
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a8af2d0 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %5370 : int = prim::Constant[value=1]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be: 1
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5371 : Tensor = aten::t(%self.blocks.3.attention.c_proj.weight.1) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found IValue containing object of type Float(768, 768, strides=[768, 1], requires_grad=0, device=cuda:0)
DEBUG: [Torch-TensorRT] - Weights: [768, 768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a8a3af0 as an IConstantLayer
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 388) [Constant]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [768, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [768, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5372 : Tensor = aten::matmul(%5270, %5371) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 387) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 389) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [768, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5373 : Tensor = trt::const(%self.blocks.0.attention.c_proj.bias.1) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor %5373 : Tensor = trt::const(%self.blocks.0.attention.c_proj.bias.1) as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5374 : Tensor = aten::add(%5373, %5372, %5370) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 391) [Constant]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 390) [Matrix Multiply]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %x.30 : Tensor = aten::add(%x.14, %5374, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:162:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 330) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 393) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %4805 : Tensor = aten::layer_norm(%x.30, %9, %self.blocks.3.ln_2.weight.1, %self.blocks.3.ln_2.bias.1, %11, %10) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2515:11 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - cudnn disregarded
DEBUG: [Torch-TensorRT] - Axis Mask for E[x]00000000000000000000000000000010
DEBUG: [Torch-TensorRT] - Weights: [1]
    Data Type: Float32
    Number of input maps: 1
    Number of output maps: 1
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a8ad3d0 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Weights: [1]
    Data Type: Float32
    Number of input maps: 1
    Number of output maps: 1
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a8587c0 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %5375 : int = prim::Constant[value=1]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be: 1
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5376 : Tensor = aten::t(%self.blocks.3.mlp.0.weight.1) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found IValue containing object of type Float(3072, 768, strides=[768, 1], requires_grad=0, device=cuda:0)
DEBUG: [Torch-TensorRT] - Weights: [3072, 768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 3072
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a8bbe20 as an IConstantLayer
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 415) [Constant]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [3072, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [768, 3072]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5377 : Tensor = aten::matmul(%4805, %5376) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 414) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 416) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [768, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 3072]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5378 : Tensor = trt::const(%self.blocks.3.mlp.0.bias.1) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - Weights: [3072]
    Data Type: Float32
    Number of input maps: 3072
    Number of output maps: 3072
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor %5378 : Tensor = trt::const(%self.blocks.3.mlp.0.bias.1) as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [3072]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5379 : Tensor = aten::add(%5378, %5377, %5375) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 418) [Constant]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 417) [Matrix Multiply]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 3072]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %4807 : Tensor = aten::mul(%5379, %15) # gptadv_static.py:26:15 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 420) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Weights: [1]
    Data Type: Float32
    Number of input maps: 1
    Number of output maps: 1
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a8adfe0 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 3072]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %4808 : Tensor = aten::div(%5379, %16) # gptadv_static.py:26:42 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 420) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Weights: [1]
    Data Type: Float32
    Number of input maps: 1
    Number of output maps: 1
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a8b0bf0 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 3072]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %4809 : Tensor = aten::erf(%4808) # gptadv_static.py:26:32 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 426) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 3072]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %4810 : Tensor = aten::add(%4809, %14, %17) # <string>:5:9 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 427) [Unary]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Weights: [1]
    Data Type: Float32
    Number of input maps: 1
    Number of output maps: 1
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a8af100 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 3072]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %input.30 : Tensor = aten::mul(%4807, %4810) # gptadv_static.py:26:15 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 423) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 430) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 3072]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %5380 : int = prim::Constant[value=1]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be: 1
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5381 : Tensor = aten::t(%self.blocks.3.mlp.2.weight.1) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found IValue containing object of type Float(768, 3072, strides=[3072, 1], requires_grad=0, device=cuda:0)
DEBUG: [Torch-TensorRT] - Weights: [768, 3072]
    Data Type: Float32
    Number of input maps: 3072
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a8c14a0 as an IConstantLayer
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 432) [Constant]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [768, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [3072, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5382 : Tensor = aten::matmul(%input.30, %5381) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 431) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 433) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [3072, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5383 : Tensor = trt::const(%self.blocks.3.mlp.2.bias.1) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor %5383 : Tensor = trt::const(%self.blocks.3.mlp.2.bias.1) as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5384 : Tensor = aten::add(%5383, %5382, %5380) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 435) [Constant]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 434) [Matrix Multiply]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %x.17 : Tensor = aten::add(%x.30, %5384, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:163:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 394) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 437) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %x_.10 : Tensor = aten::layer_norm(%x.17, %9, %self.blocks.4.ln_1.weight.1, %self.blocks.4.ln_1.bias.1, %11, %10) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2515:11 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - cudnn disregarded
DEBUG: [Torch-TensorRT] - Axis Mask for E[x]00000000000000000000000000000010
DEBUG: [Torch-TensorRT] - Weights: [1]
    Data Type: Float32
    Number of input maps: 1
    Number of output maps: 1
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a8c2790 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Weights: [1]
    Data Type: Float32
    Number of input maps: 1
    Number of output maps: 1
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a8cb990 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %5385 : int = prim::Constant[value=1]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be: 1
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5386 : Tensor = aten::t(%self.blocks.4.attention.c_attn.weight) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found IValue containing object of type Float(2304, 768, strides=[768, 1], requires_grad=0, device=cuda:0)
DEBUG: [Torch-TensorRT] - Weights: [2304, 768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 2304
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a8d2ba0 as an IConstantLayer
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 459) [Constant]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [2304, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [768, 2304]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5387 : Tensor = aten::matmul(%x_.10, %5386) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 458) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 460) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [768, 2304]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 2304]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5388 : Tensor = trt::const(%self.blocks.0.attention.c_attn.bias) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - Weights: [2304]
    Data Type: Float32
    Number of input maps: 2304
    Number of output maps: 2304
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor %5388 : Tensor = trt::const(%self.blocks.0.attention.c_attn.bias) as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [2304]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5389 : Tensor = aten::add(%5388, %5387, %5385) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 462) [Constant]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [2304]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 461) [Matrix Multiply]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 2304]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 2304]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %302 : Tensor[] = aten::split(%5389, %self.blocks.0.attention.n_embd, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:119:19 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 464) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 2304]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Number of split outputs: 3
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Int32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a8cfff0 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Int32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a8ca440 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Int32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a8deb60 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Converted split op into a list of IValues
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %q.30 : Tensor, %k.30 : Tensor, %v.30 : Tensor = prim::ListUnpack(%302)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the evaluated value(s) to be an ITensor of shape: [-1, 768]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the evaluated value(s) to be an ITensor of shape: [-1, 768]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the evaluated value(s) to be an ITensor of shape: [-1, 768]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %306 : Tensor[] = prim::ListConstruct(%8, %k.30)
DEBUG: [Torch-TensorRT] - Weights: [32, 768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 32
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a8debd0 as an IConstantLayer
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be: [<__torch__.torch.classes._torch_tensorrt_eval_ivalue_types.TensorContainer object at 0x56403a8e0780>, <__torch__.torch.classes._torch_tensorrt_eval_ivalue_types.TensorContainer object at 0x56403a8d8ef0>]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %308 : Tensor[] = prim::ListConstruct(%8, %q.30)
DEBUG: [Torch-TensorRT] - Weights: [32, 768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 32
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a8c9a70 as an IConstantLayer
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be: [<__torch__.torch.classes._torch_tensorrt_eval_ivalue_types.TensorContainer object at 0x56403a8d1230>, <__torch__.torch.classes._torch_tensorrt_eval_ivalue_types.TensorContainer object at 0x56403a8d12b0>]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %310 : Tensor[] = prim::ListConstruct(%8, %v.30)
DEBUG: [Torch-TensorRT] - Weights: [32, 768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 32
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a8c9ae0 as an IConstantLayer
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be: [<__torch__.torch.classes._torch_tensorrt_eval_ivalue_types.TensorContainer object at 0x56403a8d59d0>, <__torch__.torch.classes._torch_tensorrt_eval_ivalue_types.TensorContainer object at 0x56403a8d5a80>]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %k.32 : Tensor = aten::cat(%306, %19) # gptadv_static.py:54:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5271 : Tensor = aten::reshape(%k.32, %7) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 474) [Concatenation]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Using dynamic version of reshape layer
DEBUG: [Torch-TensorRT] - Shape tensor is an IntList
DEBUG: [Torch-TensorRT] - Weights: [3]
    Data Type: Int32
    Number of input maps: 3
    Number of output maps: 3
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a92ded0 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 12, 64]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %q.32 : Tensor = aten::cat(%308, %19) # gptadv_static.py:55:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5272 : Tensor = aten::reshape(%q.32, %7) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 477) [Concatenation]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Using dynamic version of reshape layer
DEBUG: [Torch-TensorRT] - Shape tensor is an IntList
DEBUG: [Torch-TensorRT] - Weights: [3]
    Data Type: Int32
    Number of input maps: 3
    Number of output maps: 3
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a8df050 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 12, 64]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %v.32 : Tensor = aten::cat(%310, %19) # gptadv_static.py:56:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5273 : Tensor = aten::reshape(%v.32, %7) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 480) [Concatenation]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Using dynamic version of reshape layer
DEBUG: [Torch-TensorRT] - Shape tensor is an IntList
DEBUG: [Torch-TensorRT] - Weights: [3]
    Data Type: Int32
    Number of input maps: 3
    Number of output maps: 3
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a8dfc60 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 12, 64]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %k.34 : Tensor = aten::transpose(%5271, %19, %17) # gptadv_static.py:58:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 476) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 12, 64]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Shuffle to: [1, 0, 2]
DEBUG: [Torch-TensorRT] - Output tensor shape: [12, -1, 64]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %q.34 : Tensor = aten::transpose(%5272, %19, %17) # gptadv_static.py:59:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 479) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 12, 64]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Shuffle to: [1, 0, 2]
DEBUG: [Torch-TensorRT] - Output tensor shape: [12, -1, 64]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %v.34 : Tensor = aten::transpose(%5273, %19, %17) # gptadv_static.py:60:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 482) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 12, 64]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Shuffle to: [1, 0, 2]
DEBUG: [Torch-TensorRT] - Output tensor shape: [12, -1, 64]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %4849 : Tensor = aten::transpose(%k.34, %12, %18) # gptadv_static.py:62:19 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 483) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [12, -1, 64]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Shuffle to: [0, 2, 1]
DEBUG: [Torch-TensorRT] - Output tensor shape: [12, 64, -1]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %4850 : Tensor = aten::matmul(%q.34, %4849) # gptadv_static.py:62:15 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 484) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [12, -1, 64]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 486) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [12, 64, -1]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [12, -1, -1]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %att.10 : Tensor = aten::mul(%4850, %6) # gptadv_static.py:62:15 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 487) [Matrix Multiply]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [12, -1, -1]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Weights: [1]
    Data Type: Float32
    Number of input maps: 1
    Number of output maps: 1
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a9326b0 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [12, -1, -1]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %ret.10 : Tensor = aten::softmax(%att.10, %18, %20) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1843:14 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 490) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [12, -1, -1]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Softmax original dim -1
DEBUG: [Torch-TensorRT] - Softmax converted dim 2
DEBUG: [Torch-TensorRT] - Disregarding dtype argument
DEBUG: [Torch-TensorRT] - Output tensor shape: [12, -1, -1]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %y.19 : Tensor = aten::matmul(%ret.10, %v.34) # gptadv_static.py:66:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT] - ITensor name: ret.10
DEBUG: [Torch-TensorRT] - ITensor shape: [12, -1, -1]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 485) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [12, -1, 64]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [12, -1, 64]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %4854 : Tensor = aten::transpose(%y.19, %17, %13) # gptadv_static.py:67:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 492) [Matrix Multiply]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [12, -1, 64]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Shuffle to: [0, 2, 1]
DEBUG: [Torch-TensorRT] - Output tensor shape: [12, 64, -1]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5274 : Tensor = aten::reshape(%4854, %5) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 493) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [12, 64, -1]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Using dynamic version of reshape layer
DEBUG: [Torch-TensorRT] - Shape tensor is an IntList
DEBUG: [Torch-TensorRT] - Weights: [2]
    Data Type: Int32
    Number of input maps: 2
    Number of output maps: 2
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a8d83a0 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %5390 : int = prim::Constant[value=1]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be: 1
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5391 : Tensor = aten::t(%self.blocks.4.attention.c_proj.weight.1) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found IValue containing object of type Float(768, 768, strides=[768, 1], requires_grad=0, device=cuda:0)
DEBUG: [Torch-TensorRT] - Weights: [768, 768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a93bd80 as an IConstantLayer
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 496) [Constant]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [768, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [768, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5392 : Tensor = aten::matmul(%5274, %5391) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 495) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 497) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [768, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5393 : Tensor = trt::const(%self.blocks.0.attention.c_proj.bias.1) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor %5393 : Tensor = trt::const(%self.blocks.0.attention.c_proj.bias.1) as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5394 : Tensor = aten::add(%5393, %5392, %5390) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 499) [Constant]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 498) [Matrix Multiply]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %x.34 : Tensor = aten::add(%x.17, %5394, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:162:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 438) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 501) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %4859 : Tensor = aten::layer_norm(%x.34, %9, %self.blocks.4.ln_2.weight.1, %self.blocks.4.ln_2.bias.1, %11, %10) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2515:11 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - cudnn disregarded
DEBUG: [Torch-TensorRT] - Axis Mask for E[x]00000000000000000000000000000010
DEBUG: [Torch-TensorRT] - Weights: [1]
    Data Type: Float32
    Number of input maps: 1
    Number of output maps: 1
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a93f800 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Weights: [1]
    Data Type: Float32
    Number of input maps: 1
    Number of output maps: 1
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a940cb0 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %5395 : int = prim::Constant[value=1]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be: 1
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5396 : Tensor = aten::t(%self.blocks.4.mlp.0.weight.1) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found IValue containing object of type Float(3072, 768, strides=[768, 1], requires_grad=0, device=cuda:0)
DEBUG: [Torch-TensorRT] - Weights: [3072, 768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 3072
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a93af10 as an IConstantLayer
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 523) [Constant]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [3072, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [768, 3072]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5397 : Tensor = aten::matmul(%4859, %5396) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 522) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 524) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [768, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 3072]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5398 : Tensor = trt::const(%self.blocks.4.mlp.0.bias.1) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - Weights: [3072]
    Data Type: Float32
    Number of input maps: 3072
    Number of output maps: 3072
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor %5398 : Tensor = trt::const(%self.blocks.4.mlp.0.bias.1) as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [3072]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5399 : Tensor = aten::add(%5398, %5397, %5395) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 526) [Constant]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 525) [Matrix Multiply]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 3072]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %4861 : Tensor = aten::mul(%5399, %15) # gptadv_static.py:26:15 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 528) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Weights: [1]
    Data Type: Float32
    Number of input maps: 1
    Number of output maps: 1
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a94b950 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 3072]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %4862 : Tensor = aten::div(%5399, %16) # gptadv_static.py:26:42 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 528) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Weights: [1]
    Data Type: Float32
    Number of input maps: 1
    Number of output maps: 1
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a94f2a0 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 3072]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %4863 : Tensor = aten::erf(%4862) # gptadv_static.py:26:32 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 534) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 3072]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %4864 : Tensor = aten::add(%4863, %14, %17) # <string>:5:9 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 535) [Unary]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Weights: [1]
    Data Type: Float32
    Number of input maps: 1
    Number of output maps: 1
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a9328b0 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 3072]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %input.36 : Tensor = aten::mul(%4861, %4864) # gptadv_static.py:26:15 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 531) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 538) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 3072]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %5400 : int = prim::Constant[value=1]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be: 1
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5401 : Tensor = aten::t(%self.blocks.4.mlp.2.weight.1) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found IValue containing object of type Float(768, 3072, strides=[3072, 1], requires_grad=0, device=cuda:0)
DEBUG: [Torch-TensorRT] - Weights: [768, 3072]
    Data Type: Float32
    Number of input maps: 3072
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a9566c0 as an IConstantLayer
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 540) [Constant]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [768, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [3072, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5402 : Tensor = aten::matmul(%input.36, %5401) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 539) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 541) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [3072, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5403 : Tensor = trt::const(%self.blocks.4.mlp.2.bias.1) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor %5403 : Tensor = trt::const(%self.blocks.4.mlp.2.bias.1) as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5404 : Tensor = aten::add(%5403, %5402, %5400) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 543) [Constant]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 542) [Matrix Multiply]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %x.21 : Tensor = aten::add(%x.34, %5404, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:163:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 502) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 545) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %x_.12 : Tensor = aten::layer_norm(%x.21, %9, %self.blocks.5.ln_1.weight.1, %self.blocks.5.ln_1.bias.1, %11, %10) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2515:11 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - cudnn disregarded
DEBUG: [Torch-TensorRT] - Axis Mask for E[x]00000000000000000000000000000010
DEBUG: [Torch-TensorRT] - Weights: [1]
    Data Type: Float32
    Number of input maps: 1
    Number of output maps: 1
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a954470 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Weights: [1]
    Data Type: Float32
    Number of input maps: 1
    Number of output maps: 1
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a946a70 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %5405 : int = prim::Constant[value=1]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be: 1
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5406 : Tensor = aten::t(%self.blocks.5.attention.c_attn.weight) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found IValue containing object of type Float(2304, 768, strides=[768, 1], requires_grad=0, device=cuda:0)
DEBUG: [Torch-TensorRT] - Weights: [2304, 768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 2304
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a968820 as an IConstantLayer
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 567) [Constant]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [2304, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [768, 2304]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5407 : Tensor = aten::matmul(%x_.12, %5406) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 566) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 568) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [768, 2304]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 2304]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5408 : Tensor = trt::const(%self.blocks.0.attention.c_attn.bias) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - Weights: [2304]
    Data Type: Float32
    Number of input maps: 2304
    Number of output maps: 2304
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor %5408 : Tensor = trt::const(%self.blocks.0.attention.c_attn.bias) as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [2304]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5409 : Tensor = aten::add(%5408, %5407, %5405) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 570) [Constant]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [2304]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 569) [Matrix Multiply]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 2304]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 2304]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %339 : Tensor[] = aten::split(%5409, %self.blocks.0.attention.n_embd, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:119:19 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 572) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 2304]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Number of split outputs: 3
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Int32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a9698e0 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Int32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a95d8e0 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Int32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a9598a0 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Converted split op into a list of IValues
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %q.36 : Tensor, %k.36 : Tensor, %v.36 : Tensor = prim::ListUnpack(%339)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the evaluated value(s) to be an ITensor of shape: [-1, 768]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the evaluated value(s) to be an ITensor of shape: [-1, 768]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the evaluated value(s) to be an ITensor of shape: [-1, 768]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %343 : Tensor[] = prim::ListConstruct(%8, %k.36)
DEBUG: [Torch-TensorRT] - Weights: [32, 768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 32
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a964770 as an IConstantLayer
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be: [<__torch__.torch.classes._torch_tensorrt_eval_ivalue_types.TensorContainer object at 0x56403a95bf70>, <__torch__.torch.classes._torch_tensorrt_eval_ivalue_types.TensorContainer object at 0x56403a9693f0>]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %345 : Tensor[] = prim::ListConstruct(%8, %q.36)
DEBUG: [Torch-TensorRT] - Weights: [32, 768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 32
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a95a480 as an IConstantLayer
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be: [<__torch__.torch.classes._torch_tensorrt_eval_ivalue_types.TensorContainer object at 0x56403a966160>, <__torch__.torch.classes._torch_tensorrt_eval_ivalue_types.TensorContainer object at 0x56403a9661e0>]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %347 : Tensor[] = prim::ListConstruct(%8, %v.36)
DEBUG: [Torch-TensorRT] - Weights: [32, 768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 32
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a9407a0 as an IConstantLayer
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be: [<__torch__.torch.classes._torch_tensorrt_eval_ivalue_types.TensorContainer object at 0x56403a950a70>, <__torch__.torch.classes._torch_tensorrt_eval_ivalue_types.TensorContainer object at 0x56403a950b20>]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %k.38 : Tensor = aten::cat(%343, %19) # gptadv_static.py:54:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5275 : Tensor = aten::reshape(%k.38, %7) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 582) [Concatenation]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Using dynamic version of reshape layer
DEBUG: [Torch-TensorRT] - Shape tensor is an IntList
DEBUG: [Torch-TensorRT] - Weights: [3]
    Data Type: Int32
    Number of input maps: 3
    Number of output maps: 3
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a969e90 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 12, 64]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %q.38 : Tensor = aten::cat(%345, %19) # gptadv_static.py:55:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5276 : Tensor = aten::reshape(%q.38, %7) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 585) [Concatenation]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Using dynamic version of reshape layer
DEBUG: [Torch-TensorRT] - Shape tensor is an IntList
DEBUG: [Torch-TensorRT] - Weights: [3]
    Data Type: Int32
    Number of input maps: 3
    Number of output maps: 3
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a9a43f0 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 12, 64]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %v.38 : Tensor = aten::cat(%347, %19) # gptadv_static.py:56:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5277 : Tensor = aten::reshape(%v.38, %7) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 588) [Concatenation]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Using dynamic version of reshape layer
DEBUG: [Torch-TensorRT] - Shape tensor is an IntList
DEBUG: [Torch-TensorRT] - Weights: [3]
    Data Type: Int32
    Number of input maps: 3
    Number of output maps: 3
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56404125b7a0 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 12, 64]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %k.40 : Tensor = aten::transpose(%5275, %19, %17) # gptadv_static.py:58:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 584) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 12, 64]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Shuffle to: [1, 0, 2]
DEBUG: [Torch-TensorRT] - Output tensor shape: [12, -1, 64]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %q.40 : Tensor = aten::transpose(%5276, %19, %17) # gptadv_static.py:59:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 587) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 12, 64]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Shuffle to: [1, 0, 2]
DEBUG: [Torch-TensorRT] - Output tensor shape: [12, -1, 64]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %v.40 : Tensor = aten::transpose(%5277, %19, %17) # gptadv_static.py:60:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 590) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 12, 64]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Shuffle to: [1, 0, 2]
DEBUG: [Torch-TensorRT] - Output tensor shape: [12, -1, 64]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %4903 : Tensor = aten::transpose(%k.40, %12, %18) # gptadv_static.py:62:19 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 591) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [12, -1, 64]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Shuffle to: [0, 2, 1]
DEBUG: [Torch-TensorRT] - Output tensor shape: [12, 64, -1]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %4904 : Tensor = aten::matmul(%q.40, %4903) # gptadv_static.py:62:15 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 592) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [12, -1, 64]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 594) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [12, 64, -1]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [12, -1, -1]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %att.12 : Tensor = aten::mul(%4904, %6) # gptadv_static.py:62:15 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 595) [Matrix Multiply]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [12, -1, -1]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Weights: [1]
    Data Type: Float32
    Number of input maps: 1
    Number of output maps: 1
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a9a67e0 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [12, -1, -1]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %ret.12 : Tensor = aten::softmax(%att.12, %18, %20) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1843:14 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 598) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [12, -1, -1]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Softmax original dim -1
DEBUG: [Torch-TensorRT] - Softmax converted dim 2
DEBUG: [Torch-TensorRT] - Disregarding dtype argument
DEBUG: [Torch-TensorRT] - Output tensor shape: [12, -1, -1]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %y.23 : Tensor = aten::matmul(%ret.12, %v.40) # gptadv_static.py:66:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT] - ITensor name: ret.12
DEBUG: [Torch-TensorRT] - ITensor shape: [12, -1, -1]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 593) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [12, -1, 64]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [12, -1, 64]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %4908 : Tensor = aten::transpose(%y.23, %17, %13) # gptadv_static.py:67:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 600) [Matrix Multiply]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [12, -1, 64]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Shuffle to: [0, 2, 1]
DEBUG: [Torch-TensorRT] - Output tensor shape: [12, 64, -1]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5278 : Tensor = aten::reshape(%4908, %5) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 601) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [12, 64, -1]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Using dynamic version of reshape layer
DEBUG: [Torch-TensorRT] - Shape tensor is an IntList
DEBUG: [Torch-TensorRT] - Weights: [2]
    Data Type: Int32
    Number of input maps: 2
    Number of output maps: 2
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a970420 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %5410 : int = prim::Constant[value=1]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be: 1
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5411 : Tensor = aten::t(%self.blocks.5.attention.c_proj.weight.1) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found IValue containing object of type Float(768, 768, strides=[768, 1], requires_grad=0, device=cuda:0)
DEBUG: [Torch-TensorRT] - Weights: [768, 768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a965610 as an IConstantLayer
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 604) [Constant]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [768, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [768, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5412 : Tensor = aten::matmul(%5278, %5411) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 603) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 605) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [768, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5413 : Tensor = trt::const(%self.blocks.0.attention.c_proj.bias.1) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor %5413 : Tensor = trt::const(%self.blocks.0.attention.c_proj.bias.1) as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5414 : Tensor = aten::add(%5413, %5412, %5410) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 607) [Constant]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 606) [Matrix Multiply]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %x.38 : Tensor = aten::add(%x.21, %5414, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:162:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 546) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 609) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %4913 : Tensor = aten::layer_norm(%x.38, %9, %self.blocks.5.ln_2.weight.1, %self.blocks.5.ln_2.bias.1, %11, %10) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2515:11 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - cudnn disregarded
DEBUG: [Torch-TensorRT] - Axis Mask for E[x]00000000000000000000000000000010
DEBUG: [Torch-TensorRT] - Weights: [1]
    Data Type: Float32
    Number of input maps: 1
    Number of output maps: 1
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a96aa50 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Weights: [1]
    Data Type: Float32
    Number of input maps: 1
    Number of output maps: 1
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a96bea0 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %5415 : int = prim::Constant[value=1]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be: 1
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5416 : Tensor = aten::t(%self.blocks.5.mlp.0.weight.1) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found IValue containing object of type Float(3072, 768, strides=[768, 1], requires_grad=0, device=cuda:0)
DEBUG: [Torch-TensorRT] - Weights: [3072, 768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 3072
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x564041257c50 as an IConstantLayer
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 631) [Constant]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [3072, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [768, 3072]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5417 : Tensor = aten::matmul(%4913, %5416) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 630) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 632) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [768, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 3072]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5418 : Tensor = trt::const(%self.blocks.5.mlp.0.bias.1) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - Weights: [3072]
    Data Type: Float32
    Number of input maps: 3072
    Number of output maps: 3072
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor %5418 : Tensor = trt::const(%self.blocks.5.mlp.0.bias.1) as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [3072]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5419 : Tensor = aten::add(%5418, %5417, %5415) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 634) [Constant]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 633) [Matrix Multiply]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 3072]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %4915 : Tensor = aten::mul(%5419, %15) # gptadv_static.py:26:15 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 636) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Weights: [1]
    Data Type: Float32
    Number of input maps: 1
    Number of output maps: 1
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x564041252970 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 3072]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %4916 : Tensor = aten::div(%5419, %16) # gptadv_static.py:26:42 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 636) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Weights: [1]
    Data Type: Float32
    Number of input maps: 1
    Number of output maps: 1
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x564041252b20 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 3072]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %4917 : Tensor = aten::erf(%4916) # gptadv_static.py:26:32 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 642) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 3072]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %4918 : Tensor = aten::add(%4917, %14, %17) # <string>:5:9 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 643) [Unary]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Weights: [1]
    Data Type: Float32
    Number of input maps: 1
    Number of output maps: 1
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a947340 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 3072]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %input.42 : Tensor = aten::mul(%4915, %4918) # gptadv_static.py:26:15 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 639) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 646) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 3072]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %5420 : int = prim::Constant[value=1]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be: 1
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5421 : Tensor = aten::t(%self.blocks.5.mlp.2.weight.1) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found IValue containing object of type Float(768, 3072, strides=[3072, 1], requires_grad=0, device=cuda:0)
DEBUG: [Torch-TensorRT] - Weights: [768, 3072]
    Data Type: Float32
    Number of input maps: 3072
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56404125ea90 as an IConstantLayer
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 648) [Constant]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [768, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [3072, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5422 : Tensor = aten::matmul(%input.42, %5421) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 647) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 649) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [3072, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5423 : Tensor = trt::const(%self.blocks.5.mlp.2.bias.1) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor %5423 : Tensor = trt::const(%self.blocks.5.mlp.2.bias.1) as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5424 : Tensor = aten::add(%5423, %5422, %5420) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 651) [Constant]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 650) [Matrix Multiply]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %x.25 : Tensor = aten::add(%x.38, %5424, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:163:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 610) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 653) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %x_.14 : Tensor = aten::layer_norm(%x.25, %9, %self.blocks.6.ln_1.weight.1, %self.blocks.6.ln_1.bias.1, %11, %10) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2515:11 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - cudnn disregarded
DEBUG: [Torch-TensorRT] - Axis Mask for E[x]00000000000000000000000000000010
DEBUG: [Torch-TensorRT] - Weights: [1]
    Data Type: Float32
    Number of input maps: 1
    Number of output maps: 1
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a971df0 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Weights: [1]
    Data Type: Float32
    Number of input maps: 1
    Number of output maps: 1
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56404126d740 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %5425 : int = prim::Constant[value=1]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be: 1
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5426 : Tensor = aten::t(%self.blocks.6.attention.c_attn.weight) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found IValue containing object of type Float(2304, 768, strides=[768, 1], requires_grad=0, device=cuda:0)
DEBUG: [Torch-TensorRT] - Weights: [2304, 768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 2304
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56404126dc10 as an IConstantLayer
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 675) [Constant]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [2304, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [768, 2304]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5427 : Tensor = aten::matmul(%x_.14, %5426) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 674) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 676) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [768, 2304]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 2304]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5428 : Tensor = trt::const(%self.blocks.0.attention.c_attn.bias) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - Weights: [2304]
    Data Type: Float32
    Number of input maps: 2304
    Number of output maps: 2304
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor %5428 : Tensor = trt::const(%self.blocks.0.attention.c_attn.bias) as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [2304]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5429 : Tensor = aten::add(%5428, %5427, %5425) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 678) [Constant]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [2304]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 677) [Matrix Multiply]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 2304]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 2304]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %376 : Tensor[] = aten::split(%5429, %self.blocks.0.attention.n_embd, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:119:19 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 680) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 2304]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Number of split outputs: 3
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Int32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x564041267020 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Int32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a971200 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Int32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56404125f760 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Converted split op into a list of IValues
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %q.42 : Tensor, %k.42 : Tensor, %v.42 : Tensor = prim::ListUnpack(%376)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the evaluated value(s) to be an ITensor of shape: [-1, 768]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the evaluated value(s) to be an ITensor of shape: [-1, 768]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the evaluated value(s) to be an ITensor of shape: [-1, 768]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %380 : Tensor[] = prim::ListConstruct(%8, %k.42)
DEBUG: [Torch-TensorRT] - Weights: [32, 768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 32
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56404127daf0 as an IConstantLayer
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be: [<__torch__.torch.classes._torch_tensorrt_eval_ivalue_types.TensorContainer object at 0x564041254c50>, <__torch__.torch.classes._torch_tensorrt_eval_ivalue_types.TensorContainer object at 0x56404126fa30>]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %382 : Tensor[] = prim::ListConstruct(%8, %q.42)
DEBUG: [Torch-TensorRT] - Weights: [32, 768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 32
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56404128a6b0 as an IConstantLayer
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be: [<__torch__.torch.classes._torch_tensorrt_eval_ivalue_types.TensorContainer object at 0x56403a970cb0>, <__torch__.torch.classes._torch_tensorrt_eval_ivalue_types.TensorContainer object at 0x56403a970d30>]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %384 : Tensor[] = prim::ListConstruct(%8, %v.42)
DEBUG: [Torch-TensorRT] - Weights: [32, 768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 32
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a95ea50 as an IConstantLayer
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be: [<__torch__.torch.classes._torch_tensorrt_eval_ivalue_types.TensorContainer object at 0x564041273540>, <__torch__.torch.classes._torch_tensorrt_eval_ivalue_types.TensorContainer object at 0x56403a95eaf0>]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %k.44 : Tensor = aten::cat(%380, %19) # gptadv_static.py:54:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5279 : Tensor = aten::reshape(%k.44, %7) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 690) [Concatenation]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Using dynamic version of reshape layer
DEBUG: [Torch-TensorRT] - Shape tensor is an IntList
DEBUG: [Torch-TensorRT] - Weights: [3]
    Data Type: Int32
    Number of input maps: 3
    Number of output maps: 3
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56404127bb70 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 12, 64]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %q.44 : Tensor = aten::cat(%382, %19) # gptadv_static.py:55:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5280 : Tensor = aten::reshape(%q.44, %7) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 693) [Concatenation]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Using dynamic version of reshape layer
DEBUG: [Torch-TensorRT] - Shape tensor is an IntList
DEBUG: [Torch-TensorRT] - Weights: [3]
    Data Type: Int32
    Number of input maps: 3
    Number of output maps: 3
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x564041276020 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 12, 64]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %v.44 : Tensor = aten::cat(%384, %19) # gptadv_static.py:56:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5281 : Tensor = aten::reshape(%v.44, %7) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 696) [Concatenation]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Using dynamic version of reshape layer
DEBUG: [Torch-TensorRT] - Shape tensor is an IntList
DEBUG: [Torch-TensorRT] - Weights: [3]
    Data Type: Int32
    Number of input maps: 3
    Number of output maps: 3
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x564041277dd0 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 12, 64]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %k.46 : Tensor = aten::transpose(%5279, %19, %17) # gptadv_static.py:58:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 692) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 12, 64]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Shuffle to: [1, 0, 2]
DEBUG: [Torch-TensorRT] - Output tensor shape: [12, -1, 64]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %q.46 : Tensor = aten::transpose(%5280, %19, %17) # gptadv_static.py:59:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 695) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 12, 64]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Shuffle to: [1, 0, 2]
DEBUG: [Torch-TensorRT] - Output tensor shape: [12, -1, 64]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %v.46 : Tensor = aten::transpose(%5281, %19, %17) # gptadv_static.py:60:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 698) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 12, 64]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Shuffle to: [1, 0, 2]
DEBUG: [Torch-TensorRT] - Output tensor shape: [12, -1, 64]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %4957 : Tensor = aten::transpose(%k.46, %12, %18) # gptadv_static.py:62:19 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 699) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [12, -1, 64]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Shuffle to: [0, 2, 1]
DEBUG: [Torch-TensorRT] - Output tensor shape: [12, 64, -1]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %4958 : Tensor = aten::matmul(%q.46, %4957) # gptadv_static.py:62:15 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 700) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [12, -1, 64]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 702) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [12, 64, -1]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [12, -1, -1]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %att.14 : Tensor = aten::mul(%4958, %6) # gptadv_static.py:62:15 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 703) [Matrix Multiply]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [12, -1, -1]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Weights: [1]
    Data Type: Float32
    Number of input maps: 1
    Number of output maps: 1
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x5640412e6760 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [12, -1, -1]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %ret.14 : Tensor = aten::softmax(%att.14, %18, %20) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1843:14 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 706) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [12, -1, -1]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Softmax original dim -1
DEBUG: [Torch-TensorRT] - Softmax converted dim 2
DEBUG: [Torch-TensorRT] - Disregarding dtype argument
DEBUG: [Torch-TensorRT] - Output tensor shape: [12, -1, -1]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %y.27 : Tensor = aten::matmul(%ret.14, %v.46) # gptadv_static.py:66:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT] - ITensor name: ret.14
DEBUG: [Torch-TensorRT] - ITensor shape: [12, -1, -1]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 701) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [12, -1, 64]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [12, -1, 64]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %4962 : Tensor = aten::transpose(%y.27, %17, %13) # gptadv_static.py:67:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 708) [Matrix Multiply]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [12, -1, 64]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Shuffle to: [0, 2, 1]
DEBUG: [Torch-TensorRT] - Output tensor shape: [12, 64, -1]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5282 : Tensor = aten::reshape(%4962, %5) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 709) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [12, 64, -1]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Using dynamic version of reshape layer
DEBUG: [Torch-TensorRT] - Shape tensor is an IntList
DEBUG: [Torch-TensorRT] - Weights: [2]
    Data Type: Int32
    Number of input maps: 2
    Number of output maps: 2
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x5640412897b0 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %5430 : int = prim::Constant[value=1]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be: 1
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5431 : Tensor = aten::t(%self.blocks.6.attention.c_proj.weight.1) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found IValue containing object of type Float(768, 768, strides=[768, 1], requires_grad=0, device=cuda:0)
DEBUG: [Torch-TensorRT] - Weights: [768, 768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x564041279470 as an IConstantLayer
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 712) [Constant]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [768, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [768, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5432 : Tensor = aten::matmul(%5282, %5431) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 711) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 713) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [768, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5433 : Tensor = trt::const(%self.blocks.0.attention.c_proj.bias.1) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor %5433 : Tensor = trt::const(%self.blocks.0.attention.c_proj.bias.1) as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5434 : Tensor = aten::add(%5433, %5432, %5430) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 715) [Constant]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 714) [Matrix Multiply]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %x.42 : Tensor = aten::add(%x.25, %5434, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:162:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 654) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 717) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %4967 : Tensor = aten::layer_norm(%x.42, %9, %self.blocks.6.ln_2.weight.1, %self.blocks.6.ln_2.bias.1, %11, %10) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2515:11 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - cudnn disregarded
DEBUG: [Torch-TensorRT] - Axis Mask for E[x]00000000000000000000000000000010
DEBUG: [Torch-TensorRT] - Weights: [1]
    Data Type: Float32
    Number of input maps: 1
    Number of output maps: 1
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x5640412d3f50 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Weights: [1]
    Data Type: Float32
    Number of input maps: 1
    Number of output maps: 1
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x5640412e3e60 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %5435 : int = prim::Constant[value=1]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be: 1
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5436 : Tensor = aten::t(%self.blocks.6.mlp.0.weight.1) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found IValue containing object of type Float(3072, 768, strides=[768, 1], requires_grad=0, device=cuda:0)
DEBUG: [Torch-TensorRT] - Weights: [3072, 768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 3072
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x564041277040 as an IConstantLayer
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 739) [Constant]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [3072, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [768, 3072]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5437 : Tensor = aten::matmul(%4967, %5436) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 738) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 740) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [768, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 3072]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5438 : Tensor = trt::const(%self.blocks.6.mlp.0.bias.1) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - Weights: [3072]
    Data Type: Float32
    Number of input maps: 3072
    Number of output maps: 3072
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor %5438 : Tensor = trt::const(%self.blocks.6.mlp.0.bias.1) as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [3072]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5439 : Tensor = aten::add(%5438, %5437, %5435) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 742) [Constant]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 741) [Matrix Multiply]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 3072]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %4969 : Tensor = aten::mul(%5439, %15) # gptadv_static.py:26:15 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 744) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Weights: [1]
    Data Type: Float32
    Number of input maps: 1
    Number of output maps: 1
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56404125fd70 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 3072]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %4970 : Tensor = aten::div(%5439, %16) # gptadv_static.py:26:42 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 744) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Weights: [1]
    Data Type: Float32
    Number of input maps: 1
    Number of output maps: 1
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56404125f910 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 3072]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %4971 : Tensor = aten::erf(%4970) # gptadv_static.py:26:32 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 750) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 3072]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %4972 : Tensor = aten::add(%4971, %14, %17) # <string>:5:9 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 751) [Unary]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Weights: [1]
    Data Type: Float32
    Number of input maps: 1
    Number of output maps: 1
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x5640412d7a60 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 3072]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %input.48 : Tensor = aten::mul(%4969, %4972) # gptadv_static.py:26:15 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 747) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 754) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 3072]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %5440 : int = prim::Constant[value=1]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be: 1
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5441 : Tensor = aten::t(%self.blocks.6.mlp.2.weight.1) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found IValue containing object of type Float(768, 3072, strides=[3072, 1], requires_grad=0, device=cuda:0)
DEBUG: [Torch-TensorRT] - Weights: [768, 3072]
    Data Type: Float32
    Number of input maps: 3072
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56404127b3b0 as an IConstantLayer
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 756) [Constant]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [768, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [3072, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5442 : Tensor = aten::matmul(%input.48, %5441) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 755) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 757) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [3072, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5443 : Tensor = trt::const(%self.blocks.6.mlp.2.bias.1) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor %5443 : Tensor = trt::const(%self.blocks.6.mlp.2.bias.1) as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5444 : Tensor = aten::add(%5443, %5442, %5440) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 759) [Constant]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 758) [Matrix Multiply]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %x.29 : Tensor = aten::add(%x.42, %5444, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:163:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 718) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 761) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %x_.16 : Tensor = aten::layer_norm(%x.29, %9, %self.blocks.7.ln_1.weight.1, %self.blocks.7.ln_1.bias.1, %11, %10) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2515:11 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - cudnn disregarded
DEBUG: [Torch-TensorRT] - Axis Mask for E[x]00000000000000000000000000000010
DEBUG: [Torch-TensorRT] - Weights: [1]
    Data Type: Float32
    Number of input maps: 1
    Number of output maps: 1
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56404127e280 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Weights: [1]
    Data Type: Float32
    Number of input maps: 1
    Number of output maps: 1
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x5640412fc130 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %5445 : int = prim::Constant[value=1]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be: 1
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5446 : Tensor = aten::t(%self.blocks.7.attention.c_attn.weight) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found IValue containing object of type Float(2304, 768, strides=[768, 1], requires_grad=0, device=cuda:0)
DEBUG: [Torch-TensorRT] - Weights: [2304, 768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 2304
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x5640412fa710 as an IConstantLayer
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 783) [Constant]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [2304, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [768, 2304]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5447 : Tensor = aten::matmul(%x_.16, %5446) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 782) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 784) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [768, 2304]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 2304]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5448 : Tensor = trt::const(%self.blocks.0.attention.c_attn.bias) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - Weights: [2304]
    Data Type: Float32
    Number of input maps: 2304
    Number of output maps: 2304
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor %5448 : Tensor = trt::const(%self.blocks.0.attention.c_attn.bias) as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [2304]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5449 : Tensor = aten::add(%5448, %5447, %5445) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 786) [Constant]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [2304]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 785) [Matrix Multiply]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 2304]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 2304]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %413 : Tensor[] = aten::split(%5449, %self.blocks.0.attention.n_embd, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:119:19 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 788) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 2304]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Number of split outputs: 3
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Int32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x5640412d5f70 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Int32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x5640412eb750 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Int32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x564041301210 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Converted split op into a list of IValues
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %q.48 : Tensor, %k.48 : Tensor, %v.48 : Tensor = prim::ListUnpack(%413)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the evaluated value(s) to be an ITensor of shape: [-1, 768]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the evaluated value(s) to be an ITensor of shape: [-1, 768]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the evaluated value(s) to be an ITensor of shape: [-1, 768]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %417 : Tensor[] = prim::ListConstruct(%8, %k.48)
DEBUG: [Torch-TensorRT] - Weights: [32, 768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 32
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x5640412f24e0 as an IConstantLayer
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be: [<__torch__.torch.classes._torch_tensorrt_eval_ivalue_types.TensorContainer object at 0x56403a83d640>, <__torch__.torch.classes._torch_tensorrt_eval_ivalue_types.TensorContainer object at 0x5640412e4050>]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %419 : Tensor[] = prim::ListConstruct(%8, %q.48)
DEBUG: [Torch-TensorRT] - Weights: [32, 768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 32
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x5640412fb7f0 as an IConstantLayer
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be: [<__torch__.torch.classes._torch_tensorrt_eval_ivalue_types.TensorContainer object at 0x564041307860>, <__torch__.torch.classes._torch_tensorrt_eval_ivalue_types.TensorContainer object at 0x5640412fb880>]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %421 : Tensor[] = prim::ListConstruct(%8, %v.48)
DEBUG: [Torch-TensorRT] - Weights: [32, 768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 32
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x5640412f2380 as an IConstantLayer
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be: [<__torch__.torch.classes._torch_tensorrt_eval_ivalue_types.TensorContainer object at 0x56403a83d550>, <__torch__.torch.classes._torch_tensorrt_eval_ivalue_types.TensorContainer object at 0x5640412e7a90>]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %k.50 : Tensor = aten::cat(%417, %19) # gptadv_static.py:54:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5283 : Tensor = aten::reshape(%k.50, %7) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 798) [Concatenation]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Using dynamic version of reshape layer
DEBUG: [Torch-TensorRT] - Shape tensor is an IntList
DEBUG: [Torch-TensorRT] - Weights: [3]
    Data Type: Int32
    Number of input maps: 3
    Number of output maps: 3
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56404130bce0 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 12, 64]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %q.50 : Tensor = aten::cat(%419, %19) # gptadv_static.py:55:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5284 : Tensor = aten::reshape(%q.50, %7) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 801) [Concatenation]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Using dynamic version of reshape layer
DEBUG: [Torch-TensorRT] - Shape tensor is an IntList
DEBUG: [Torch-TensorRT] - Weights: [3]
    Data Type: Int32
    Number of input maps: 3
    Number of output maps: 3
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x564041371890 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 12, 64]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %v.50 : Tensor = aten::cat(%421, %19) # gptadv_static.py:56:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5285 : Tensor = aten::reshape(%v.50, %7) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 804) [Concatenation]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Using dynamic version of reshape layer
DEBUG: [Torch-TensorRT] - Shape tensor is an IntList
DEBUG: [Torch-TensorRT] - Weights: [3]
    Data Type: Int32
    Number of input maps: 3
    Number of output maps: 3
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x5640412f0870 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 12, 64]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %k.52 : Tensor = aten::transpose(%5283, %19, %17) # gptadv_static.py:58:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 800) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 12, 64]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Shuffle to: [1, 0, 2]
DEBUG: [Torch-TensorRT] - Output tensor shape: [12, -1, 64]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %q.52 : Tensor = aten::transpose(%5284, %19, %17) # gptadv_static.py:59:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 803) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 12, 64]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Shuffle to: [1, 0, 2]
DEBUG: [Torch-TensorRT] - Output tensor shape: [12, -1, 64]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %v.52 : Tensor = aten::transpose(%5285, %19, %17) # gptadv_static.py:60:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 806) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 12, 64]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Shuffle to: [1, 0, 2]
DEBUG: [Torch-TensorRT] - Output tensor shape: [12, -1, 64]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5011 : Tensor = aten::transpose(%k.52, %12, %18) # gptadv_static.py:62:19 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 807) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [12, -1, 64]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Shuffle to: [0, 2, 1]
DEBUG: [Torch-TensorRT] - Output tensor shape: [12, 64, -1]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5012 : Tensor = aten::matmul(%q.52, %5011) # gptadv_static.py:62:15 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 808) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [12, -1, 64]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 810) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [12, 64, -1]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [12, -1, -1]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %att.16 : Tensor = aten::mul(%5012, %6) # gptadv_static.py:62:15 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 811) [Matrix Multiply]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [12, -1, -1]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Weights: [1]
    Data Type: Float32
    Number of input maps: 1
    Number of output maps: 1
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x5640412f6880 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [12, -1, -1]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %ret.16 : Tensor = aten::softmax(%att.16, %18, %20) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1843:14 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 814) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [12, -1, -1]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Softmax original dim -1
DEBUG: [Torch-TensorRT] - Softmax converted dim 2
DEBUG: [Torch-TensorRT] - Disregarding dtype argument
DEBUG: [Torch-TensorRT] - Output tensor shape: [12, -1, -1]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %y.31 : Tensor = aten::matmul(%ret.16, %v.52) # gptadv_static.py:66:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT] - ITensor name: ret.16
DEBUG: [Torch-TensorRT] - ITensor shape: [12, -1, -1]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 809) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [12, -1, 64]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [12, -1, 64]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5016 : Tensor = aten::transpose(%y.31, %17, %13) # gptadv_static.py:67:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 816) [Matrix Multiply]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [12, -1, 64]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Shuffle to: [0, 2, 1]
DEBUG: [Torch-TensorRT] - Output tensor shape: [12, 64, -1]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5286 : Tensor = aten::reshape(%5016, %5) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 817) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [12, 64, -1]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Using dynamic version of reshape layer
DEBUG: [Torch-TensorRT] - Shape tensor is an IntList
DEBUG: [Torch-TensorRT] - Weights: [2]
    Data Type: Int32
    Number of input maps: 2
    Number of output maps: 2
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56404130a910 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %5450 : int = prim::Constant[value=1]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be: 1
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5451 : Tensor = aten::t(%self.blocks.7.attention.c_proj.weight.1) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found IValue containing object of type Float(768, 768, strides=[768, 1], requires_grad=0, device=cuda:0)
DEBUG: [Torch-TensorRT] - Weights: [768, 768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x564041370b10 as an IConstantLayer
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 820) [Constant]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [768, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [768, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5452 : Tensor = aten::matmul(%5286, %5451) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 819) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 821) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [768, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5453 : Tensor = trt::const(%self.blocks.0.attention.c_proj.bias.1) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor %5453 : Tensor = trt::const(%self.blocks.0.attention.c_proj.bias.1) as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5454 : Tensor = aten::add(%5453, %5452, %5450) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 823) [Constant]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 822) [Matrix Multiply]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %x.46 : Tensor = aten::add(%x.29, %5454, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:162:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 762) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 825) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5021 : Tensor = aten::layer_norm(%x.46, %9, %self.blocks.7.ln_2.weight.1, %self.blocks.7.ln_2.bias.1, %11, %10) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2515:11 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - cudnn disregarded
DEBUG: [Torch-TensorRT] - Axis Mask for E[x]00000000000000000000000000000010
DEBUG: [Torch-TensorRT] - Weights: [1]
    Data Type: Float32
    Number of input maps: 1
    Number of output maps: 1
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56404130ced0 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Weights: [1]
    Data Type: Float32
    Number of input maps: 1
    Number of output maps: 1
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56404135abd0 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %5455 : int = prim::Constant[value=1]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be: 1
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5456 : Tensor = aten::t(%self.blocks.7.mlp.0.weight.1) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found IValue containing object of type Float(3072, 768, strides=[768, 1], requires_grad=0, device=cuda:0)
DEBUG: [Torch-TensorRT] - Weights: [3072, 768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 3072
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x5640413053d0 as an IConstantLayer
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 847) [Constant]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [3072, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [768, 3072]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5457 : Tensor = aten::matmul(%5021, %5456) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 846) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 848) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [768, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 3072]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5458 : Tensor = trt::const(%self.blocks.7.mlp.0.bias.1) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - Weights: [3072]
    Data Type: Float32
    Number of input maps: 3072
    Number of output maps: 3072
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor %5458 : Tensor = trt::const(%self.blocks.7.mlp.0.bias.1) as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [3072]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5459 : Tensor = aten::add(%5458, %5457, %5455) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 850) [Constant]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 849) [Matrix Multiply]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 3072]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5023 : Tensor = aten::mul(%5459, %15) # gptadv_static.py:26:15 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 852) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Weights: [1]
    Data Type: Float32
    Number of input maps: 1
    Number of output maps: 1
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x564041369540 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 3072]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5024 : Tensor = aten::div(%5459, %16) # gptadv_static.py:26:42 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 852) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Weights: [1]
    Data Type: Float32
    Number of input maps: 1
    Number of output maps: 1
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56402bf649b0 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 3072]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5025 : Tensor = aten::erf(%5024) # gptadv_static.py:26:32 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 858) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 3072]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5026 : Tensor = aten::add(%5025, %14, %17) # <string>:5:9 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 859) [Unary]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Weights: [1]
    Data Type: Float32
    Number of input maps: 1
    Number of output maps: 1
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x564041370510 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 3072]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %input.54 : Tensor = aten::mul(%5023, %5026) # gptadv_static.py:26:15 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 855) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 862) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 3072]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %5460 : int = prim::Constant[value=1]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be: 1
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5461 : Tensor = aten::t(%self.blocks.7.mlp.2.weight.1) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found IValue containing object of type Float(768, 3072, strides=[3072, 1], requires_grad=0, device=cuda:0)
DEBUG: [Torch-TensorRT] - Weights: [768, 3072]
    Data Type: Float32
    Number of input maps: 3072
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x5640412ffb70 as an IConstantLayer
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 864) [Constant]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [768, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [3072, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5462 : Tensor = aten::matmul(%input.54, %5461) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 863) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 865) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [3072, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5463 : Tensor = trt::const(%self.blocks.7.mlp.2.bias.1) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor %5463 : Tensor = trt::const(%self.blocks.7.mlp.2.bias.1) as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5464 : Tensor = aten::add(%5463, %5462, %5460) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 867) [Constant]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 866) [Matrix Multiply]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %x.33 : Tensor = aten::add(%x.46, %5464, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:163:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 826) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 869) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %x_.18 : Tensor = aten::layer_norm(%x.33, %9, %self.blocks.8.ln_1.weight.1, %self.blocks.8.ln_1.bias.1, %11, %10) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2515:11 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - cudnn disregarded
DEBUG: [Torch-TensorRT] - Axis Mask for E[x]00000000000000000000000000000010
DEBUG: [Torch-TensorRT] - Weights: [1]
    Data Type: Float32
    Number of input maps: 1
    Number of output maps: 1
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x564041380cb0 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Weights: [1]
    Data Type: Float32
    Number of input maps: 1
    Number of output maps: 1
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56404136dba0 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %5465 : int = prim::Constant[value=1]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be: 1
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5466 : Tensor = aten::t(%self.blocks.8.attention.c_attn.weight) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found IValue containing object of type Float(2304, 768, strides=[768, 1], requires_grad=0, device=cuda:0)
DEBUG: [Torch-TensorRT] - Weights: [2304, 768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 2304
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x564041388ff0 as an IConstantLayer
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 891) [Constant]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [2304, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [768, 2304]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5467 : Tensor = aten::matmul(%x_.18, %5466) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 890) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 892) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [768, 2304]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 2304]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5468 : Tensor = trt::const(%self.blocks.0.attention.c_attn.bias) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - Weights: [2304]
    Data Type: Float32
    Number of input maps: 2304
    Number of output maps: 2304
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor %5468 : Tensor = trt::const(%self.blocks.0.attention.c_attn.bias) as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [2304]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5469 : Tensor = aten::add(%5468, %5467, %5465) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 894) [Constant]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [2304]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 893) [Matrix Multiply]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 2304]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 2304]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %450 : Tensor[] = aten::split(%5469, %self.blocks.0.attention.n_embd, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:119:19 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 896) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 2304]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Number of split outputs: 3
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Int32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x5640413753d0 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Int32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x564041368fc0 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Int32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x564041309670 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Converted split op into a list of IValues
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %q.54 : Tensor, %k.54 : Tensor, %v.54 : Tensor = prim::ListUnpack(%450)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the evaluated value(s) to be an ITensor of shape: [-1, 768]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the evaluated value(s) to be an ITensor of shape: [-1, 768]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the evaluated value(s) to be an ITensor of shape: [-1, 768]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %454 : Tensor[] = prim::ListConstruct(%8, %k.54)
DEBUG: [Torch-TensorRT] - Weights: [32, 768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 32
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56404138d230 as an IConstantLayer
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be: [<__torch__.torch.classes._torch_tensorrt_eval_ivalue_types.TensorContainer object at 0x5640413750a0>, <__torch__.torch.classes._torch_tensorrt_eval_ivalue_types.TensorContainer object at 0x564041375120>]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %456 : Tensor[] = prim::ListConstruct(%8, %q.54)
DEBUG: [Torch-TensorRT] - Weights: [32, 768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 32
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x564041389e00 as an IConstantLayer
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be: [<__torch__.torch.classes._torch_tensorrt_eval_ivalue_types.TensorContainer object at 0x564041309d10>, <__torch__.torch.classes._torch_tensorrt_eval_ivalue_types.TensorContainer object at 0x564041389a20>]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %458 : Tensor[] = prim::ListConstruct(%8, %v.54)
DEBUG: [Torch-TensorRT] - Weights: [32, 768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 32
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x564041389be0 as an IConstantLayer
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be: [<__torch__.torch.classes._torch_tensorrt_eval_ivalue_types.TensorContainer object at 0x56403a8badb0>, <__torch__.torch.classes._torch_tensorrt_eval_ivalue_types.TensorContainer object at 0x56403a8bae60>]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %k.56 : Tensor = aten::cat(%454, %19) # gptadv_static.py:54:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5287 : Tensor = aten::reshape(%k.56, %7) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 906) [Concatenation]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Using dynamic version of reshape layer
DEBUG: [Torch-TensorRT] - Shape tensor is an IntList
DEBUG: [Torch-TensorRT] - Weights: [3]
    Data Type: Int32
    Number of input maps: 3
    Number of output maps: 3
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x564041392a50 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 12, 64]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %q.56 : Tensor = aten::cat(%456, %19) # gptadv_static.py:55:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5288 : Tensor = aten::reshape(%q.56, %7) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 909) [Concatenation]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Using dynamic version of reshape layer
DEBUG: [Torch-TensorRT] - Shape tensor is an IntList
DEBUG: [Torch-TensorRT] - Weights: [3]
    Data Type: Int32
    Number of input maps: 3
    Number of output maps: 3
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x5640413926c0 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 12, 64]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %v.56 : Tensor = aten::cat(%458, %19) # gptadv_static.py:56:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5289 : Tensor = aten::reshape(%v.56, %7) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 912) [Concatenation]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Using dynamic version of reshape layer
DEBUG: [Torch-TensorRT] - Shape tensor is an IntList
DEBUG: [Torch-TensorRT] - Weights: [3]
    Data Type: Int32
    Number of input maps: 3
    Number of output maps: 3
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56404138b890 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 12, 64]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %k.58 : Tensor = aten::transpose(%5287, %19, %17) # gptadv_static.py:58:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 908) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 12, 64]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Shuffle to: [1, 0, 2]
DEBUG: [Torch-TensorRT] - Output tensor shape: [12, -1, 64]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %q.58 : Tensor = aten::transpose(%5288, %19, %17) # gptadv_static.py:59:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 911) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 12, 64]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Shuffle to: [1, 0, 2]
DEBUG: [Torch-TensorRT] - Output tensor shape: [12, -1, 64]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %v.58 : Tensor = aten::transpose(%5289, %19, %17) # gptadv_static.py:60:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 914) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 12, 64]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Shuffle to: [1, 0, 2]
DEBUG: [Torch-TensorRT] - Output tensor shape: [12, -1, 64]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5065 : Tensor = aten::transpose(%k.58, %12, %18) # gptadv_static.py:62:19 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 915) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [12, -1, 64]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Shuffle to: [0, 2, 1]
DEBUG: [Torch-TensorRT] - Output tensor shape: [12, 64, -1]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5066 : Tensor = aten::matmul(%q.58, %5065) # gptadv_static.py:62:15 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 916) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [12, -1, 64]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 918) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [12, 64, -1]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [12, -1, -1]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %att.18 : Tensor = aten::mul(%5066, %6) # gptadv_static.py:62:15 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 919) [Matrix Multiply]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [12, -1, -1]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Weights: [1]
    Data Type: Float32
    Number of input maps: 1
    Number of output maps: 1
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x564041377cb0 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [12, -1, -1]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %ret.18 : Tensor = aten::softmax(%att.18, %18, %20) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1843:14 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 922) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [12, -1, -1]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Softmax original dim -1
DEBUG: [Torch-TensorRT] - Softmax converted dim 2
DEBUG: [Torch-TensorRT] - Disregarding dtype argument
DEBUG: [Torch-TensorRT] - Output tensor shape: [12, -1, -1]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %y.35 : Tensor = aten::matmul(%ret.18, %v.58) # gptadv_static.py:66:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT] - ITensor name: ret.18
DEBUG: [Torch-TensorRT] - ITensor shape: [12, -1, -1]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 917) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [12, -1, 64]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [12, -1, 64]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5070 : Tensor = aten::transpose(%y.35, %17, %13) # gptadv_static.py:67:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 924) [Matrix Multiply]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [12, -1, 64]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Shuffle to: [0, 2, 1]
DEBUG: [Torch-TensorRT] - Output tensor shape: [12, 64, -1]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5290 : Tensor = aten::reshape(%5070, %5) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 925) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [12, 64, -1]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Using dynamic version of reshape layer
DEBUG: [Torch-TensorRT] - Shape tensor is an IntList
DEBUG: [Torch-TensorRT] - Weights: [2]
    Data Type: Int32
    Number of input maps: 2
    Number of output maps: 2
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x564041403610 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %5470 : int = prim::Constant[value=1]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be: 1
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5471 : Tensor = aten::t(%self.blocks.8.attention.c_proj.weight.1) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found IValue containing object of type Float(768, 768, strides=[768, 1], requires_grad=0, device=cuda:0)
DEBUG: [Torch-TensorRT] - Weights: [768, 768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x5640413a1190 as an IConstantLayer
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 928) [Constant]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [768, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [768, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5472 : Tensor = aten::matmul(%5290, %5471) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 927) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 929) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [768, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5473 : Tensor = trt::const(%self.blocks.0.attention.c_proj.bias.1) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor %5473 : Tensor = trt::const(%self.blocks.0.attention.c_proj.bias.1) as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5474 : Tensor = aten::add(%5473, %5472, %5470) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 931) [Constant]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 930) [Matrix Multiply]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %x.50 : Tensor = aten::add(%x.33, %5474, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:162:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 870) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 933) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5075 : Tensor = aten::layer_norm(%x.50, %9, %self.blocks.8.ln_2.weight.1, %self.blocks.8.ln_2.bias.1, %11, %10) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2515:11 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - cudnn disregarded
DEBUG: [Torch-TensorRT] - Axis Mask for E[x]00000000000000000000000000000010
DEBUG: [Torch-TensorRT] - Weights: [1]
    Data Type: Float32
    Number of input maps: 1
    Number of output maps: 1
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56404139bf60 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Weights: [1]
    Data Type: Float32
    Number of input maps: 1
    Number of output maps: 1
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56404139c430 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %5475 : int = prim::Constant[value=1]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be: 1
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5476 : Tensor = aten::t(%self.blocks.8.mlp.0.weight.1) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found IValue containing object of type Float(3072, 768, strides=[768, 1], requires_grad=0, device=cuda:0)
DEBUG: [Torch-TensorRT] - Weights: [3072, 768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 3072
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x564041407130 as an IConstantLayer
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 955) [Constant]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [3072, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [768, 3072]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5477 : Tensor = aten::matmul(%5075, %5476) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 954) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 956) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [768, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 3072]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5478 : Tensor = trt::const(%self.blocks.8.mlp.0.bias.1) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - Weights: [3072]
    Data Type: Float32
    Number of input maps: 3072
    Number of output maps: 3072
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor %5478 : Tensor = trt::const(%self.blocks.8.mlp.0.bias.1) as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [3072]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5479 : Tensor = aten::add(%5478, %5477, %5475) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 958) [Constant]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 957) [Matrix Multiply]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 3072]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5077 : Tensor = aten::mul(%5479, %15) # gptadv_static.py:26:15 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 960) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Weights: [1]
    Data Type: Float32
    Number of input maps: 1
    Number of output maps: 1
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x5640413ff060 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 3072]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5078 : Tensor = aten::div(%5479, %16) # gptadv_static.py:26:42 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 960) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Weights: [1]
    Data Type: Float32
    Number of input maps: 1
    Number of output maps: 1
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x564041407d40 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 3072]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5079 : Tensor = aten::erf(%5078) # gptadv_static.py:26:32 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 966) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 3072]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5080 : Tensor = aten::add(%5079, %14, %17) # <string>:5:9 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 967) [Unary]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Weights: [1]
    Data Type: Float32
    Number of input maps: 1
    Number of output maps: 1
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56404140c940 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 3072]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %input.60 : Tensor = aten::mul(%5077, %5080) # gptadv_static.py:26:15 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 963) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 970) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 3072]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %5480 : int = prim::Constant[value=1]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be: 1
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5481 : Tensor = aten::t(%self.blocks.8.mlp.2.weight.1) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found IValue containing object of type Float(768, 3072, strides=[3072, 1], requires_grad=0, device=cuda:0)
DEBUG: [Torch-TensorRT] - Weights: [768, 3072]
    Data Type: Float32
    Number of input maps: 3072
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x5640413ecfc0 as an IConstantLayer
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 972) [Constant]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [768, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [3072, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5482 : Tensor = aten::matmul(%input.60, %5481) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 971) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 973) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [3072, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5483 : Tensor = trt::const(%self.blocks.8.mlp.2.bias.1) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor %5483 : Tensor = trt::const(%self.blocks.8.mlp.2.bias.1) as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5484 : Tensor = aten::add(%5483, %5482, %5480) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 975) [Constant]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 974) [Matrix Multiply]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %x.37 : Tensor = aten::add(%x.50, %5484, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:163:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 934) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 977) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %x_.20 : Tensor = aten::layer_norm(%x.37, %9, %self.blocks.9.ln_1.weight.1, %self.blocks.9.ln_1.bias.1, %11, %10) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2515:11 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - cudnn disregarded
DEBUG: [Torch-TensorRT] - Axis Mask for E[x]00000000000000000000000000000010
DEBUG: [Torch-TensorRT] - Weights: [1]
    Data Type: Float32
    Number of input maps: 1
    Number of output maps: 1
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x564041394600 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Weights: [1]
    Data Type: Float32
    Number of input maps: 1
    Number of output maps: 1
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56404138c2e0 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %5485 : int = prim::Constant[value=1]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be: 1
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5486 : Tensor = aten::t(%self.blocks.9.attention.c_attn.weight) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found IValue containing object of type Float(2304, 768, strides=[768, 1], requires_grad=0, device=cuda:0)
DEBUG: [Torch-TensorRT] - Weights: [2304, 768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 2304
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x564041412d30 as an IConstantLayer
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 999) [Constant]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [2304, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [768, 2304]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5487 : Tensor = aten::matmul(%x_.20, %5486) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 998) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1000) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [768, 2304]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 2304]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5488 : Tensor = trt::const(%self.blocks.0.attention.c_attn.bias) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - Weights: [2304]
    Data Type: Float32
    Number of input maps: 2304
    Number of output maps: 2304
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor %5488 : Tensor = trt::const(%self.blocks.0.attention.c_attn.bias) as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [2304]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5489 : Tensor = aten::add(%5488, %5487, %5485) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1002) [Constant]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [2304]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1001) [Matrix Multiply]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 2304]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 2304]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %487 : Tensor[] = aten::split(%5489, %self.blocks.0.attention.n_embd, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:119:19 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1004) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 2304]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Number of split outputs: 3
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Int32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x5640413f0cd0 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Int32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x5640413fc010 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Int32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x564041390310 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Converted split op into a list of IValues
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %q.60 : Tensor, %k.60 : Tensor, %v.60 : Tensor = prim::ListUnpack(%487)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the evaluated value(s) to be an ITensor of shape: [-1, 768]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the evaluated value(s) to be an ITensor of shape: [-1, 768]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the evaluated value(s) to be an ITensor of shape: [-1, 768]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %491 : Tensor[] = prim::ListConstruct(%8, %k.60)
DEBUG: [Torch-TensorRT] - Weights: [32, 768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 32
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x564041409a90 as an IConstantLayer
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be: [<__torch__.torch.classes._torch_tensorrt_eval_ivalue_types.TensorContainer object at 0x564041392980>, <__torch__.torch.classes._torch_tensorrt_eval_ivalue_types.TensorContainer object at 0x564041361ee0>]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %493 : Tensor[] = prim::ListConstruct(%8, %q.60)
DEBUG: [Torch-TensorRT] - Weights: [32, 768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 32
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x564041409930 as an IConstantLayer
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be: [<__torch__.torch.classes._torch_tensorrt_eval_ivalue_types.TensorContainer object at 0x56404141ca20>, <__torch__.torch.classes._torch_tensorrt_eval_ivalue_types.TensorContainer object at 0x56404141caa0>]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %495 : Tensor[] = prim::ListConstruct(%8, %v.60)
DEBUG: [Torch-TensorRT] - Weights: [32, 768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 32
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x564041409a20 as an IConstantLayer
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be: [<__torch__.torch.classes._torch_tensorrt_eval_ivalue_types.TensorContainer object at 0x56404140c040>, <__torch__.torch.classes._torch_tensorrt_eval_ivalue_types.TensorContainer object at 0x56404140c0f0>]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %k.62 : Tensor = aten::cat(%491, %19) # gptadv_static.py:54:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5291 : Tensor = aten::reshape(%k.62, %7) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1014) [Concatenation]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Using dynamic version of reshape layer
DEBUG: [Torch-TensorRT] - Shape tensor is an IntList
DEBUG: [Torch-TensorRT] - Weights: [3]
    Data Type: Int32
    Number of input maps: 3
    Number of output maps: 3
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x564041473a90 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 12, 64]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %q.62 : Tensor = aten::cat(%493, %19) # gptadv_static.py:55:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5292 : Tensor = aten::reshape(%q.62, %7) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1017) [Concatenation]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Using dynamic version of reshape layer
DEBUG: [Torch-TensorRT] - Shape tensor is an IntList
DEBUG: [Torch-TensorRT] - Weights: [3]
    Data Type: Int32
    Number of input maps: 3
    Number of output maps: 3
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56404141ef20 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 12, 64]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %v.62 : Tensor = aten::cat(%495, %19) # gptadv_static.py:56:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5293 : Tensor = aten::reshape(%v.62, %7) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1020) [Concatenation]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Using dynamic version of reshape layer
DEBUG: [Torch-TensorRT] - Shape tensor is an IntList
DEBUG: [Torch-TensorRT] - Weights: [3]
    Data Type: Int32
    Number of input maps: 3
    Number of output maps: 3
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x564041475c70 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 12, 64]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %k.64 : Tensor = aten::transpose(%5291, %19, %17) # gptadv_static.py:58:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1016) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 12, 64]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Shuffle to: [1, 0, 2]
DEBUG: [Torch-TensorRT] - Output tensor shape: [12, -1, 64]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %q.64 : Tensor = aten::transpose(%5292, %19, %17) # gptadv_static.py:59:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1019) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 12, 64]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Shuffle to: [1, 0, 2]
DEBUG: [Torch-TensorRT] - Output tensor shape: [12, -1, 64]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %v.64 : Tensor = aten::transpose(%5293, %19, %17) # gptadv_static.py:60:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1022) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 12, 64]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Shuffle to: [1, 0, 2]
DEBUG: [Torch-TensorRT] - Output tensor shape: [12, -1, 64]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5119 : Tensor = aten::transpose(%k.64, %12, %18) # gptadv_static.py:62:19 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1023) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [12, -1, 64]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Shuffle to: [0, 2, 1]
DEBUG: [Torch-TensorRT] - Output tensor shape: [12, 64, -1]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5120 : Tensor = aten::matmul(%q.64, %5119) # gptadv_static.py:62:15 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1024) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [12, -1, 64]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1026) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [12, 64, -1]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [12, -1, -1]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %att.20 : Tensor = aten::mul(%5120, %6) # gptadv_static.py:62:15 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1027) [Matrix Multiply]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [12, -1, -1]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Weights: [1]
    Data Type: Float32
    Number of input maps: 1
    Number of output maps: 1
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56404141dcb0 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [12, -1, -1]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %ret.20 : Tensor = aten::softmax(%att.20, %18, %20) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1843:14 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1030) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [12, -1, -1]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Softmax original dim -1
DEBUG: [Torch-TensorRT] - Softmax converted dim 2
DEBUG: [Torch-TensorRT] - Disregarding dtype argument
DEBUG: [Torch-TensorRT] - Output tensor shape: [12, -1, -1]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %y.39 : Tensor = aten::matmul(%ret.20, %v.64) # gptadv_static.py:66:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT] - ITensor name: ret.20
DEBUG: [Torch-TensorRT] - ITensor shape: [12, -1, -1]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1025) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [12, -1, 64]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [12, -1, 64]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5124 : Tensor = aten::transpose(%y.39, %17, %13) # gptadv_static.py:67:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1032) [Matrix Multiply]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [12, -1, 64]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Shuffle to: [0, 2, 1]
DEBUG: [Torch-TensorRT] - Output tensor shape: [12, 64, -1]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5294 : Tensor = aten::reshape(%5124, %5) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1033) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [12, 64, -1]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Using dynamic version of reshape layer
DEBUG: [Torch-TensorRT] - Shape tensor is an IntList
DEBUG: [Torch-TensorRT] - Weights: [2]
    Data Type: Int32
    Number of input maps: 2
    Number of output maps: 2
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x564048094e40 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %5490 : int = prim::Constant[value=1]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be: 1
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5491 : Tensor = aten::t(%self.blocks.9.attention.c_proj.weight.1) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found IValue containing object of type Float(768, 768, strides=[768, 1], requires_grad=0, device=cuda:0)
DEBUG: [Torch-TensorRT] - Weights: [768, 768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x564041476970 as an IConstantLayer
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1036) [Constant]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [768, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [768, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5492 : Tensor = aten::matmul(%5294, %5491) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1035) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1037) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [768, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5493 : Tensor = trt::const(%self.blocks.0.attention.c_proj.bias.1) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor %5493 : Tensor = trt::const(%self.blocks.0.attention.c_proj.bias.1) as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5494 : Tensor = aten::add(%5493, %5492, %5490) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1039) [Constant]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1038) [Matrix Multiply]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %x.54 : Tensor = aten::add(%x.37, %5494, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:162:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 978) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1041) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5129 : Tensor = aten::layer_norm(%x.54, %9, %self.blocks.9.ln_2.weight.1, %self.blocks.9.ln_2.bias.1, %11, %10) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2515:11 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - cudnn disregarded
DEBUG: [Torch-TensorRT] - Axis Mask for E[x]00000000000000000000000000000010
DEBUG: [Torch-TensorRT] - Weights: [1]
    Data Type: Float32
    Number of input maps: 1
    Number of output maps: 1
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x564041419ec0 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Weights: [1]
    Data Type: Float32
    Number of input maps: 1
    Number of output maps: 1
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56404141ab40 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %5495 : int = prim::Constant[value=1]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be: 1
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5496 : Tensor = aten::t(%self.blocks.9.mlp.0.weight.1) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found IValue containing object of type Float(3072, 768, strides=[768, 1], requires_grad=0, device=cuda:0)
DEBUG: [Torch-TensorRT] - Weights: [3072, 768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 3072
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a936b70 as an IConstantLayer
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1063) [Constant]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [3072, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [768, 3072]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5497 : Tensor = aten::matmul(%5129, %5496) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1062) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1064) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [768, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 3072]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5498 : Tensor = trt::const(%self.blocks.9.mlp.0.bias.1) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - Weights: [3072]
    Data Type: Float32
    Number of input maps: 3072
    Number of output maps: 3072
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor %5498 : Tensor = trt::const(%self.blocks.9.mlp.0.bias.1) as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [3072]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5499 : Tensor = aten::add(%5498, %5497, %5495) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1066) [Constant]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1065) [Matrix Multiply]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 3072]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5131 : Tensor = aten::mul(%5499, %15) # gptadv_static.py:26:15 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1068) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Weights: [1]
    Data Type: Float32
    Number of input maps: 1
    Number of output maps: 1
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56404809ceb0 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 3072]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5132 : Tensor = aten::div(%5499, %16) # gptadv_static.py:26:42 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1068) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Weights: [1]
    Data Type: Float32
    Number of input maps: 1
    Number of output maps: 1
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56404809cf20 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 3072]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5133 : Tensor = aten::erf(%5132) # gptadv_static.py:26:32 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1074) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 3072]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5134 : Tensor = aten::add(%5133, %14, %17) # <string>:5:9 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1075) [Unary]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Weights: [1]
    Data Type: Float32
    Number of input maps: 1
    Number of output maps: 1
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x5640413620b0 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 3072]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %input.66 : Tensor = aten::mul(%5131, %5134) # gptadv_static.py:26:15 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1071) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1078) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 3072]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %5500 : int = prim::Constant[value=1]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be: 1
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5501 : Tensor = aten::t(%self.blocks.9.mlp.2.weight.1) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found IValue containing object of type Float(768, 3072, strides=[3072, 1], requires_grad=0, device=cuda:0)
DEBUG: [Torch-TensorRT] - Weights: [768, 3072]
    Data Type: Float32
    Number of input maps: 3072
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56403a936dc0 as an IConstantLayer
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1080) [Constant]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [768, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [3072, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5502 : Tensor = aten::matmul(%input.66, %5501) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1079) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1081) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [3072, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5503 : Tensor = trt::const(%self.blocks.9.mlp.2.bias.1) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor %5503 : Tensor = trt::const(%self.blocks.9.mlp.2.bias.1) as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5504 : Tensor = aten::add(%5503, %5502, %5500) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1083) [Constant]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1082) [Matrix Multiply]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %x.41 : Tensor = aten::add(%x.54, %5504, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:163:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1042) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1085) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %x_.22 : Tensor = aten::layer_norm(%x.41, %9, %self.blocks.10.ln_1.weight.1, %self.blocks.10.ln_1.bias.1, %11, %10) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2515:11 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - cudnn disregarded
DEBUG: [Torch-TensorRT] - Axis Mask for E[x]00000000000000000000000000000010
DEBUG: [Torch-TensorRT] - Weights: [1]
    Data Type: Float32
    Number of input maps: 1
    Number of output maps: 1
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x5640480a0090 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Weights: [1]
    Data Type: Float32
    Number of input maps: 1
    Number of output maps: 1
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x5640413f9170 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %5505 : int = prim::Constant[value=1]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be: 1
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5506 : Tensor = aten::t(%self.blocks.10.attention.c_attn.weight) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found IValue containing object of type Float(2304, 768, strides=[768, 1], requires_grad=0, device=cuda:0)
DEBUG: [Torch-TensorRT] - Weights: [2304, 768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 2304
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x5640480a5b10 as an IConstantLayer
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1107) [Constant]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [2304, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [768, 2304]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5507 : Tensor = aten::matmul(%x_.22, %5506) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1106) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1108) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [768, 2304]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 2304]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5508 : Tensor = trt::const(%self.blocks.0.attention.c_attn.bias) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - Weights: [2304]
    Data Type: Float32
    Number of input maps: 2304
    Number of output maps: 2304
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor %5508 : Tensor = trt::const(%self.blocks.0.attention.c_attn.bias) as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [2304]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5509 : Tensor = aten::add(%5508, %5507, %5505) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1110) [Constant]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [2304]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1109) [Matrix Multiply]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 2304]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 2304]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %524 : Tensor[] = aten::split(%5509, %self.blocks.0.attention.n_embd, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:119:19 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1112) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 2304]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Number of split outputs: 3
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Int32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56404808d320 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Int32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x5640480a7ed0 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Int32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x5640480839f0 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Converted split op into a list of IValues
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %q.66 : Tensor, %k.66 : Tensor, %v.66 : Tensor = prim::ListUnpack(%524)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the evaluated value(s) to be an ITensor of shape: [-1, 768]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the evaluated value(s) to be an ITensor of shape: [-1, 768]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the evaluated value(s) to be an ITensor of shape: [-1, 768]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %528 : Tensor[] = prim::ListConstruct(%8, %k.66)
DEBUG: [Torch-TensorRT] - Weights: [32, 768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 32
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x564041429100 as an IConstantLayer
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be: [<__torch__.torch.classes._torch_tensorrt_eval_ivalue_types.TensorContainer object at 0x5640413f93c0>, <__torch__.torch.classes._torch_tensorrt_eval_ivalue_types.TensorContainer object at 0x56404141e9d0>]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %530 : Tensor[] = prim::ListConstruct(%8, %q.66)
DEBUG: [Torch-TensorRT] - Weights: [32, 768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 32
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56404809c3f0 as an IConstantLayer
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be: [<__torch__.torch.classes._torch_tensorrt_eval_ivalue_types.TensorContainer object at 0x56404808a590>, <__torch__.torch.classes._torch_tensorrt_eval_ivalue_types.TensorContainer object at 0x56404808a610>]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %532 : Tensor[] = prim::ListConstruct(%8, %v.66)
DEBUG: [Torch-TensorRT] - Weights: [32, 768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 32
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x5640480945d0 as an IConstantLayer
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be: [<__torch__.torch.classes._torch_tensorrt_eval_ivalue_types.TensorContainer object at 0x56404809b290>, <__torch__.torch.classes._torch_tensorrt_eval_ivalue_types.TensorContainer object at 0x56404809b340>]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %k.68 : Tensor = aten::cat(%528, %19) # gptadv_static.py:54:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5295 : Tensor = aten::reshape(%k.68, %7) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1122) [Concatenation]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Using dynamic version of reshape layer
DEBUG: [Torch-TensorRT] - Shape tensor is an IntList
DEBUG: [Torch-TensorRT] - Weights: [3]
    Data Type: Int32
    Number of input maps: 3
    Number of output maps: 3
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x5640480b5700 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 12, 64]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %q.68 : Tensor = aten::cat(%530, %19) # gptadv_static.py:55:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5296 : Tensor = aten::reshape(%q.68, %7) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1125) [Concatenation]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Using dynamic version of reshape layer
DEBUG: [Torch-TensorRT] - Shape tensor is an IntList
DEBUG: [Torch-TensorRT] - Weights: [3]
    Data Type: Int32
    Number of input maps: 3
    Number of output maps: 3
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x564041414380 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 12, 64]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %v.68 : Tensor = aten::cat(%532, %19) # gptadv_static.py:56:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5297 : Tensor = aten::reshape(%v.68, %7) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1128) [Concatenation]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Using dynamic version of reshape layer
DEBUG: [Torch-TensorRT] - Shape tensor is an IntList
DEBUG: [Torch-TensorRT] - Weights: [3]
    Data Type: Int32
    Number of input maps: 3
    Number of output maps: 3
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56404811a1b0 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 12, 64]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %k.70 : Tensor = aten::transpose(%5295, %19, %17) # gptadv_static.py:58:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1124) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 12, 64]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Shuffle to: [1, 0, 2]
DEBUG: [Torch-TensorRT] - Output tensor shape: [12, -1, 64]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %q.70 : Tensor = aten::transpose(%5296, %19, %17) # gptadv_static.py:59:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1127) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 12, 64]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Shuffle to: [1, 0, 2]
DEBUG: [Torch-TensorRT] - Output tensor shape: [12, -1, 64]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %v.70 : Tensor = aten::transpose(%5297, %19, %17) # gptadv_static.py:60:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1130) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 12, 64]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Shuffle to: [1, 0, 2]
DEBUG: [Torch-TensorRT] - Output tensor shape: [12, -1, 64]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5173 : Tensor = aten::transpose(%k.70, %12, %18) # gptadv_static.py:62:19 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1131) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [12, -1, 64]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Shuffle to: [0, 2, 1]
DEBUG: [Torch-TensorRT] - Output tensor shape: [12, 64, -1]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5174 : Tensor = aten::matmul(%q.70, %5173) # gptadv_static.py:62:15 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1132) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [12, -1, 64]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1134) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [12, 64, -1]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [12, -1, -1]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %att.22 : Tensor = aten::mul(%5174, %6) # gptadv_static.py:62:15 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1135) [Matrix Multiply]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [12, -1, -1]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Weights: [1]
    Data Type: Float32
    Number of input maps: 1
    Number of output maps: 1
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x5640480a9ea0 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [12, -1, -1]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %ret.22 : Tensor = aten::softmax(%att.22, %18, %20) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1843:14 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1138) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [12, -1, -1]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Softmax original dim -1
DEBUG: [Torch-TensorRT] - Softmax converted dim 2
DEBUG: [Torch-TensorRT] - Disregarding dtype argument
DEBUG: [Torch-TensorRT] - Output tensor shape: [12, -1, -1]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %y.43 : Tensor = aten::matmul(%ret.22, %v.70) # gptadv_static.py:66:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT] - ITensor name: ret.22
DEBUG: [Torch-TensorRT] - ITensor shape: [12, -1, -1]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1133) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [12, -1, 64]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [12, -1, 64]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5178 : Tensor = aten::transpose(%y.43, %17, %13) # gptadv_static.py:67:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1140) [Matrix Multiply]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [12, -1, 64]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Shuffle to: [0, 2, 1]
DEBUG: [Torch-TensorRT] - Output tensor shape: [12, 64, -1]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5298 : Tensor = aten::reshape(%5178, %5) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1141) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [12, 64, -1]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Using dynamic version of reshape layer
DEBUG: [Torch-TensorRT] - Shape tensor is an IntList
DEBUG: [Torch-TensorRT] - Weights: [2]
    Data Type: Int32
    Number of input maps: 2
    Number of output maps: 2
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x5640480adc30 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %5510 : int = prim::Constant[value=1]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be: 1
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5511 : Tensor = aten::t(%self.blocks.10.attention.c_proj.weight.1) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found IValue containing object of type Float(768, 768, strides=[768, 1], requires_grad=0, device=cuda:0)
DEBUG: [Torch-TensorRT] - Weights: [768, 768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x564048113b30 as an IConstantLayer
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1144) [Constant]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [768, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [768, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5512 : Tensor = aten::matmul(%5298, %5511) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1143) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1145) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [768, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5513 : Tensor = trt::const(%self.blocks.0.attention.c_proj.bias.1) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor %5513 : Tensor = trt::const(%self.blocks.0.attention.c_proj.bias.1) as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5514 : Tensor = aten::add(%5513, %5512, %5510) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1147) [Constant]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1146) [Matrix Multiply]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %x.58 : Tensor = aten::add(%x.41, %5514, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:162:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1086) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1149) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5183 : Tensor = aten::layer_norm(%x.58, %9, %self.blocks.10.ln_2.weight.1, %self.blocks.10.ln_2.bias.1, %11, %10) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2515:11 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - cudnn disregarded
DEBUG: [Torch-TensorRT] - Axis Mask for E[x]00000000000000000000000000000010
DEBUG: [Torch-TensorRT] - Weights: [1]
    Data Type: Float32
    Number of input maps: 1
    Number of output maps: 1
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x5640480abd40 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Weights: [1]
    Data Type: Float32
    Number of input maps: 1
    Number of output maps: 1
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56404811ef70 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %5515 : int = prim::Constant[value=1]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be: 1
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5516 : Tensor = aten::t(%self.blocks.10.mlp.0.weight.1) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found IValue containing object of type Float(3072, 768, strides=[768, 1], requires_grad=0, device=cuda:0)
DEBUG: [Torch-TensorRT] - Weights: [3072, 768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 3072
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x5640480b01b0 as an IConstantLayer
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1171) [Constant]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [3072, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [768, 3072]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5517 : Tensor = aten::matmul(%5183, %5516) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1170) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1172) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [768, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 3072]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5518 : Tensor = trt::const(%self.blocks.10.mlp.0.bias.1) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - Weights: [3072]
    Data Type: Float32
    Number of input maps: 3072
    Number of output maps: 3072
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor %5518 : Tensor = trt::const(%self.blocks.10.mlp.0.bias.1) as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [3072]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5519 : Tensor = aten::add(%5518, %5517, %5515) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1174) [Constant]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1173) [Matrix Multiply]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 3072]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5185 : Tensor = aten::mul(%5519, %15) # gptadv_static.py:26:15 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1176) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Weights: [1]
    Data Type: Float32
    Number of input maps: 1
    Number of output maps: 1
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x5640481089e0 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 3072]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5186 : Tensor = aten::div(%5519, %16) # gptadv_static.py:26:42 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1176) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Weights: [1]
    Data Type: Float32
    Number of input maps: 1
    Number of output maps: 1
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x5640481002c0 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 3072]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5187 : Tensor = aten::erf(%5186) # gptadv_static.py:26:32 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1182) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 3072]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5188 : Tensor = aten::add(%5187, %14, %17) # <string>:5:9 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1183) [Unary]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Weights: [1]
    Data Type: Float32
    Number of input maps: 1
    Number of output maps: 1
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x564048117e80 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 3072]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %input.72 : Tensor = aten::mul(%5185, %5188) # gptadv_static.py:26:15 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1179) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1186) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 3072]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %5520 : int = prim::Constant[value=1]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be: 1
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5521 : Tensor = aten::t(%self.blocks.10.mlp.2.weight.1) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found IValue containing object of type Float(768, 3072, strides=[3072, 1], requires_grad=0, device=cuda:0)
DEBUG: [Torch-TensorRT] - Weights: [768, 3072]
    Data Type: Float32
    Number of input maps: 3072
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x564048121f40 as an IConstantLayer
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1188) [Constant]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [768, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [3072, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5522 : Tensor = aten::matmul(%input.72, %5521) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1187) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1189) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [3072, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5523 : Tensor = trt::const(%self.blocks.10.mlp.2.bias.1) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor %5523 : Tensor = trt::const(%self.blocks.10.mlp.2.bias.1) as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5524 : Tensor = aten::add(%5523, %5522, %5520) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1191) [Constant]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1190) [Matrix Multiply]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %x.45 : Tensor = aten::add(%x.58, %5524, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:163:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1150) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1193) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %x_.1 : Tensor = aten::layer_norm(%x.45, %9, %self.blocks.11.ln_1.weight.1, %self.blocks.11.ln_1.bias.1, %11, %10) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2515:11 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - cudnn disregarded
DEBUG: [Torch-TensorRT] - Axis Mask for E[x]00000000000000000000000000000010
DEBUG: [Torch-TensorRT] - Weights: [1]
    Data Type: Float32
    Number of input maps: 1
    Number of output maps: 1
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x5640480af730 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Weights: [1]
    Data Type: Float32
    Number of input maps: 1
    Number of output maps: 1
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x5640480abcc0 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %5525 : int = prim::Constant[value=1]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be: 1
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5526 : Tensor = aten::t(%self.blocks.11.attention.c_attn.weight) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found IValue containing object of type Float(2304, 768, strides=[768, 1], requires_grad=0, device=cuda:0)
DEBUG: [Torch-TensorRT] - Weights: [2304, 768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 2304
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x564048102a40 as an IConstantLayer
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1215) [Constant]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [2304, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [768, 2304]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5527 : Tensor = aten::matmul(%x_.1, %5526) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1214) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1216) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [768, 2304]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 2304]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5528 : Tensor = trt::const(%self.blocks.0.attention.c_attn.bias) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - Weights: [2304]
    Data Type: Float32
    Number of input maps: 2304
    Number of output maps: 2304
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor %5528 : Tensor = trt::const(%self.blocks.0.attention.c_attn.bias) as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [2304]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5529 : Tensor = aten::add(%5528, %5527, %5525) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1218) [Constant]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [2304]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1217) [Matrix Multiply]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 2304]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 2304]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %561 : Tensor[] = aten::split(%5529, %self.blocks.0.attention.n_embd, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:119:19 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1220) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 2304]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Number of split outputs: 3
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Int32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x564048099200 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Int32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x5640481121f0 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Int32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56404812b680 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Converted split op into a list of IValues
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %q.1 : Tensor, %k.1 : Tensor, %v.1 : Tensor = prim::ListUnpack(%561)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the evaluated value(s) to be an ITensor of shape: [-1, 768]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the evaluated value(s) to be an ITensor of shape: [-1, 768]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the evaluated value(s) to be an ITensor of shape: [-1, 768]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %565 : Tensor[] = prim::ListConstruct(%8, %k.1)
DEBUG: [Torch-TensorRT] - Weights: [32, 768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 32
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x5640480a8ea0 as an IConstantLayer
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be: [<__torch__.torch.classes._torch_tensorrt_eval_ivalue_types.TensorContainer object at 0x5640480a94d0>, <__torch__.torch.classes._torch_tensorrt_eval_ivalue_types.TensorContainer object at 0x564048107bd0>]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %567 : Tensor[] = prim::ListConstruct(%8, %q.1)
DEBUG: [Torch-TensorRT] - Weights: [32, 768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 32
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x564048113420 as an IConstantLayer
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be: [<__torch__.torch.classes._torch_tensorrt_eval_ivalue_types.TensorContainer object at 0x564048103b20>, <__torch__.torch.classes._torch_tensorrt_eval_ivalue_types.TensorContainer object at 0x564048103bd0>]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %569 : Tensor[] = prim::ListConstruct(%8, %v.1)
DEBUG: [Torch-TensorRT] - Weights: [32, 768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 32
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56404808a9b0 as an IConstantLayer
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be: [<__torch__.torch.classes._torch_tensorrt_eval_ivalue_types.TensorContainer object at 0x56404810f890>, <__torch__.torch.classes._torch_tensorrt_eval_ivalue_types.TensorContainer object at 0x56404810f940>]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %k.5 : Tensor = aten::cat(%565, %19) # gptadv_static.py:54:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5299 : Tensor = aten::reshape(%k.5, %7) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1230) [Concatenation]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Using dynamic version of reshape layer
DEBUG: [Torch-TensorRT] - Shape tensor is an IntList
DEBUG: [Torch-TensorRT] - Weights: [3]
    Data Type: Int32
    Number of input maps: 3
    Number of output maps: 3
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x564048190e70 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 12, 64]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %q.5 : Tensor = aten::cat(%567, %19) # gptadv_static.py:55:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5300 : Tensor = aten::reshape(%q.5, %7) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1233) [Concatenation]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Using dynamic version of reshape layer
DEBUG: [Torch-TensorRT] - Shape tensor is an IntList
DEBUG: [Torch-TensorRT] - Weights: [3]
    Data Type: Int32
    Number of input maps: 3
    Number of output maps: 3
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x5640481ae8c0 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 12, 64]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %v.5 : Tensor = aten::cat(%569, %19) # gptadv_static.py:56:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5301 : Tensor = aten::reshape(%v.5, %7) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1236) [Concatenation]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Using dynamic version of reshape layer
DEBUG: [Torch-TensorRT] - Shape tensor is an IntList
DEBUG: [Torch-TensorRT] - Weights: [3]
    Data Type: Int32
    Number of input maps: 3
    Number of output maps: 3
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x5640481a4c60 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 12, 64]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %k.9 : Tensor = aten::transpose(%5299, %19, %17) # gptadv_static.py:58:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1232) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 12, 64]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Shuffle to: [1, 0, 2]
DEBUG: [Torch-TensorRT] - Output tensor shape: [12, -1, 64]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %q.9 : Tensor = aten::transpose(%5300, %19, %17) # gptadv_static.py:59:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1235) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 12, 64]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Shuffle to: [1, 0, 2]
DEBUG: [Torch-TensorRT] - Output tensor shape: [12, -1, 64]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %v.9 : Tensor = aten::transpose(%5301, %19, %17) # gptadv_static.py:60:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1238) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 12, 64]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Shuffle to: [1, 0, 2]
DEBUG: [Torch-TensorRT] - Output tensor shape: [12, -1, 64]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5229 : Tensor = aten::transpose(%k.9, %12, %18) # gptadv_static.py:62:19 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1239) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [12, -1, 64]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Shuffle to: [0, 2, 1]
DEBUG: [Torch-TensorRT] - Output tensor shape: [12, 64, -1]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5230 : Tensor = aten::matmul(%q.9, %5229) # gptadv_static.py:62:15 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1240) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [12, -1, 64]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1242) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [12, 64, -1]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [12, -1, -1]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %att.1 : Tensor = aten::mul(%5230, %6) # gptadv_static.py:62:15 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1243) [Matrix Multiply]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [12, -1, -1]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Weights: [1]
    Data Type: Float32
    Number of input maps: 1
    Number of output maps: 1
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x564048134740 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [12, -1, -1]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %ret.26 : Tensor = aten::softmax(%att.1, %18, %20) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1843:14 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1246) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [12, -1, -1]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Softmax original dim -1
DEBUG: [Torch-TensorRT] - Softmax converted dim 2
DEBUG: [Torch-TensorRT] - Disregarding dtype argument
DEBUG: [Torch-TensorRT] - Output tensor shape: [12, -1, -1]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %y.1 : Tensor = aten::matmul(%ret.26, %v.9) # gptadv_static.py:66:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT] - ITensor name: ret.26
DEBUG: [Torch-TensorRT] - ITensor shape: [12, -1, -1]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1241) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [12, -1, 64]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [12, -1, 64]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5234 : Tensor = aten::transpose(%y.1, %17, %13) # gptadv_static.py:67:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1248) [Matrix Multiply]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [12, -1, 64]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Shuffle to: [0, 2, 1]
DEBUG: [Torch-TensorRT] - Output tensor shape: [12, 64, -1]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5302 : Tensor = aten::reshape(%5234, %5) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1249) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [12, 64, -1]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Using dynamic version of reshape layer
DEBUG: [Torch-TensorRT] - Shape tensor is an IntList
DEBUG: [Torch-TensorRT] - Weights: [2]
    Data Type: Int32
    Number of input maps: 2
    Number of output maps: 2
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x564048183500 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %5530 : int = prim::Constant[value=1]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be: 1
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5531 : Tensor = aten::t(%self.blocks.11.attention.c_proj.weight.1) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found IValue containing object of type Float(768, 768, strides=[768, 1], requires_grad=0, device=cuda:0)
DEBUG: [Torch-TensorRT] - Weights: [768, 768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56404810d580 as an IConstantLayer
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1252) [Constant]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [768, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [768, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5532 : Tensor = aten::matmul(%5302, %5531) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1251) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1253) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [768, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5533 : Tensor = trt::const(%self.blocks.0.attention.c_proj.bias.1) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor %5533 : Tensor = trt::const(%self.blocks.0.attention.c_proj.bias.1) as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5534 : Tensor = aten::add(%5533, %5532, %5530) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1255) [Constant]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1254) [Matrix Multiply]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %x.7 : Tensor = aten::add(%x.45, %5534, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:162:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1194) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1257) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5239 : Tensor = aten::layer_norm(%x.7, %9, %self.blocks.11.ln_2.weight.1, %self.blocks.11.ln_2.bias.1, %11, %10) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2515:11 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - cudnn disregarded
DEBUG: [Torch-TensorRT] - Axis Mask for E[x]00000000000000000000000000000010
DEBUG: [Torch-TensorRT] - Weights: [1]
    Data Type: Float32
    Number of input maps: 1
    Number of output maps: 1
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x564048110dd0 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Weights: [1]
    Data Type: Float32
    Number of input maps: 1
    Number of output maps: 1
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x5640481a6e40 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %5535 : int = prim::Constant[value=1]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be: 1
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5536 : Tensor = aten::t(%self.blocks.11.mlp.0.weight.1) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found IValue containing object of type Float(3072, 768, strides=[768, 1], requires_grad=0, device=cuda:0)
DEBUG: [Torch-TensorRT] - Weights: [3072, 768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 3072
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x5640481a8850 as an IConstantLayer
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1279) [Constant]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [3072, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [768, 3072]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5537 : Tensor = aten::matmul(%5239, %5536) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1278) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1280) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [768, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 3072]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5538 : Tensor = trt::const(%self.blocks.11.mlp.0.bias.1) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - Weights: [3072]
    Data Type: Float32
    Number of input maps: 3072
    Number of output maps: 3072
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor %5538 : Tensor = trt::const(%self.blocks.11.mlp.0.bias.1) as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [3072]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5539 : Tensor = aten::add(%5538, %5537, %5535) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1282) [Constant]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1281) [Matrix Multiply]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 3072]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5241 : Tensor = aten::mul(%5539, %15) # gptadv_static.py:26:15 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1284) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Weights: [1]
    Data Type: Float32
    Number of input maps: 1
    Number of output maps: 1
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x564048182510 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 3072]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5242 : Tensor = aten::div(%5539, %16) # gptadv_static.py:26:42 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1284) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Weights: [1]
    Data Type: Float32
    Number of input maps: 1
    Number of output maps: 1
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x564048182580 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 3072]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5243 : Tensor = aten::erf(%5242) # gptadv_static.py:26:32 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1290) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 3072]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5244 : Tensor = aten::add(%5243, %14, %17) # <string>:5:9 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1291) [Unary]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Weights: [1]
    Data Type: Float32
    Number of input maps: 1
    Number of output maps: 1
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x5640481aaa90 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 3072]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %input.9 : Tensor = aten::mul(%5241, %5244) # gptadv_static.py:26:15 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1287) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1294) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 3072]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Evaluating %5540 : int = prim::Constant[value=1]()
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found the value to be: 1
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5541 : Tensor = aten::t(%self.blocks.11.mlp.2.weight.1) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found IValue containing object of type Float(768, 3072, strides=[3072, 1], requires_grad=0, device=cuda:0)
DEBUG: [Torch-TensorRT] - Weights: [768, 3072]
    Data Type: Float32
    Number of input maps: 3072
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56404819fcc0 as an IConstantLayer
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1296) [Constant]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [768, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [3072, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5542 : Tensor = aten::matmul(%input.9, %5541) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1295) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 3072]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1297) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [3072, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5543 : Tensor = trt::const(%self.blocks.11.mlp.2.bias.1) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor %5543 : Tensor = trt::const(%self.blocks.11.mlp.2.bias.1) as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5544 : Tensor = aten::add(%5543, %5542, %5540) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1299) [Constant]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1298) [Matrix Multiply]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %x.49 : Tensor = aten::add(%x.7, %5544, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:163:12 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1258) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1301) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 768]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %x.53 : Tensor = aten::layer_norm(%x.49, %9, %self.ln.weight.1, %self.ln.bias.1, %11, %10) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2515:11 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - cudnn disregarded
DEBUG: [Torch-TensorRT] - Axis Mask for E[x]00000000000000000000000000000010
DEBUG: [Torch-TensorRT] - Weights: [1]
    Data Type: Float32
    Number of input maps: 1
    Number of output maps: 1
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56404817d650 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Weights: [1]
    Data Type: Float32
    Number of input maps: 1
    Number of output maps: 1
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x5640481b7a60 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
DEBUG: [Torch-TensorRT] - Weights: [768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 768
    Element shape: [1]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5545 : Tensor = aten::t(%self.token_emb.weight.1) # <string>:3:35 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Found IValue containing object of type Float(50257, 768, strides=[768, 1], requires_grad=0, device=cuda:0)
DEBUG: [Torch-TensorRT] - Weights: [50257, 768]
    Data Type: Float32
    Number of input maps: 768
    Number of output maps: 50257
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x56404819ada0 as an IConstantLayer
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1323) [Constant]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [50257, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [768, 50257]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5546 : Tensor = aten::matmul(%x.53, %5545) # <string>:3:16 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1322) [ElementWise]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 768]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1324) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [768, 50257]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [-1, 50257]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5250 : Tensor = aten::select(%5546, %19, %18) # gptadv_static.py:237:20 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1325) [Matrix Multiply]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [-1, 50257]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Gather input dimensions: [-1, 50257]
DEBUG: [Torch-TensorRT] - Dimension to select: 0
DEBUG: [Torch-TensorRT] - Index: -2
DEBUG: [Torch-TensorRT] - Weights: [1]
    Data Type: Int32
    Number of input maps: 1
    Number of output maps: 1
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x5640481a9500 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Gather tensor shape: [1, 50257]
DEBUG: [Torch-TensorRT] - Output tensor shape: [50257]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5303 : Tensor = aten::reshape(%5250, %4) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1328) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [50257]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Using dynamic version of reshape layer
DEBUG: [Torch-TensorRT] - Shape tensor is an IntList
DEBUG: [Torch-TensorRT] - Weights: [2]
    Data Type: Int32
    Number of input maps: 2
    Number of output maps: 2
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x564048198160 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [1, 50257]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %ret.1 : Tensor = aten::softmax(%5303, %17, %20) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1843:14 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1330) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [1, 50257]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Softmax original dim 1
DEBUG: [Torch-TensorRT] - Softmax converted dim 1
DEBUG: [Torch-TensorRT] - Disregarding dtype argument
DEBUG: [Torch-TensorRT] - Output tensor shape: [1, 50257]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %new_token_idx.1 : Tensor = aten::argmax(%ret.1, %17, %21) # gptadv_static.py:241:24 (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: ret.1
DEBUG: [Torch-TensorRT] - ITensor shape: [1, 50257]
DEBUG: [Torch-TensorRT] - ITensor type: Float32
DEBUG: [Torch-TensorRT] - Output tensor shape: [1]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Adding Layer %5304 : Tensor = aten::reshape(%new_token_idx.1, %3) (ctx.AddLayer)
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is an already converted tensor
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Node input is a result of a previously evaluated value
DEBUG: [Torch-TensorRT] - ITensor name: (Unnamed Layer* 1333) [Shuffle]_output
DEBUG: [Torch-TensorRT] - ITensor shape: [1]
DEBUG: [Torch-TensorRT] - ITensor type: Int32
DEBUG: [Torch-TensorRT] - Using dynamic version of reshape layer
DEBUG: [Torch-TensorRT] - Shape tensor is an IntList
DEBUG: [Torch-TensorRT] - Weights: [2]
    Data Type: Int32
    Number of input maps: 2
    Number of output maps: 2
    Element shape: [1]
DEBUG: [Torch-TensorRT TorchScript Conversion Context] - Freezing tensor 0x5640481c0b90 as an IConstantLayer
DEBUG: [Torch-TensorRT] - Output tensor shape: [1, 1]
INFO: [Torch-TensorRT TorchScript Conversion Context] - Marking Output 5304 named output_0 in engine (ctx.MarkOutput)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 4: [graphShapeAnalyzer.cpp::processCheck::727] Error Code 4: Internal Error (%x.22 : Tensor = aten::add(%x.5, %5334, %17) # /opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:162:12: dimensions not compatible for elementwise)
ERROR: [Torch-TensorRT TorchScript Conversion Context] - 2: [builder.cpp::buildSerializedNetwork::738] Error Code 2: Internal Error (Assertion engine != nullptr failed. )
Traceback (most recent call last):
  File "gptadv_static.py", line 270, in <module>
    trt_model = torch_tensorrt.compile(model_ours, inputs = [
  File "/opt/conda/lib/python3.8/site-packages/torch_tensorrt/_compile.py", line 133, in compile
    return torch_tensorrt.ts.compile(
  File "/opt/conda/lib/python3.8/site-packages/torch_tensorrt/ts/_compiler.py", line 139, in compile
    compiled_cpp_mod = _C.compile_graph(module._c, _parse_compile_spec(spec))
RuntimeError: [Error thrown at core/conversion/conversionctx/ConversionCtx.cpp:169] Building serialized network failed in TensorRT

